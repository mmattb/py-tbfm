{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af62bf71",
   "metadata": {},
   "source": [
    "# TBFM Multisession Training Experiments\n",
    "\n",
    "This notebook runs various TBFM training experiments including baseline, spatial regularization, AE reconstruction penalties, and sparsity training.\n",
    "\n",
    "**Key Features:**\n",
    "- ðŸ”„ **Modular training functions** imported from `multisession_training.py`\n",
    "- ðŸ“Š **Structured logging** with progress tracking and ETA\n",
    "- ðŸ’¾ **Smart model saving** with training-type specific names\n",
    "- ðŸ§¹ **Automatic cleanup** of intermediate checkpoints\n",
    "- ðŸ“ˆ **Comprehensive visualization** of training curves and comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cfa465",
   "metadata": {},
   "source": [
    "## Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0bff3c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T22:28:46.544175Z",
     "start_time": "2025-11-05T22:28:43.996257Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mdeterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# TBFM imports\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtbfm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multisession, meta, utils\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Import our custom training functions\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmultisession_training\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     ExperimentLogger, \n\u001b[1;32m     26\u001b[0m     train_with_logging, \n\u001b[1;32m     27\u001b[0m     train_with_spatial_ae_recon,\n\u001b[1;32m     28\u001b[0m     cleanup_checkpoints\n\u001b[1;32m     29\u001b[0m )\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/tbfm/multisession.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlr_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LambdaLR\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorcheval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Tuple, List\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ae\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torcheval/metrics/__init__.py:44\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorcheval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FrechetAudioDistance\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorcheval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     BinaryAccuracy,\n\u001b[1;32m     12\u001b[0m     BinaryAUPRC,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     TopKMultilabelAccuracy,\n\u001b[1;32m     42\u001b[0m )\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorcheval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FrechetInceptionDistance, PeakSignalNoiseRatio\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorcheval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Metric\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorcheval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mranking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     48\u001b[0m     ClickThroughRate,\n\u001b[1;32m     49\u001b[0m     HitRate,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     WeightedCalibration,\n\u001b[1;32m     53\u001b[0m )\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torcheval/metrics/image/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorcheval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FrechetInceptionDistance\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorcheval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpsnr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeakSignalNoiseRatio\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrechetInceptionDistance\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPeakSignalNoiseRatio\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m ]\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torcheval/metrics/image/fid.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorcheval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Metric\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m find_spec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchvision\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     19\u001b[0m     _TORCHVISION_AVAILABLE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torchvision/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torchvision/models/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malexnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdensenet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torchvision/models/convnext.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_depth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_presets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torchvision/ops/__init__.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgiou_loss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoolers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_align\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_pool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torchvision/ops/poolers.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroi_align\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: \u001b[38;5;28mlist\u001b[39m[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torchvision/ops/roi_align.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_compile_supported\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BroadcastingList2\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pair\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, eval_frame, resume_execution\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallbackTrigger\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:58\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m guard_bool\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache_method\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     59\u001b[0m     config,\n\u001b[1;32m     60\u001b[0m     exc,\n\u001b[1;32m     61\u001b[0m     graph_break_hints,\n\u001b[1;32m     62\u001b[0m     logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging,\n\u001b[1;32m     63\u001b[0m     trace_rules,\n\u001b[1;32m     64\u001b[0m     variables,\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     67\u001b[0m     get_indexof,\n\u001b[1;32m     68\u001b[0m     JUMP_OPNAMES,\n\u001b[1;32m     69\u001b[0m     livevars_analysis,\n\u001b[1;32m     70\u001b[0m     propagate_line_nums,\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     73\u001b[0m     cleaned_instructions,\n\u001b[1;32m     74\u001b[0m     create_call_function,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m     unique_id,\n\u001b[1;32m     82\u001b[0m )\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/trace_rules.py:56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresume_execution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     57\u001b[0m     BuiltinVariable,\n\u001b[1;32m     58\u001b[0m     FunctionalCallVariable,\n\u001b[1;32m     59\u001b[0m     FunctorchHigherOrderVariable,\n\u001b[1;32m     60\u001b[0m     LocalGeneratorFunctionVariable,\n\u001b[1;32m     61\u001b[0m     LocalGeneratorObjectVariable,\n\u001b[1;32m     62\u001b[0m     NestedUserFunctionVariable,\n\u001b[1;32m     63\u001b[0m     PolyfilledFunctionVariable,\n\u001b[1;32m     64\u001b[0m     SkipFunctionVariable,\n\u001b[1;32m     65\u001b[0m     TorchInGraphFunctionVariable,\n\u001b[1;32m     66\u001b[0m     UserFunctionVariable,\n\u001b[1;32m     67\u001b[0m     UserMethodVariable,\n\u001b[1;32m     68\u001b[0m )\n\u001b[1;32m     71\u001b[0m np: Optional[types\u001b[38;5;241m.\u001b[39mModuleType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/variables/__init__.py:19\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThis package implements variable tracking and symbolic execution capabilities for Dynamo,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mwhich are essential for converting Python code into FX graphs. It provides a comprehensive\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mallows Dynamo to accurately trace and optimize Python code while preserving its semantics.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuiltin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BuiltinVariable\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable, EnumVariable\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/variables/base.py:642\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(typestr, objs))\n\u001b[0;32m--> 642\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/variables/builder.py:93\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GuardBuilder, install_guard, make_dupe_guard\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpgo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     87\u001b[0m     auto_dynamic,\n\u001b[1;32m     88\u001b[0m     auto_unset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m     process_automatic_dynamic,\n\u001b[1;32m     92\u001b[0m )\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mside_effects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SideEffects\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     95\u001b[0m     AttrProxySource,\n\u001b[1;32m     96\u001b[0m     AttrSource,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m     UnspecializedNNModuleSource,\n\u001b[1;32m    121\u001b[0m )\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    123\u001b[0m     _extract_tensor_dict,\n\u001b[1;32m    124\u001b[0m     build_checkpoint_variable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     wrap_fake_exception,\n\u001b[1;32m    154\u001b[0m )\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/side_effects.py:44\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m graph_break_hints, utils, variables\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     bytecode_from_template,\n\u001b[1;32m     40\u001b[0m     create_call_function,\n\u001b[1;32m     41\u001b[0m     create_call_method,\n\u001b[1;32m     42\u001b[0m     create_instruction,\n\u001b[1;32m     43\u001b[0m )\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcodegen\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyCodegen\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SideEffectsError, unimplemented_v2\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalSource, LocalCellSource, LocalSource, Source\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/codegen.py:54\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NNModuleVariable\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     49\u001b[0m     NumpyNdarrayVariable,\n\u001b[1;32m     50\u001b[0m     SymNodeVariable,\n\u001b[1;32m     51\u001b[0m     TensorVariable,\n\u001b[1;32m     52\u001b[0m     UnspecializedPythonVariable,\n\u001b[1;32m     53\u001b[0m )\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_function\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorWithTFOverrideVariable\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InstructionTranslatorBase\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/variables/torch_function.py:193\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m most_recent_func \u001b[38;5;241m!=\u001b[39m BUILTIN_TO_TENSOR_FN_MAP[op]:\n\u001b[1;32m    190\u001b[0m                     BUILTIN_TO_TENSOR_RFN_MAP[op] \u001b[38;5;241m=\u001b[39m most_recent_func\n\u001b[0;32m--> 193\u001b[0m \u001b[43mpopulate_builtin_to_tensor_fn_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m banned_attrs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    196\u001b[0m     fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions()\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_tensor_base_attr_getter(fn)\n\u001b[1;32m    199\u001b[0m ]\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcache\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_prev_stack_var_name\u001b[39m():\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/variables/torch_function.py:168\u001b[0m, in \u001b[0;36mpopulate_builtin_to_tensor_fn_map\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m setup_fn, op_list \u001b[38;5;129;01min\u001b[39;00m setups_and_oplists:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m op_list:\n\u001b[0;32m--> 168\u001b[0m         \u001b[43msetup_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m most_recent_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         BUILTIN_TO_TENSOR_FN_MAP[op] \u001b[38;5;241m=\u001b[39m most_recent_func\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/variables/torch_function.py:160\u001b[0m, in \u001b[0;36mpopulate_builtin_to_tensor_fn_map.<locals>.<lambda>\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    157\u001b[0m inp1_int \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m GetMethodMode():\n\u001b[1;32m    159\u001b[0m     setups_and_oplists \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 160\u001b[0m         (\u001b[38;5;28;01mlambda\u001b[39;00m o: \u001b[43mo\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp0\u001b[49m\u001b[43m)\u001b[49m, un_ops),\n\u001b[1;32m    161\u001b[0m         (\u001b[38;5;28;01mlambda\u001b[39;00m o: o(inp0_int), un_int_ops),\n\u001b[1;32m    162\u001b[0m         (\u001b[38;5;28;01mlambda\u001b[39;00m o: o(inp0, inp1), bin_ops),\n\u001b[1;32m    163\u001b[0m         (\u001b[38;5;28;01mlambda\u001b[39;00m o: o(inp0_int, inp1_int), bin_int_ops),\n\u001b[1;32m    164\u001b[0m         (\u001b[38;5;28;01mlambda\u001b[39;00m o: o(inp0_int, \u001b[38;5;241m0\u001b[39m), tensor_and_int_ops),\n\u001b[1;32m    165\u001b[0m     ]\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m setup_fn, op_list \u001b[38;5;129;01min\u001b[39;00m setups_and_oplists:\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m op_list:\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/.venv/lib/python3.10/site-packages/torch/_dynamo/variables/torch_function.py:152\u001b[0m, in \u001b[0;36mpopulate_builtin_to_tensor_fn_map.<locals>.GetMethodMode.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m most_recent_func\n\u001b[1;32m    151\u001b[0m most_recent_func \u001b[38;5;241m=\u001b[39m func\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize_config_dir, compose\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "# Memory optimization settings\n",
    "torch.backends.cudnn.benchmark = False  # Disable for memory consistency\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# TBFM imports\n",
    "from tbfm import multisession, meta, utils\n",
    "\n",
    "# Import our custom training functions\n",
    "from multisession_training import (\n",
    "    ExperimentLogger, \n",
    "    train_with_logging, \n",
    "    train_with_spatial_ae_recon,\n",
    "    cleanup_checkpoints\n",
    ")\n",
    "\n",
    "conf_dir = Path(\"./conf\").resolve()\n",
    "# Initialize Hydra with the configuration directory\n",
    "with initialize_config_dir(config_dir=str(conf_dir), version_base=None):\n",
    "    # Compose the configuration\n",
    "    cfg = compose(config_name=\"config\")\n",
    "\n",
    "print(\"âœ… All imports successful\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176ad72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T22:28:46.564512Z",
     "start_time": "2025-11-05T22:28:46.560709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration set\n",
      "Training enabled: Baseline=True, Spatial=False, AE_Recon=False, Sparsity=False\n"
     ]
    }
   ],
   "source": [
    "# Experiment Configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_DIR = \"/var/data/opto-coproc/\"  # Use absolute path like original notebook\n",
    "EMBEDDING_REST_SUBDIR = \"embed_rest\"\n",
    "OUT_DIR = \"saved_models\"\n",
    "WINDOW_SIZE = cfg.data.trial_len  # Reduce significantly to optimize GPU utilization (35% reduction)\n",
    "MAX_BATCH_SIZE = 32768  # Optimize for GPU memory bandwidth\n",
    "NUM_HELD_OUT_SESSIONS = 2\n",
    "\n",
    "# Training switches - Set to True to enable each training type\n",
    "TRAIN_BASELINE = True\n",
    "TRAIN_SPATIAL = False\n",
    "TRAIN_AE_RECON = False\n",
    "TRAIN_SPARSITY = False\n",
    "\n",
    "# Global training configuration\n",
    "GLOBAL_CONFIG = {\n",
    "    'latent_dim': 50,\n",
    "    'lambda_fro': 0.04,\n",
    "    'test_interval': 1000,  # Test less frequently to reduce memory overhead\n",
    "}\n",
    "\n",
    "# Training-specific configurations\n",
    "BASELINE_CONFIG = {\n",
    "    'epochs': 10000,\n",
    "    'coadapt': True,\n",
    "    'warm_start_is_identity': False,\n",
    "}\n",
    "\n",
    "SPATIAL_CONFIG = {\n",
    "    'epochs': 7000,\n",
    "    'use_spatial': True,\n",
    "    'coadapt': True,\n",
    "    'lambda_spatial_smooth': 0.05,\n",
    "    'lambda_spatial_decoder': 0.01,\n",
    "}\n",
    "\n",
    "AE_RECON_CONFIG = {\n",
    "    'epochs': 5000,\n",
    "    'coadapt': True,\n",
    "    'lambda_ae_recon': 0.01,\n",
    "}\n",
    "\n",
    "SPARSITY_CONFIG = {\n",
    "    'epochs': 10000,\n",
    "    'coadapt': False,\n",
    "    'warm_start_is_identity': True,\n",
    "    'lambda_channel_sparsity': 0.001,\n",
    "    'lambda_sparsity_recon': 0.01,\n",
    "}\n",
    "\n",
    "print(\"âœ… Configuration set\")\n",
    "print(f\"Training enabled: Baseline={TRAIN_BASELINE}, Spatial={TRAIN_SPATIAL}, AE_Recon={TRAIN_AE_RECON}, Sparsity={TRAIN_SPARSITY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e80d82",
   "metadata": {},
   "source": [
    "## Initialize Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d3324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T22:28:46.612514Z",
     "start_time": "2025-11-05T22:28:46.609433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-05 14:43:17 - ================================================================================\n",
      "2025-11-05 14:43:17 - TBFM MULTISESSION TRAINING EXPERIMENTS\n",
      "2025-11-05 14:43:17 - ================================================================================\n",
      "2025-11-05 14:43:17 - Device: cuda\n",
      "2025-11-05 14:43:17 - Window size: 184\n",
      "2025-11-05 14:43:17 - Logging to: logs/multisession_training_20251105_144317.log\n"
     ]
    }
   ],
   "source": [
    "# Create experiment logger\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "log_file = f\"logs/multisession_training_{timestamp}.log\"\n",
    "logger = ExperimentLogger(log_file=log_file)\n",
    "\n",
    "logger.info(\"=\"*80)\n",
    "logger.info(\"TBFM MULTISESSION TRAINING EXPERIMENTS\")\n",
    "logger.info(\"=\"*80)\n",
    "logger.info(f\"Device: {DEVICE}\")\n",
    "logger.info(f\"Window size: {WINDOW_SIZE}\")\n",
    "logger.info(f\"Logging to: {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108e1ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T22:28:46.703525Z",
     "start_time": "2025-11-05T22:28:46.657713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU memory state:\n",
      "GPU Memory: 0.00GB allocated, 0.00GB reserved, 23.43GB total\n",
      "Usage: 0.0% of total VRAM\n"
     ]
    }
   ],
   "source": [
    "# Memory monitoring function\n",
    "def check_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3  # GB\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3   # GB\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB\n",
    "        print(f\"GPU Memory: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved, {total:.2f}GB total\")\n",
    "        print(f\"Usage: {reserved/total*100:.1f}% of total VRAM\")\n",
    "        return reserved/total\n",
    "    return 0\n",
    "\n",
    "# Check initial memory\n",
    "print(\"Initial GPU memory state:\")\n",
    "initial_usage = check_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655bec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T22:28:46.708350Z",
     "start_time": "2025-11-05T22:28:46.706523Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Additional memory optimization settings\n",
    "# def optimize_memory():\n",
    "#     \"\"\"Apply memory optimization settings\"\"\"\n",
    "#     # Force garbage collection\n",
    "#     import gc\n",
    "#     gc.collect()\n",
    "    \n",
    "#     # Clear GPU cache\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "#         # Set memory fraction (optional - use if still having issues)\n",
    "#         # torch.cuda.set_per_process_memory_fraction(0.9)\n",
    "        \n",
    "#         # Enable memory efficient attention if available\n",
    "#         try:\n",
    "#             torch.backends.cuda.enable_flash_sdp(True)\n",
    "#         except:\n",
    "#             pass\n",
    "            \n",
    "#     print(\"âœ… Memory optimization applied\")\n",
    "\n",
    "# # Apply optimizations\n",
    "# optimize_memory()\n",
    "# check_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e6d8e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T22:28:46.756258Z",
     "start_time": "2025-11-05T22:28:46.753835Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Gradient accumulation wrapper for memory-efficient training\n",
    "# def train_with_gradient_accumulation(cfg, model, data_train, model_optims, embeddings_rest, \n",
    "#                                    accumulation_steps=4, **kwargs):\n",
    "#     \"\"\"\n",
    "#     Wrapper that adds gradient accumulation to reduce memory usage.\n",
    "    \n",
    "#     Args:\n",
    "#         accumulation_steps: Number of mini-batches to accumulate before optimizer step\n",
    "#         **kwargs: Other arguments passed to train_with_logging\n",
    "#     \"\"\"\n",
    "#     # Store original step function\n",
    "#     original_step = model_optims.step\n",
    "#     original_zero_grad = model_optims.zero_grad\n",
    "    \n",
    "#     # Gradient accumulation state\n",
    "#     step_count = 0\n",
    "    \n",
    "#     def accumulating_step(*args, **kwargs):\n",
    "#         nonlocal step_count\n",
    "#         step_count += 1\n",
    "        \n",
    "#         # Only actually step every accumulation_steps\n",
    "#         if step_count % accumulation_steps == 0:\n",
    "#             # Scale gradients by accumulation steps\n",
    "#             for param_group in model_optims.optimizer.param_groups:\n",
    "#                 for param in param_group['params']:\n",
    "#                     if param.grad is not None:\n",
    "#                         param.grad = param.grad / accumulation_steps\n",
    "            \n",
    "#             return original_step(*args, **kwargs)\n",
    "#         return None\n",
    "    \n",
    "#     def accumulating_zero_grad(*args, **kwargs):\n",
    "#         nonlocal step_count\n",
    "#         # Only zero gradients at the start of accumulation cycle\n",
    "#         if step_count % accumulation_steps == 0:\n",
    "#             return original_zero_grad(*args, **kwargs)\n",
    "#         return None\n",
    "    \n",
    "#     # Monkey patch the optimizer\n",
    "#     model_optims.step = accumulating_step\n",
    "#     model_optims.zero_grad = accumulating_zero_grad\n",
    "    \n",
    "#     try:\n",
    "#         # Call the original training function\n",
    "#         return train_with_logging(cfg, model, data_train, model_optims, embeddings_rest, **kwargs)\n",
    "#     finally:\n",
    "#         # Restore original functions\n",
    "#         model_optims.step = original_step\n",
    "#         model_optims.zero_grad = original_zero_grad\n",
    "\n",
    "# print(\"âœ… Gradient accumulation function defined\")\n",
    "# print(\"This allows effective batch size of 4096 * 4 = 16384 with same memory as 4096\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f5b391",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e763e0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T22:28:49.628115Z",
     "start_time": "2025-11-05T22:28:46.802191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-05 14:43:17 - ================================================================================\n",
      "2025-11-05 14:43:17 - Starting: Data Loading\n",
      "2025-11-05 14:43:17 - ================================================================================\n",
      "2025-11-05 14:43:17 - ================================================================================\n",
      "2025-11-05 14:43:19 - Loaded 2 sessions\n",
      "2025-11-05 14:43:19 - Sessions: ['MonkeyG_20150918_Session1_M1', 'MonkeyG_20150925_Session2_S1']\n",
      "2025-11-05 14:43:19 - Held out sessions: ['MonkeyJ_20160426_Session2_S1', 'MonkeyJ_20160428_Session2_S1', 'MonkeyJ_20160630_Session3_S1', 'MonkeyG_20150910_Session3_S1', 'MonkeyJ_20160429_Session1_S1', 'MonkeyJ_20160426_Session3_S1', 'MonkeyG_20150909_Session4_M1', 'MonkeyJ_20160627_Session2_S1', 'MonkeyG_20150910_Session7_S1', 'MonkeyG_20150917_Session2_S1', 'MonkeyG_20150914_Session3_S1', 'MonkeyG_20150915_Session3_S1', 'MonkeyJ_20160624_Session4_S1', 'MonkeyG_20150915_Session4_S1', 'MonkeyG_20150910_Session6_S1', 'MonkeyJ_20160425_Session2_M1', 'MonkeyG_20150922_Session1_S1', 'MonkeyG_20150925_Session1_S1', 'MonkeyG_20150918_Session1_S1', 'MonkeyJ_20160702_Session4_S1', 'MonkeyJ_20160624_Session3_S1', 'MonkeyJ_20160427_Session2_S1', 'MonkeyG_20150911_Session2_S1', 'MonkeyG_20150911_Session5_S1', 'MonkeyJ_20160426_Session1_S1', 'MonkeyG_20150922_Session2_S1', 'MonkeyG_20150908_Session4_M1', 'MonkeyJ_20160625_Session3_S1', 'MonkeyJ_20160626_Session3_S1', 'MonkeyJ_20160626_Session1_S1', 'MonkeyJ_20160702_Session2_S1', 'MonkeyG_20150910_Session4_S1', 'MonkeyJ_20160502_Session1_S1', 'MonkeyJ_20160425_Session1_M1', 'MonkeyG_20150909_Session5_M1', 'MonkeyG_20150915_Session5_S1', 'MonkeyG_20150917_Session1_S1', 'MonkeyJ_20160625_Session2_S1', 'MonkeyG_20150908_Session2_M1', 'MonkeyG_20150921_Session5_S1', 'MonkeyG_20150908_Session3_M1', 'MonkeyG_20150909_Session3_M1', 'MonkeyG_20150917_Session3_S1', 'MonkeyJ_20160625_Session5_S1', 'MonkeyG_20150922_Session3_S1', 'MonkeyJ_20160624_Session2_S1', 'MonkeyG_20150909_Session2_M1', 'MonkeyG_20150916_Session4_S1', 'MonkeyG_20150911_Session4_S1', 'MonkeyG_20150911_Session6_S1', 'MonkeyJ_20160625_Session4_S1', 'MonkeyG_20150921_Session3_S1', 'MonkeyJ_20160428_Session3_S1', 'MonkeyJ_20160429_Session3_S1', 'MonkeyG_20150911_Session3_S1', 'MonkeyJ_20160627_Session1_S1', 'MonkeyJ_20160626_Session2_S1', 'MonkeyG_20150914_Session2_S1', 'MonkeyG_20150917_Session2_M1', 'MonkeyG_20150914_Session1_S1', 'MonkeyJ_20160425_Session3_S1', 'MonkeyJ_20160624_Session1_S1', 'MonkeyG_20150917_Session3_M1', 'MonkeyG_20150917_Session1_M1', 'MonkeyJ_20160630_Session1_S1', 'MonkeyG_20150911_Session7_S1', 'MonkeyG_20150915_Session2_S1']\n",
      "2025-11-05 14:43:19 - Training batch size: 32768\n",
      "2025-11-05 14:43:19 - Train batch shape: torch.Size([5000, 20, 74])\n",
      "2025-11-05 14:43:19 - Test batch shape: torch.Size([2500, 20, 74])\n",
      "\n",
      "Memory after data loading:\n",
      "GPU Memory: 0.00GB allocated, 0.00GB reserved, 23.43GB total\n",
      "Usage: 0.0% of total VRAM\n",
      "2025-11-05 14:43:19 - \n",
      "Completed: Data Loading\n",
      "2025-11-05 14:43:19 - Duration: 00:02\n",
      "2025-11-05 14:43:19 - ================================================================================\n",
      "2025-11-05 14:43:19 - Loaded 2 sessions\n",
      "2025-11-05 14:43:19 - Sessions: ['MonkeyG_20150918_Session1_M1', 'MonkeyG_20150925_Session2_S1']\n",
      "2025-11-05 14:43:19 - Held out sessions: ['MonkeyJ_20160426_Session2_S1', 'MonkeyJ_20160428_Session2_S1', 'MonkeyJ_20160630_Session3_S1', 'MonkeyG_20150910_Session3_S1', 'MonkeyJ_20160429_Session1_S1', 'MonkeyJ_20160426_Session3_S1', 'MonkeyG_20150909_Session4_M1', 'MonkeyJ_20160627_Session2_S1', 'MonkeyG_20150910_Session7_S1', 'MonkeyG_20150917_Session2_S1', 'MonkeyG_20150914_Session3_S1', 'MonkeyG_20150915_Session3_S1', 'MonkeyJ_20160624_Session4_S1', 'MonkeyG_20150915_Session4_S1', 'MonkeyG_20150910_Session6_S1', 'MonkeyJ_20160425_Session2_M1', 'MonkeyG_20150922_Session1_S1', 'MonkeyG_20150925_Session1_S1', 'MonkeyG_20150918_Session1_S1', 'MonkeyJ_20160702_Session4_S1', 'MonkeyJ_20160624_Session3_S1', 'MonkeyJ_20160427_Session2_S1', 'MonkeyG_20150911_Session2_S1', 'MonkeyG_20150911_Session5_S1', 'MonkeyJ_20160426_Session1_S1', 'MonkeyG_20150922_Session2_S1', 'MonkeyG_20150908_Session4_M1', 'MonkeyJ_20160625_Session3_S1', 'MonkeyJ_20160626_Session3_S1', 'MonkeyJ_20160626_Session1_S1', 'MonkeyJ_20160702_Session2_S1', 'MonkeyG_20150910_Session4_S1', 'MonkeyJ_20160502_Session1_S1', 'MonkeyJ_20160425_Session1_M1', 'MonkeyG_20150909_Session5_M1', 'MonkeyG_20150915_Session5_S1', 'MonkeyG_20150917_Session1_S1', 'MonkeyJ_20160625_Session2_S1', 'MonkeyG_20150908_Session2_M1', 'MonkeyG_20150921_Session5_S1', 'MonkeyG_20150908_Session3_M1', 'MonkeyG_20150909_Session3_M1', 'MonkeyG_20150917_Session3_S1', 'MonkeyJ_20160625_Session5_S1', 'MonkeyG_20150922_Session3_S1', 'MonkeyJ_20160624_Session2_S1', 'MonkeyG_20150909_Session2_M1', 'MonkeyG_20150916_Session4_S1', 'MonkeyG_20150911_Session4_S1', 'MonkeyG_20150911_Session6_S1', 'MonkeyJ_20160625_Session4_S1', 'MonkeyG_20150921_Session3_S1', 'MonkeyJ_20160428_Session3_S1', 'MonkeyJ_20160429_Session3_S1', 'MonkeyG_20150911_Session3_S1', 'MonkeyJ_20160627_Session1_S1', 'MonkeyJ_20160626_Session2_S1', 'MonkeyG_20150914_Session2_S1', 'MonkeyG_20150917_Session2_M1', 'MonkeyG_20150914_Session1_S1', 'MonkeyJ_20160425_Session3_S1', 'MonkeyJ_20160624_Session1_S1', 'MonkeyG_20150917_Session3_M1', 'MonkeyG_20150917_Session1_M1', 'MonkeyJ_20160630_Session1_S1', 'MonkeyG_20150911_Session7_S1', 'MonkeyG_20150915_Session2_S1']\n",
      "2025-11-05 14:43:19 - Training batch size: 32768\n",
      "2025-11-05 14:43:19 - Train batch shape: torch.Size([5000, 20, 74])\n",
      "2025-11-05 14:43:19 - Test batch shape: torch.Size([2500, 20, 74])\n",
      "\n",
      "Memory after data loading:\n",
      "GPU Memory: 0.00GB allocated, 0.00GB reserved, 23.43GB total\n",
      "Usage: 0.0% of total VRAM\n",
      "2025-11-05 14:43:19 - \n",
      "Completed: Data Loading\n",
      "2025-11-05 14:43:19 - Duration: 00:02\n",
      "2025-11-05 14:43:19 - ================================================================================\n"
     ]
    }
   ],
   "source": [
    "logger.start_phase(\"Data Loading\")\n",
    "\n",
    "# Load configuration using Hydra (like the original notebook)\n",
    "from hydra import initialize_config_dir, compose\n",
    "\n",
    "conf_dir = Path(\"./conf\").resolve()\n",
    "with initialize_config_dir(config_dir=str(conf_dir), version_base=None):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "\n",
    "# Define session IDs to use (can be customized)\n",
    "# held_in_session_ids = [\"MonkeyG_20150925_Session2_S1\", \"MonkeyG_20150918_Session1_M1\"]\n",
    "held_in_session_ids = [\"MonkeyG_20150925_Session2_S1\", \"MonkeyG_20150918_Session1_M1\", \"MonkeyG_20150915_Session3_S1\", \"MonkeyG_20150917_Session1_M1\"]\n",
    "# held_in_session_ids=[\n",
    "    # \"MonkeyG_20150914_Session1_S1\",\n",
    "    # \"MonkeyG_20150915_Session3_S1\",\n",
    "    # \"MonkeyG_20150915_Session5_S1\",\n",
    "    # \"MonkeyG_20150916_Session4_S1\",\n",
    "    # \"MonkeyG_20150917_Session1_M1\",\n",
    "    # \"MonkeyG_20150917_Session1_S1\",\n",
    "    # \"MonkeyG_20150917_Session2_M1\",\n",
    "    # \"MonkeyG_20150917_Session2_S1\",\n",
    "    # \"MonkeyG_20150921_Session3_S1\",\n",
    "    # \"MonkeyG_20150921_Session5_S1\",\n",
    "    # \"MonkeyG_20150922_Session1_S1\",\n",
    "    # \"MonkeyG_20150922_Session2_S1\",\n",
    "    # \"MonkeyG_20150925_Session1_S1\",\n",
    "    # \"MonkeyG_20150925_Session2_S1\",\n",
    "    # \"MonkeyJ_20160426_Session2_S1\",\n",
    "    # \"MonkeyJ_20160426_Session3_S1\",\n",
    "    # \"MonkeyJ_20160428_Session3_S1\",\n",
    "    # \"MonkeyJ_20160429_Session1_S1\",\n",
    "    # \"MonkeyJ_20160502_Session1_S1\",\n",
    "    # \"MonkeyJ_20160624_Session3_S1\",\n",
    "    # \"MonkeyJ_20160625_Session4_S1\",\n",
    "    # \"MonkeyJ_20160625_Session5_S1\",\n",
    "    # \"MonkeyJ_20160627_Session1_S1\",\n",
    "    # \"MonkeyJ_20160630_Session3_S1\",\n",
    "    # \"MonkeyJ_20160702_Session2_S1\",\n",
    "# ]\n",
    "\n",
    "num_sessions = len(held_in_session_ids)\n",
    "batch_size = (MAX_BATCH_SIZE // num_sessions) * num_sessions\n",
    "\n",
    "# Load data using the correct TBFM function signature\n",
    "d, held_out_session_ids = multisession.load_stim_batched(\n",
    "    window_size=WINDOW_SIZE,\n",
    "    session_subdir=\"torchraw\",\n",
    "    data_dir=DATA_DIR,\n",
    "    unpack_stiminds=True,\n",
    "    held_in_session_ids=held_in_session_ids,\n",
    "    batch_size=batch_size,\n",
    "    num_held_out_sessions=NUM_HELD_OUT_SESSIONS,\n",
    ")\n",
    "data_train, data_test = d.train_test_split(5000, test_cut=2500)\n",
    "\n",
    "held_in_session_ids = data_train.session_ids\n",
    "\n",
    "logger.info(f\"Loaded {len(held_in_session_ids)} sessions\")\n",
    "logger.info(f\"Sessions: {held_in_session_ids}\")\n",
    "logger.info(f\"Held out sessions: {held_out_session_ids}\")\n",
    "logger.info(f\"Training batch size: {batch_size}\")\n",
    "\n",
    "# Load embeddings_rest\n",
    "embeddings_rest = multisession.load_rest_embeddings(held_in_session_ids, device=DEVICE)\n",
    "\n",
    "# Test data loading\n",
    "b = next(iter(data_train))\n",
    "k0 = list(b.keys())[0]\n",
    "logger.info(f\"Train batch shape: {b[k0][0].shape}\")\n",
    "b = next(iter(data_test))\n",
    "logger.info(f\"Test batch shape: {b[k0][0].shape}\")\n",
    "\n",
    "# Clear unnecessary references and check memory\n",
    "del b, k0\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nMemory after data loading:\")\n",
    "post_data_usage = check_gpu_memory()\n",
    "\n",
    "logger.end_phase(\"Data Loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada81580",
   "metadata": {},
   "source": [
    "## Model Configuration and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd4c61",
   "metadata": {},
   "source": [
    "### Spatial Regularization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0545ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-05 14:43:20 - â­ï¸  Skipping Spatial model (TRAIN_SPATIAL=False)\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_SPATIAL:\n",
    "    logger.start_phase(\"Loading Spatial Structures\")\n",
    "\n",
    "    # Import spatial utilities\n",
    "    sys.path.append(\"/home/danmuir\")\n",
    "    from utils import get_preprocess_info\n",
    "\n",
    "    # Load spatial structures for each session\n",
    "    spatial_structures = {}\n",
    "    for session_id in held_in_session_ids:\n",
    "        logger.info(f\"Loading spatial structure for {session_id}\")\n",
    "        (\n",
    "            preprocess,\n",
    "            ch_from_orig,\n",
    "            ch_to_orig,\n",
    "            node_position_orig,  # Dict[int, tuple]: node_id -> (x, y)\n",
    "            node_id_orig,\n",
    "            ch_from_after,\n",
    "            ch_to_after,\n",
    "        ) = get_preprocess_info(session_id, subdir=DATA_DIR)\n",
    "\n",
    "        # Store for later use\n",
    "        spatial_structures[session_id] = {\n",
    "            'node_position': node_position_orig,\n",
    "            'node_position_after': preprocess.node_position,\n",
    "            'mask_indices': list(preprocess.node_position.keys()),\n",
    "            'num_channels': len(preprocess.node_position)\n",
    "        }\n",
    "\n",
    "        logger.info(f\"  {session_id}: {len(node_position_orig)} total electrodes, \"\n",
    "                    f\"{len(preprocess.node_position)} valid electrodes\")\n",
    "\n",
    "    logger.end_phase(\"Loading Spatial Structures\")\n",
    "else:\n",
    "    logger.info(\"â­ï¸  Skipping Spatial model (TRAIN_SPATIAL=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8914d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-05 14:43:20 - â­ï¸  Skipping Spatial training (TRAIN_SPATIAL=False)\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_SPATIAL:\n",
    "    logger.start_training(SPATIAL_CONFIG['epochs'], \"Spatial Model Training\")\n",
    "\n",
    "    # Build spatial model\n",
    "    cfg_spatial = OmegaConf.create(OmegaConf.to_container(cfg, resolve=True))\n",
    "    cfg_spatial.ae.module.use_spatial = SPATIAL_CONFIG['use_spatial']\n",
    "    cfg_spatial.training.epochs = SPATIAL_CONFIG['epochs']\n",
    "    cfg_spatial.ae.training.coadapt = SPATIAL_CONFIG['coadapt']\n",
    "\n",
    "    ms_spatial = multisession.build_from_cfg(cfg_spatial, data_train, device=DEVICE)\n",
    "\n",
    "    # Register spatial structures\n",
    "    for session_id in held_in_session_ids:\n",
    "        ae_instance = ms_spatial.ae.instances[session_id]\n",
    "        spatial_info = spatial_structures[session_id]\n",
    "        \n",
    "        ae_instance.register_spatial_structure(\n",
    "            node_position=spatial_info['node_position'],\n",
    "            mask_indices=spatial_info['mask_indices']\n",
    "        )\n",
    "\n",
    "    model_optims_spatial = multisession.get_optims(cfg_spatial, ms_spatial)\n",
    "\n",
    "    # Train with spatial regularization\n",
    "    embeddings_stim_spatial, results_spatial = train_with_spatial_ae_recon(\n",
    "        cfg_spatial,\n",
    "        ms_spatial,\n",
    "        data_train,\n",
    "        model_optims_spatial,\n",
    "        embeddings_rest,\n",
    "        data_test=data_test,\n",
    "        test_interval=GLOBAL_CONFIG['test_interval'],\n",
    "        epochs=cfg_spatial.training.epochs,\n",
    "        lambda_spatial_smooth=SPATIAL_CONFIG['lambda_spatial_smooth'],\n",
    "        lambda_spatial_decoder=SPATIAL_CONFIG['lambda_spatial_decoder'],\n",
    "        lambda_ae_recon=0.0,  # No AE reconstruction penalty\n",
    "        training_type=\"Spatial\",\n",
    "        logger=logger\n",
    "    )\n",
    "\n",
    "    logger.end_training(\"Spatial Model Training\")\n",
    "\n",
    "    # Log spatial results\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"SPATIAL MODEL RESULTS\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"Overall Test RÂ²: {results_spatial['final_test_r2']:.6f}\")\n",
    "    logger.info(\"\\nPer-session Test RÂ²:\")\n",
    "    for session_id, r2 in results_spatial['final_test_r2s'].items():\n",
    "        logger.info(f\"  {session_id}: {r2:.6f}\")\n",
    "    logger.info(\"=\"*80)\n",
    "else:\n",
    "    logger.info(\"â­ï¸  Skipping Spatial training (TRAIN_SPATIAL=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c4238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPU-Optimized Training Function\n",
    "# def train_with_gpu_optimization(cfg, ms, data_train, model_optims, embeddings_rest,\n",
    "#                                data_test=None, epochs=5000, test_interval=1000,\n",
    "#                                training_type=\"\", logger=None, save_best_model=True):\n",
    "#     \"\"\"\n",
    "#     GPU-optimized training function that uses the standard TBFM training with optimizations.\n",
    "#     \"\"\"\n",
    "#     import torch\n",
    "#     from tbfm import multisession\n",
    "    \n",
    "#     # GPU optimization settings\n",
    "#     torch.backends.cudnn.benchmark = True  # Optimize for consistent input sizes\n",
    "#     torch.backends.cuda.matmul.allow_tf32 = True  # Use TF32 for faster matmul\n",
    "#     torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "#     # Compile model for better GPU utilization (if PyTorch 2.0+)\n",
    "#     try:\n",
    "#         if hasattr(torch, 'compile'):\n",
    "#             logger.info(\"ðŸ”¥ Compiling model with torch.compile for better GPU utilization...\")\n",
    "#             # Use 'default' mode to avoid CUDA graphs memory issues\n",
    "#             for session_id in ms.model.instances:\n",
    "#                 ms.model.instances[session_id] = torch.compile(\n",
    "#                     ms.model.instances[session_id], \n",
    "#                     mode='default',  # Safer than 'reduce-overhead'\n",
    "#                     disable=False,\n",
    "#                     options={\"triton.cudagraphs\": False}  # Disable CUDA graphs\n",
    "#                 )\n",
    "#     except Exception as e:\n",
    "#         logger.info(f\"Model compilation not available or failed: {e}\")\n",
    "    \n",
    "#     logger.info(f\"Starting GPU-optimized training for {epochs} epochs...\")\n",
    "    \n",
    "#     # Use the standard TBFM training function with our optimizations\n",
    "#     embeddings_stim, results = multisession.train_from_cfg(\n",
    "#         cfg,\n",
    "#         ms,\n",
    "#         data_train,\n",
    "#         model_optims,\n",
    "#         embeddings_rest,\n",
    "#         data_test=data_test,\n",
    "#         epochs=epochs,\n",
    "#         test_interval=test_interval\n",
    "#     )\n",
    "    \n",
    "#     # Clean up GPU memory after training\n",
    "#     torch.cuda.empty_cache()\n",
    "    \n",
    "#     logger.info(f\"âœ… GPU-optimized training complete\")\n",
    "    \n",
    "#     return embeddings_stim, results\n",
    "\n",
    "# print(\"âœ… GPU-optimized training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a18700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Safe GPU-Optimized Training Function (No Compilation)\n",
    "# def train_with_safe_gpu_optimization(cfg, ms, data_train, model_optims, embeddings_rest,\n",
    "#                                     data_test=None, epochs=5000, test_interval=1000,\n",
    "#                                     training_type=\"\", logger=None, save_best_model=True):\n",
    "#     \"\"\"\n",
    "#     GPU-optimized training function without torch.compile to avoid CUDA graphs issues.\n",
    "#     \"\"\"\n",
    "#     import torch\n",
    "#     from tbfm import multisession\n",
    "    \n",
    "#     # Basic GPU optimization settings (no compilation)\n",
    "#     torch.backends.cudnn.benchmark = True\n",
    "#     torch.backends.cuda.matmul.allow_tf32 = True\n",
    "#     torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "#     # Disable CUDA graphs globally to prevent memory issues\n",
    "#     torch._C._set_print_stacktraces_on_fatal_signal(False)\n",
    "    \n",
    "#     logger.info(f\"Starting safe GPU-optimized training for {epochs} epochs (no compilation)...\")\n",
    "    \n",
    "#     # Use the standard TBFM training function with basic optimizations\n",
    "#     embeddings_stim, results = multisession.train_from_cfg(\n",
    "#         cfg,\n",
    "#         ms,\n",
    "#         data_train,\n",
    "#         model_optims,\n",
    "#         embeddings_rest,\n",
    "#         data_test=data_test,\n",
    "#         epochs=epochs,\n",
    "#         test_interval=test_interval\n",
    "#     )\n",
    "    \n",
    "#     # Clean up GPU memory after training\n",
    "#     torch.cuda.empty_cache()\n",
    "    \n",
    "#     logger.info(f\"âœ… Safe GPU-optimized training complete\")\n",
    "    \n",
    "#     return embeddings_stim, results\n",
    "\n",
    "# print(\"âœ… Safe GPU-optimized training function defined (no torch.compile)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f34ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Memory Optimization Function\n",
    "# def optimize_memory():\n",
    "#     \"\"\"\n",
    "#     Optimize GPU memory usage and clear unnecessary cached data.\n",
    "#     \"\"\"\n",
    "#     import torch\n",
    "#     import gc\n",
    "    \n",
    "#     # Clear Python garbage collection\n",
    "#     gc.collect()\n",
    "    \n",
    "#     # Clear GPU cache\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache()\n",
    "#         torch.cuda.synchronize()\n",
    "    \n",
    "#     # Set memory optimization flags\n",
    "#     torch.backends.cudnn.benchmark = True\n",
    "#     torch.backends.cuda.matmul.allow_tf32 = True\n",
    "#     torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "#     # Enable memory efficient attention if available\n",
    "#     try:\n",
    "#         torch.backends.cuda.enable_flash_sdp(True)\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "#     print(\"ðŸ§¹ Memory optimized and caches cleared\")\n",
    "\n",
    "# def monitor_gpu_memory():\n",
    "#     \"\"\"\n",
    "#     Monitor GPU memory usage and return current usage.\n",
    "#     \"\"\"\n",
    "#     import torch\n",
    "#     if torch.cuda.is_available():\n",
    "#         allocated = torch.cuda.memory_allocated() / 1024**3  # GB\n",
    "#         reserved = torch.cuda.memory_reserved() / 1024**3   # GB\n",
    "#         print(f\"GPU Memory: {allocated:.1f}GB allocated, {reserved:.1f}GB reserved\")\n",
    "#         return allocated, reserved\n",
    "#     return 0, 0\n",
    "\n",
    "# print(\"âœ… Memory optimization functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f52c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Real-time GPU Monitoring\n",
    "# import subprocess\n",
    "# import threading\n",
    "# import time\n",
    "\n",
    "# def monitor_gpu_utilization(duration=60, interval=2):\n",
    "#     \"\"\"\n",
    "#     Monitor GPU utilization for a specified duration.\n",
    "#     \"\"\"\n",
    "#     def monitor():\n",
    "#         print(f\"ðŸ” Monitoring GPU utilization for {duration} seconds...\")\n",
    "#         start_time = time.time()\n",
    "#         max_util = 0\n",
    "#         min_util = 100\n",
    "#         utilizations = []\n",
    "        \n",
    "#         while time.time() - start_time < duration:\n",
    "#             try:\n",
    "#                 result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total', \n",
    "#                                        '--format=csv,noheader,nounits'], capture_output=True, text=True)\n",
    "#                 if result.returncode == 0:\n",
    "#                     lines = result.stdout.strip().split('\\n')\n",
    "#                     for line in lines:\n",
    "#                         util, mem_used, mem_total = map(int, line.split(', '))\n",
    "#                         utilizations.append(util)\n",
    "#                         max_util = max(max_util, util)\n",
    "#                         min_util = min(min_util, util)\n",
    "#                         print(f\"GPU: {util:2d}% util, {mem_used:5d}/{mem_total}MB memory\", end='\\r')\n",
    "#                 time.sleep(interval)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error monitoring GPU: {e}\")\n",
    "#                 break\n",
    "        \n",
    "#         if utilizations:\n",
    "#             avg_util = sum(utilizations) / len(utilizations)\n",
    "#             print(f\"\\nðŸ“Š GPU Utilization Summary:\")\n",
    "#             print(f\"   Average: {avg_util:.1f}%\")\n",
    "#             print(f\"   Range: {min_util}% - {max_util}%\")\n",
    "            \n",
    "#             if avg_util < 50:\n",
    "#                 print(\"âš ï¸  Low GPU utilization detected!\")\n",
    "#                 print(\"   Possible causes: Memory bottlenecks, CPU-GPU sync, small batch sizes\")\n",
    "#             elif avg_util > 85:\n",
    "#                 print(\"âœ… Good GPU utilization!\")\n",
    "    \n",
    "#     # Start monitoring in background thread\n",
    "#     monitor_thread = threading.Thread(target=monitor)\n",
    "#     monitor_thread.daemon = True\n",
    "#     monitor_thread.start()\n",
    "#     return monitor_thread\n",
    "\n",
    "# print(\"âœ… GPU monitoring functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e177fd",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d98edc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-05 14:43:20 - ================================================================================\n",
      "2025-11-05 14:43:20 - Starting: Model Configuration - Baseline\n",
      "2025-11-05 14:43:20 - ================================================================================\n",
      "2025-11-05 14:43:20 - Configuration:\n",
      "2025-11-05 14:43:20 -   Epochs: 10000\n",
      "2025-11-05 14:43:20 -   Latent dim: 50\n",
      "2025-11-05 14:43:20 -   Co-adaptation: True\n",
      "2025-11-05 14:43:20 -   Lambda Fro: 0.04\n",
      "2025-11-05 14:43:20 - Building model...\n",
      "Building and fitting normalizers...\n",
      "Building and warm starting AEs...\n",
      "Building TBFM...\n",
      "BOOM! Dino DNA!\n",
      "2025-11-05 14:43:20 - \n",
      "Completed: Model Configuration - Baseline\n",
      "2025-11-05 14:43:20 - Duration: 00:00\n",
      "2025-11-05 14:43:20 - ================================================================================\n",
      "Building TBFM...\n",
      "BOOM! Dino DNA!\n",
      "2025-11-05 14:43:20 - \n",
      "Completed: Model Configuration - Baseline\n",
      "2025-11-05 14:43:20 - Duration: 00:00\n",
      "2025-11-05 14:43:20 - ================================================================================\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_BASELINE:\n",
    "    logger.start_phase(\"Model Configuration - Baseline\")\n",
    "\n",
    "    def cfg_base(cfg, dim):\n",
    "        cfg.ae.training.coadapt = BASELINE_CONFIG['coadapt']\n",
    "        cfg.ae.warm_start_is_identity = BASELINE_CONFIG['warm_start_is_identity']\n",
    "        cfg.tbfm.module.use_meta_learning = True\n",
    "        cfg.tbfm.module.num_bases = 12\n",
    "        cfg.tbfm.module.latent_dim = 64\n",
    "        cfg.latent_dim = dim\n",
    "        cfg.training.epochs = BASELINE_CONFIG['epochs']\n",
    "        cfg.normalizers.module._target_ = \"tbfm.normalizers.ScalerZscore\"\n",
    "        return cfg\n",
    "\n",
    "    cfg = cfg_base(cfg, dim=GLOBAL_CONFIG['latent_dim'])\n",
    "    cfg.tbfm.training.lambda_fro = GLOBAL_CONFIG['lambda_fro']\n",
    "\n",
    "    logger.info(f\"Configuration:\")\n",
    "    logger.info(f\"  Epochs: {cfg.training.epochs}\")\n",
    "    logger.info(f\"  Latent dim: {cfg.latent_dim}\")\n",
    "    logger.info(f\"  Co-adaptation: {cfg.ae.training.coadapt}\")\n",
    "    logger.info(f\"  Lambda Fro: {cfg.tbfm.training.lambda_fro}\")\n",
    "\n",
    "    logger.info(\"Building model...\")\n",
    "    ms = multisession.build_from_cfg(cfg, data_train, device=DEVICE)\n",
    "    model_optims = multisession.get_optims(cfg, ms)\n",
    "\n",
    "    logger.end_phase(\"Model Configuration - Baseline\")\n",
    "else:\n",
    "    logger.info(\"â­ï¸  Skipping Baseline model (TRAIN_BASELINE=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-05 14:43:20 - ================================================================================\n",
      "2025-11-05 14:43:20 - Starting: Baseline Model Training\n",
      "2025-11-05 14:43:20 - ================================================================================\n",
      "2025-11-05 14:43:21 - Epoch 0/10000 (0.0%) | Train Loss: 0.346039 | Test Loss: 0.553863 | Train RÂ²: 0.430523 | Test RÂ²: 0.148119 | Elapsed: 00:00 | ETA: --:--\n",
      "2025-11-05 14:43:21 -   â†’ New best model! Test RÂ²: 0.148119 (checkpointed)\n",
      "2025-11-05 14:43:21 - Saved best checkpoint to /home/danmuir/GitHub/py-tbfm/saved_models/Baseline_TBFMMultisession_best_1762382601.pt\n",
      "2025-11-05 14:43:21 - Epoch 0/10000 (0.0%) | Train Loss: 0.346039 | Test Loss: 0.553863 | Train RÂ²: 0.430523 | Test RÂ²: 0.148119 | Elapsed: 00:00 | ETA: --:--\n",
      "2025-11-05 14:43:21 -   â†’ New best model! Test RÂ²: 0.148119 (checkpointed)\n",
      "2025-11-05 14:43:21 - Saved best checkpoint to /home/danmuir/GitHub/py-tbfm/saved_models/Baseline_TBFMMultisession_best_1762382601.pt\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_BASELINE:\n",
    "    logger.start_training(cfg.training.epochs, \"Baseline Model Training\")\n",
    "\n",
    "    embeddings_stim, results = train_with_logging(\n",
    "        cfg,\n",
    "        ms,\n",
    "        data_train,\n",
    "        model_optims,\n",
    "        embeddings_rest,\n",
    "        data_test=data_test,\n",
    "        test_interval=GLOBAL_CONFIG['test_interval'],\n",
    "        epochs=cfg.training.epochs,\n",
    "        training_type=\"Baseline\",  # NEW: Specify training type for model naming\n",
    "        logger=logger,  # Pass logger for progress tracking\n",
    "        save_best_model=True  # Save best model based on test RÂ²\n",
    "    )\n",
    "\n",
    "    logger.end_training(\"Baseline Model Training\")\n",
    "\n",
    "    # Log final results\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"FINAL RESULTS - BASELINE\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"Overall Test RÂ²: {results['final_test_r2']:.6f}\")\n",
    "    logger.info(\"\\nPer-session Test RÂ²:\")\n",
    "    for session_id, r2 in results['final_test_r2s'].items():\n",
    "        logger.info(f\"  {session_id}: {r2:.6f}\")\n",
    "    logger.info(\"=\"*80)\n",
    "else:\n",
    "    logger.info(\"â­ï¸  Skipping Baseline training (TRAIN_BASELINE=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634f6575",
   "metadata": {},
   "source": [
    "### Two-Stage Sparsity Training\n",
    "\n",
    "Two-stage approach for sparsity-based compression:\n",
    "1. **Stage 1**: Train with identity AE + sparsity penalties â†’ learn which channels matter\n",
    "2. **Stage 2**: Train compressed AE using knowledge from Stage 1 â†’ task-informed compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-30 16:15:56 - ================================================================================\n",
      "2025-10-30 16:15:56 - Starting: Two-Stage Sparsity Training: Identity AE â†’ Compressed AE\n",
      "2025-10-30 16:15:56 - ================================================================================\n",
      "2025-10-30 16:15:56 - ðŸš€ STAGE 1: Training with Identity Autoencoder (no compression)\n",
      "2025-10-30 16:15:56 - This is functionally equivalent to vanilla TBFM but uses existing infrastructure\n",
      "2025-10-30 16:15:56 -   AE latent_dim: 74 (same as input - identity transform)\n",
      "2025-10-30 16:15:56 -   AE coadapt: False\n",
      "2025-10-30 16:15:56 -   AE identity init: True\n",
      "2025-10-30 16:15:56 -   Sparsity lambda: 0.05\n",
      "2025-10-30 16:15:56 -   Prediction sparsity lambda: 0.005\n",
      "2025-10-30 16:15:56 -   Epochs: 7000\n",
      "Building and fitting normalizers...\n",
      "Building and warm starting AEs...\n",
      "Building TBFM...\n",
      "BOOM! Dino DNA!\n",
      "2025-10-30 16:15:56 - Training TBFM for sparsity with Identity AE...\n",
      "2025-10-30 16:15:57 - Epoch 0/7000 (0.0%) | Train Loss: 1.769382 | Test Loss: 1.884843 | Train RÂ²: 0.389173 | Test RÂ²: 0.211422 | Elapsed: 00:00 | ETA: --:--\n",
      "2025-10-30 16:26:47 - Epoch 1000/7000 (14.3%) | Train Loss: 0.962958 | Test Loss: 1.758796 | Train RÂ²: 0.450468 | Test RÂ²: 0.267177 | Elapsed: 10:51 | ETA: 05:06\n",
      "2025-10-30 16:37:45 - Epoch 2000/7000 (28.6%) | Train Loss: 0.959151 | Test Loss: 1.744259 | Train RÂ²: 0.455200 | Test RÂ²: 0.273562 | Elapsed: 21:49 | ETA: 54:32\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_SPARSITY:\n",
    "    logger.start_training(SPARSITY_CONFIG['epochs'] * 2, \"Two-Stage Sparsity Training: Identity AE â†’ Compressed AE\")\n",
    "    \n",
    "    # STAGE 1: Train with Identity Autoencoder (equivalent to vanilla TBFM)\n",
    "    logger.info(\"ðŸš€ STAGE 1: Training with Identity Autoencoder (no compression)\")\n",
    "    logger.info(\"This is functionally equivalent to vanilla TBFM but uses existing infrastructure\")\n",
    "    \n",
    "    # Create configuration for identity autoencoder\n",
    "    cfg_identity = OmegaConf.create(OmegaConf.to_container(cfg, resolve=True))\n",
    "    \n",
    "    # Configure for identity transformation (no compression)  \n",
    "    cfg_identity.ae.training.coadapt = SPARSITY_CONFIG['coadapt']\n",
    "    cfg_identity.ae.warm_start_is_identity = True  # Start as identity\n",
    "    \n",
    "    # Get number of channels from existing batch sample\n",
    "    b = next(iter(data_train))\n",
    "    k0 = list(b.keys())[0]\n",
    "    num_channels = b[k0][0].shape[-1]  # Last dimension is channels (93)\n",
    "    cfg_identity.ae.module.latent_dim = num_channels  # TRUE input dimension (93 channels)\n",
    "    cfg_identity.training.epochs = (int) (SPARSITY_CONFIG['epochs'] * 0.7) # Allocate 70% of epochs to Stage 1\n",
    "    \n",
    "    # Add strong sparsity penalties for Stage 1\n",
    "    cfg_identity.training.lambda_sparse = SPARSITY_CONFIG.get('lambda_sparse', 0.05)\n",
    "    cfg_identity.training.lambda_pred_sparse = SPARSITY_CONFIG.get('lambda_pred_sparse', 0.005)\n",
    "    \n",
    "    logger.info(f\"  AE latent_dim: {cfg_identity.ae.module.latent_dim} (same as input - identity transform)\")\n",
    "    logger.info(f\"  AE coadapt: {cfg_identity.ae.training.coadapt}\")\n",
    "    logger.info(f\"  AE identity init: {cfg_identity.ae.warm_start_is_identity}\")\n",
    "    logger.info(f\"  Sparsity lambda: {cfg_identity.training.lambda_sparse}\")\n",
    "    logger.info(f\"  Prediction sparsity lambda: {cfg_identity.training.lambda_pred_sparse}\")\n",
    "    logger.info(f\"  Epochs: {cfg_identity.training.epochs}\")\n",
    "    \n",
    "    # Build identity model\n",
    "    ms_identity = multisession.build_from_cfg(cfg_identity, data_train, device=DEVICE)\n",
    "    model_optims_identity = multisession.get_optims(cfg_identity, ms_identity)\n",
    "    \n",
    "    # Apply memory optimizations before training\n",
    "    # optimize_memory()\n",
    "    \n",
    "    # Train Stage 1 for sparse TBFM\n",
    "    logger.info(\"Training TBFM for sparsity with Identity AE...\")\n",
    "    embeddings_stim_identity, identity_results = train_with_logging(\n",
    "        cfg_identity,\n",
    "        ms_identity,\n",
    "        data_train,\n",
    "        model_optims_identity,\n",
    "        embeddings_rest,\n",
    "        data_test=data_test,\n",
    "        epochs=cfg_identity.training.epochs,\n",
    "        test_interval=GLOBAL_CONFIG['test_interval'],\n",
    "        training_type=\"identity_sparsity\",\n",
    "        logger=logger,\n",
    "        save_best_model=False\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"âœ… Stage 1 Complete - Identity AE (vanilla TBFM equiv) Test RÂ²: {identity_results['final_test_r2']:.6f}\")\n",
    "    \n",
    "    # STAGE 2: Train compressed model using the sparse TBFM learned in Stage 1\n",
    "    logger.info(\"ðŸš€ STAGE 2: Training compressed model with learned sparse TBFM knowledge\")\n",
    "    \n",
    "    # Create configuration for compressed autoencoder\n",
    "    cfg_compressed = OmegaConf.create(OmegaConf.to_container(cfg, resolve=True))\n",
    "    cfg_compressed.ae.training.coadapt = True\n",
    "    cfg_compressed.ae.warm_start_is_identity = False  # Now use actual compression\n",
    "    cfg_compressed.ae.module.latent_dim = GLOBAL_CONFIG['latent_dim']  # Compressed dimension (e.g., 50)\n",
    "    cfg_compressed.training.epochs = (int) (SPARSITY_CONFIG['epochs'] * 0.3) # Remaining epochs for Stage 2\n",
    "    \n",
    "    # Reduce sparsity penalties for Stage 2 (focus on compression) but add reconstruction penalty\n",
    "    cfg_compressed.training.lambda_sparse = SPARSITY_CONFIG.get('lambda_sparse', 0.1) * 0\n",
    "    cfg_compressed.training.lambda_pred_sparse = SPARSITY_CONFIG.get('lambda_pred_sparse', 0.01) * 0\n",
    "    cfg_compressed.training.lambda_ae_recon = SPARSITY_CONFIG.get('lambda_sparsity_recon', 0.01)  # Add reconstruction penalty\n",
    "    \n",
    "    logger.info(f\"  Compressed AE latent_dim: {cfg_compressed.ae.module.latent_dim}\")\n",
    "    logger.info(f\"  Sparsity lambda: {cfg_compressed.training.lambda_sparse} (disabled)\")\n",
    "    logger.info(f\"  AE reconstruction lambda: {cfg_compressed.training.lambda_ae_recon}\")\n",
    "    logger.info(f\"  Epochs: {cfg_compressed.training.epochs}\")\n",
    "    \n",
    "    # Build compressed model\n",
    "    ms_compressed = multisession.build_from_cfg(cfg_compressed, data_train, device=DEVICE)\n",
    "    model_optims_compressed = multisession.get_optims(cfg_compressed, ms_compressed)\n",
    "    \n",
    "    # Transfer learned TBFM knowledge from identity model to compressed model\n",
    "    logger.info(\"Transferring learned sparse TBFM knowledge to compressed model...\")\n",
    "    with torch.no_grad():\n",
    "        for session_id in data_train.session_ids:\n",
    "            identity_tbfm = ms_identity.model.instances[session_id]\n",
    "            compressed_tbfm = ms_compressed.model.instances[session_id]\n",
    "            \n",
    "            # Copy TBFM basis generators (temporal patterns learned in Stage 1)\n",
    "            if hasattr(identity_tbfm, 'bases') and hasattr(compressed_tbfm, 'bases'):\n",
    "                compressed_tbfm.bases.load_state_dict(identity_tbfm.bases.state_dict())\n",
    "                logger.info(f\"  {session_id}: Transferred sparse TBFM basis generator\")\n",
    "            \n",
    "            # Copy other TBFM components that are compatible\n",
    "            if hasattr(identity_tbfm, 'norms') and hasattr(compressed_tbfm, 'norms'):\n",
    "                compressed_tbfm.norms.load_state_dict(identity_tbfm.norms.state_dict())\n",
    "    \n",
    "    # Train Stage 2: Compressed model\n",
    "    logger.info(\"Training compressed model with transferred sparse TBFM knowledge...\")\n",
    "    embeddings_stim_compressed, compressed_results = train_with_logging(\n",
    "        cfg_compressed,\n",
    "        ms_compressed,\n",
    "        data_train,\n",
    "        model_optims_compressed,\n",
    "        embeddings_rest,\n",
    "        data_test=data_test,\n",
    "        epochs=cfg_compressed.training.epochs,\n",
    "        test_interval=GLOBAL_CONFIG['test_interval'],\n",
    "        training_type=\"compressed_sparsity\",\n",
    "        logger=logger,\n",
    "        save_best_model=True\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"âœ… Stage 2 Complete - Compressed Model Test RÂ²: {compressed_results['final_test_r2']:.6f}\")\n",
    "    \n",
    "    # Combine results for analysis\n",
    "    results_corrected_sparsity = {\n",
    "        'stage1_identity': identity_results,\n",
    "        'stage2_compressed': compressed_results,\n",
    "        'final_test_r2': compressed_results['final_test_r2'],\n",
    "        'final_test_r2s': compressed_results.get('final_test_r2s', {}),\n",
    "        'identity_model': ms_identity,\n",
    "        'compressed_model': ms_compressed,\n",
    "        'embeddings_stim_compressed': embeddings_stim_compressed,\n",
    "    }\n",
    "    \n",
    "    logger.end_training(\"Two-Stage Sparsity Training\")\n",
    "    \n",
    "    # Log final results\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"TWO-STAGE SPARSITY RESULTS\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"Stage 1 (Identity AE - Sparse TBFM): {identity_results['final_test_r2']:.6f}\")\n",
    "    logger.info(f\"Stage 2 (Compressed AE): {compressed_results['final_test_r2']:.6f}\")\n",
    "    improvement = compressed_results['final_test_r2'] - identity_results['final_test_r2']\n",
    "    logger.info(f\"Compression Improvement: {improvement:+.6f}\")\n",
    "    \n",
    "    if 'final_test_r2s' in compressed_results:\n",
    "        logger.info(\"\\nPer-session Final RÂ² (Compressed):\")\n",
    "        for session_id, r2 in compressed_results['final_test_r2s'].items():\n",
    "            logger.info(f\"  {session_id}: {r2:.6f}\")\n",
    "    \n",
    "    logger.info(\"=\"*80)\n",
    "else:\n",
    "    logger.info(\"â­ï¸  Skipping Sparsity training (TRAIN_SPARSITY=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bacd998",
   "metadata": {},
   "source": [
    "### AE Reconstruction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2831a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-29 17:21:45 - â­ï¸  Skipping AE Recon training (TRAIN_AE_RECON=False)\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_AE_RECON:\n",
    "    logger.start_training(AE_RECON_CONFIG['epochs'], \"AE Reconstruction Model Training\")\n",
    "\n",
    "    # Build AE reconstruction model\n",
    "    cfg_ae_recon = OmegaConf.create(OmegaConf.to_container(cfg, resolve=True))\n",
    "    cfg_ae_recon.training.epochs = AE_RECON_CONFIG['epochs']\n",
    "    cfg_ae_recon.ae.training.coadapt = AE_RECON_CONFIG['coadapt']\n",
    "\n",
    "    ms_ae_recon = multisession.build_from_cfg(cfg_ae_recon, data_train, device=DEVICE)\n",
    "    model_optims_ae_recon = multisession.get_optims(cfg_ae_recon, ms_ae_recon)\n",
    "\n",
    "    # Train with ONLY AE reconstruction penalty (no spatial regularization)\n",
    "    embeddings_stim_ae_recon, results_ae_recon = train_with_spatial_ae_recon(\n",
    "        cfg_ae_recon,\n",
    "        ms_ae_recon,\n",
    "        data_train,\n",
    "        model_optims_ae_recon,\n",
    "        embeddings_rest,\n",
    "        data_test=data_test,\n",
    "        test_interval=GLOBAL_CONFIG['test_interval'],\n",
    "        epochs=cfg_ae_recon.training.epochs,\n",
    "        lambda_spatial_smooth=0.0,  # NO spatial smoothness\n",
    "        lambda_spatial_decoder=0.0,  # NO spatial decoder penalty\n",
    "        lambda_ae_recon=AE_RECON_CONFIG['lambda_ae_recon'],\n",
    "        training_type=\"AE_Recon\",\n",
    "        logger=logger\n",
    "    )\n",
    "\n",
    "    logger.end_training(\"AE Reconstruction Model Training\")\n",
    "\n",
    "    # Log results\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"AE RECONSTRUCTION MODEL RESULTS\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"Overall Test RÂ²: {results_ae_recon['final_test_r2']:.6f}\")\n",
    "    logger.info(\"\\nPer-session Test RÂ²:\")\n",
    "    for session_id, r2 in results_ae_recon['final_test_r2s'].items():\n",
    "        logger.info(f\"  {session_id}: {r2:.6f}\")\n",
    "    logger.info(\"=\"*80)\n",
    "else:\n",
    "    logger.info(\"â­ï¸  Skipping AE Recon training (TRAIN_AE_RECON=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209ddc87",
   "metadata": {},
   "source": [
    "## Results and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ebb761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-29 18:45:59 - \n",
      "================================================================================\n",
      "2025-10-29 18:45:59 - EXPERIMENT SUMMARY\n",
      "2025-10-29 18:45:59 - ================================================================================\n",
      "2025-10-29 18:45:59 -   âœ“ Baseline        - Standard TBFM with PCA-initialized AE\n",
      "2025-10-29 18:45:59 -   âœ— Spatial         - Spatial smoothness regularization\n",
      "2025-10-29 18:45:59 -   âœ— AE Recon        - AE reconstruction penalty only\n",
      "2025-10-29 18:45:59 -   âœ“ Sparsity        - Two-stage sparsity: Identity â†’ Compressed AE\n",
      "2025-10-29 18:45:59 - \n",
      "PERFORMANCE COMPARISON:\n",
      "2025-10-29 18:45:59 -   Baseline       : Test RÂ² = 0.556167\n",
      "2025-10-29 18:45:59 -   Sparsity       : Test RÂ² = 0.556167\n",
      "2025-10-29 18:45:59 - ================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Model comparison summary\n",
    "logger.info(\"\\n\" + \"=\"*80)\n",
    "logger.info(\"EXPERIMENT SUMMARY\")\n",
    "logger.info(\"=\"*80)\n",
    "\n",
    "# Check which models are available\n",
    "models_info = {\n",
    "    'Baseline': ('results', 'Standard TBFM with PCA-initialized AE'),\n",
    "    'Spatial': ('results_spatial', 'Spatial smoothness regularization'),\n",
    "    'AE Recon': ('results_ae_recon', 'AE reconstruction penalty only'),\n",
    "    'Sparsity': ('results_corrected_sparsity', 'Two-stage sparsity: Identity â†’ Compressed AE'),\n",
    "}\n",
    "\n",
    "available_models = []\n",
    "for name, (var_name, description) in models_info.items():\n",
    "    is_available = var_name in globals()\n",
    "    status = \"âœ“\" if is_available else \"âœ—\"\n",
    "    logger.info(f\"  {status} {name:15s} - {description}\")\n",
    "    if is_available:\n",
    "        available_models.append((name, var_name, globals()[var_name]))\n",
    "\n",
    "if available_models:\n",
    "    logger.info(\"\\nPERFORMANCE COMPARISON:\")\n",
    "    for name, var_name, results in available_models:\n",
    "        logger.info(f\"  {name:15s}: Test RÂ² = {results['final_test_r2']:.6f}\")\n",
    "\n",
    "logger.info(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47bae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training curves for available models\n",
    "if available_models:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    for name, var_name, results in available_models:\n",
    "        # Handle nested sparsity results structure\n",
    "        if name == 'Sparsity' and 'stage2_compressed' in results:\n",
    "            plot_results = results['stage2_compressed']\n",
    "        else:\n",
    "            plot_results = results\n",
    "            \n",
    "        if 'test_losses' in plot_results:\n",
    "            # Test loss curves\n",
    "            tx = [t[0] for t in plot_results['test_losses']]\n",
    "            tl = [t[1] for t in plot_results['test_losses']]\n",
    "            axes[0].plot(tx, tl, label=f\"{name}\", alpha=0.8, linewidth=2)\n",
    "            \n",
    "        if 'test_r2s' in plot_results:\n",
    "            # Test RÂ² curves\n",
    "            tx_r2 = [t[0] for t in plot_results['test_r2s']]\n",
    "            te = [t[1] for t in plot_results['test_r2s']]\n",
    "            axes[1].plot(tx_r2, te, label=f\"{name}\", alpha=0.8, linewidth=2)\n",
    "\n",
    "    axes[0].set_xlabel(\"Epoch\")\n",
    "    axes[0].set_ylabel(\"Test Loss\")\n",
    "    axes[0].set_title(\"Test Loss: All Models\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1].set_xlabel(\"Epoch\")\n",
    "    axes[1].set_ylabel(\"Test RÂ²\")\n",
    "    axes[1].set_title(\"Test RÂ²: All Models\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No trained models available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f0326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-29 18:44:08 - \n",
      "================================================================================\n",
      "2025-10-29 18:44:08 - SAVED MODELS\n",
      "2025-10-29 18:44:08 - ================================================================================\n",
      "2025-10-29 18:44:08 -   Baseline_TBFMMultisession_final_1761736616.pt                ( 1683.6 MB)\n",
      "2025-10-29 18:44:08 -   Baseline_TBFMMultisession_final_1761766970.pt                ( 1683.6 MB)\n",
      "2025-10-29 18:44:08 -   Baseline_TBFMMultisession_final_1761777099.pt                (  855.7 MB)\n",
      "2025-10-29 18:44:08 -   Baseline_TBFMMultisession_final_1761779027.pt                (  855.7 MB)\n",
      "2025-10-29 18:44:08 -   Baseline_TBFMMultisession_final_1761780807.pt                (  855.7 MB)\n",
      "2025-10-29 18:44:08 -   Baseline_TBFMMultisession_final_1761782949.pt                (  855.7 MB)\n",
      "2025-10-29 18:44:08 -   TBFMMultisession_best_1761722291.pt                          (    0.0 MB)\n",
      "2025-10-29 18:44:08 -   TBFMMultisession_final_1761688839.pt                         ( 1683.6 MB)\n",
      "2025-10-29 18:44:08 -   TBFMMultisession_final_1761689517.pt                         (    0.1 MB)\n",
      "2025-10-29 18:44:08 -   TBFMMultisession_final_1761711001.pt                         ( 1683.6 MB)\n",
      "2025-10-29 18:44:08 -   TBFMMultisession_final_1761712710.pt                         ( 1683.6 MB)\n",
      "2025-10-29 18:44:08 -   baseline_model_best.pt                                       ( 1683.6 MB)\n",
      "2025-10-29 18:44:08 -   baseline_model_best_5s.pt                                    ( 3956.1 MB)\n",
      "2025-10-29 18:44:08 -   compressed_sparsity_TBFMMultisession_final_1761735966.pt     ( 1683.6 MB)\n",
      "2025-10-29 18:44:08 -   compressed_sparsity_TBFMMultisession_final_1761768325.pt     ( 1683.6 MB)\n",
      "2025-10-29 18:44:08 -   compressed_sparsity_TBFMMultisession_final_1761776251.pt     ( 1683.6 MB)\n",
      "2025-10-29 18:44:08 -   compressed_sparsity_TBFMMultisession_final_1761779681.pt     (  855.7 MB)\n",
      "2025-10-29 18:44:08 -   compressed_sparsity_TBFMMultisession_final_1761781729.pt     (  855.7 MB)\n",
      "2025-10-29 18:44:08 -   compressed_sparsity_TBFMMultisession_final_1761783704.pt     (  855.7 MB)\n",
      "2025-10-29 18:44:08 -   identity_sparsity_TBFMMultisession_final_1761732723.pt       ( 1683.6 MB)\n",
      "2025-10-29 18:44:08 -   identity_sparsity_TBFMMultisession_final_1761767650.pt       ( 1683.6 MB)\n",
      "2025-10-29 18:44:08 -   identity_sparsity_TBFMMultisession_final_1761772990.pt       ( 1683.6 MB)\n",
      "2025-10-29 18:44:08 -   identity_sparsity_TBFMMultisession_final_1761777432.pt       (  855.7 MB)\n",
      "2025-10-29 18:44:08 -   identity_sparsity_TBFMMultisession_final_1761779355.pt       (  855.7 MB)\n",
      "2025-10-29 18:44:08 -   identity_sparsity_TBFMMultisession_final_1761781188.pt       (  855.6 MB)\n",
      "2025-10-29 18:44:08 -   identity_sparsity_TBFMMultisession_final_1761783179.pt       (  855.6 MB)\n",
      "2025-10-29 18:44:08 -   spatial_model_best.pt                                        (    0.3 MB)\n",
      "2025-10-29 18:44:08 -   spatial_model_best_5s.pt                                     (    0.7 MB)\n",
      "2025-10-29 18:44:08 - \n",
      "Total: 28 files, 33573.2 MB\n",
      "2025-10-29 18:44:08 - âœ… Models saved with training-type specific names!\n",
      "2025-10-29 18:44:08 - ================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check saved models\n",
    "logger.info(\"\\n\" + \"=\"*80)\n",
    "logger.info(\"SAVED MODELS\")\n",
    "logger.info(\"=\"*80)\n",
    "\n",
    "saved_models_dir = \"saved_models\"\n",
    "if os.path.exists(saved_models_dir):\n",
    "    files = [f for f in os.listdir(saved_models_dir) if f.endswith('.pt')]\n",
    "    files.sort()\n",
    "    \n",
    "    total_size_mb = 0\n",
    "    for f in files:\n",
    "        filepath = os.path.join(saved_models_dir, f)\n",
    "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "        total_size_mb += size_mb\n",
    "        logger.info(f\"  {f:<60} ({size_mb:>7.1f} MB)\")\n",
    "    \n",
    "    logger.info(f\"\\nTotal: {len(files)} files, {total_size_mb:.1f} MB\")\n",
    "    logger.info(\"âœ… Models saved with training-type specific names!\")\n",
    "else:\n",
    "    logger.info(\"No saved_models directory found\")\n",
    "\n",
    "logger.info(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd95bb",
   "metadata": {},
   "source": [
    "## Experiment Complete\n",
    "\n",
    "All training experiments completed successfully! \n",
    "\n",
    "**Key improvements in this streamlined version:**\n",
    "- ðŸ”„ **Modular design**: Training functions moved to separate `multisession_training.py` module\n",
    "- ðŸ“Š **Structured logging**: Comprehensive progress tracking with timestamps and ETA\n",
    "- ðŸ’¾ **Smart model management**: Training-type specific naming prevents conflicts\n",
    "- ðŸ§¹ **Automatic cleanup**: Only keeps final models, removes intermediate checkpoints\n",
    "- ðŸ“ˆ **Clear visualization**: Streamlined comparison plots\n",
    "\n",
    "Check the log files and saved models for detailed results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
