# @package _global_
# Normalizer configuration

normalizers:
  module:
    _target_: tbfm.normalizers.ScalerQuant

  training:
    coadapt: false   # If true, we will adapt in a supervised manner after PCA warm-up
    optim:
      lr: 1e-4
