# @package _global_
# Autoencoder configuration

ae:
  module:
    _target_: tbfm.ae.LinearChannelAE
    latent_dim: ${latent_dim}
    in_dim: 96
    use_bias: true

  should_warm_start: true
  warm_start_is_identity: false

  dispatcher:
    _target_: tbfm.ae.SessionDispatcherLinearAE
  
  sharing:
    is_shared: false
    lora_dim: 1

  training:
    coadapt: true # If true, we will adapt in a supervised manner after PCA warm-up
    ae_freeze_epoch: 5000    # Freeze AE after this epoch to prevent late-stage overfit
    lambda_ae_recon: 0.03     # Weight for AE reconstruction loss (0 = disabled)
    optim:
      lr: 1e-4
      eps: 1e-8
      weight_decay: 0.0
      amsgrad: true
