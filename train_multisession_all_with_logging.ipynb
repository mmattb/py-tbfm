{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "025dee1b-a9f9-41a6-87cf-169ffddf06bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'film' from 'tbfm' (/home/danmuir/GitHub/py-tbfm/tbfm/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtbfm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m film\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtbfm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multisession\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtbfm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'film' from 'tbfm' (/home/danmuir/GitHub/py-tbfm/tbfm/__init__.py)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from pathlib import Path\n",
    "from hydra import initialize_config_dir, compose\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tbfm import film\n",
    "from tbfm import multisession\n",
    "from tbfm import utils\n",
    "\n",
    "DATA_DIR = \"/home/danmuir/Projects/tbfm_multisession/data\"\n",
    "sys.path.append(DATA_DIR)\n",
    "from tbfm import dataset\n",
    "meta = dataset.load_meta(DATA_DIR)\n",
    "\n",
    "OUT_DIR = \"data\"\n",
    "EMBEDDING_REST_SUBDIR = \"embedding_rest\"\n",
    "\n",
    "conf_dir = Path(\"./conf\").resolve()\n",
    "\n",
    "with initialize_config_dir(config_dir=str(conf_dir), version_base=None):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "WINDOW_SIZE = cfg.data.trial_len\n",
    "NUM_HELD_OUT_SESSIONS = cfg.training.num_held_out_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gcsnlnq02w8",
   "metadata": {},
   "source": [
    "# Multisession TBFM Training with Multiple Approaches\n",
    "\n",
    "This notebook trains and compares multiple TBFM model variants:\n",
    "\n",
    "## Available Models\n",
    "1. **Baseline**: Standard TBFM with PCA-initialized autoencoder\n",
    "2. **Spatial Regularization**: Adds spatial smoothness penalties  \n",
    "3. **AE Reconstruction**: Adds autoencoder reconstruction penalty\n",
    "4. **Sparsity-Based**: Identity AE + sparsity penalties to identify important channels\n",
    "\n",
    "## How to Use This Notebook\n",
    "- **Run all cells sequentially** to train all models\n",
    "- **Or skip sections** to train only specific models (notebook handles missing data gracefully)\n",
    "- **Comparison cells automatically detect** which models are trained\n",
    "- All sections after \"Data Loading\" are independent except where noted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logging-setup",
   "metadata": {},
   "source": [
    "## Setup Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logger-class",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:45:06 - Logging to: logs/multisession_training_20251029_154506.log\n",
      "2025-10-29 15:45:06 - ================================================================================\n",
      "2025-10-29 15:45:06 - Device: cuda\n",
      "2025-10-29 15:45:06 - Window size: 184\n"
     ]
    }
   ],
   "source": [
    "class ExperimentLogger:\n",
    "    \"\"\"Logger that writes to both console and file with timing information.\"\"\"\n",
    "    \n",
    "    def __init__(self, log_dir=\"logs\", experiment_name=\"multisession_training\"):\n",
    "        self.log_dir = Path(log_dir)\n",
    "        self.log_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self.log_file = self.log_dir / f\"{experiment_name}_{timestamp}.log\"\n",
    "        \n",
    "        self.logger = logging.getLogger(experiment_name)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        self.logger.handlers = []\n",
    "        \n",
    "        fh = logging.FileHandler(self.log_file)\n",
    "        fh.setLevel(logging.INFO)\n",
    "        ch = logging.StreamHandler()\n",
    "        ch.setLevel(logging.INFO)\n",
    "        \n",
    "        formatter = logging.Formatter('%(asctime)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "        fh.setFormatter(formatter)\n",
    "        ch.setFormatter(formatter)\n",
    "        \n",
    "        self.logger.addHandler(fh)\n",
    "        self.logger.addHandler(ch)\n",
    "        \n",
    "        self.start_time = None\n",
    "        self.phase_start = None\n",
    "        \n",
    "        self.info(f\"Logging to: {self.log_file}\")\n",
    "        self.info(\"=\"*80)\n",
    "    \n",
    "    def info(self, message):\n",
    "        self.logger.info(message)\n",
    "    \n",
    "    def start_phase(self, phase_name):\n",
    "        self.phase_start = time.time()\n",
    "        self.info(f\"\\n{'='*80}\")\n",
    "        self.info(f\"Starting: {phase_name}\")\n",
    "        self.info(f\"{'='*80}\")\n",
    "    \n",
    "    def end_phase(self, phase_name):\n",
    "        if self.phase_start is not None:\n",
    "            duration = time.time() - self.phase_start\n",
    "            self.info(f\"\\nCompleted: {phase_name}\")\n",
    "            self.info(f\"Duration: {self.format_duration(duration)}\")\n",
    "            self.info(f\"{'='*80}\")\n",
    "            self.phase_start = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_duration(seconds):\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        secs = int(seconds % 60)\n",
    "        if hours > 0:\n",
    "            return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n",
    "        else:\n",
    "            return f\"{minutes:02d}:{secs:02d}\"\n",
    "    \n",
    "    def start_training(self, num_epochs, phase_name=\"Training\"):\n",
    "        self.training_start = time.time()\n",
    "        self.num_epochs = num_epochs\n",
    "        self.start_phase(phase_name)\n",
    "    \n",
    "    def log_progress(self, epoch, num_epochs, train_loss, test_loss=None, train_r2=None, test_r2=None):\n",
    "        elapsed = time.time() - self.training_start\n",
    "        epochs_done = epoch + 1\n",
    "        time_per_epoch = elapsed / epochs_done\n",
    "        eta_seconds = time_per_epoch * (num_epochs - epochs_done)\n",
    "        \n",
    "        progress_pct = (epochs_done / num_epochs) * 100\n",
    "        \n",
    "        msg = f\"Epoch {epoch}/{num_epochs} ({progress_pct:.1f}%) | \"\n",
    "        msg += f\"Train Loss: {train_loss:.6f}\"\n",
    "        \n",
    "        if test_loss is not None:\n",
    "            msg += f\" | Test Loss: {test_loss:.6f}\"\n",
    "        if train_r2 is not None:\n",
    "            msg += f\" | Train R¬≤: {train_r2:.6f}\"\n",
    "        if test_r2 is not None:\n",
    "            msg += f\" | Test R¬≤: {test_r2:.6f}\"\n",
    "        \n",
    "        msg += f\" | Elapsed: {self.format_duration(elapsed)}\"\n",
    "        msg += f\" | ETA: {self.format_duration(eta_seconds)}\"\n",
    "        \n",
    "        self.info(msg)\n",
    "    \n",
    "    def end_training(self, phase_name=\"Training\"):\n",
    "        total_time = time.time() - self.training_start\n",
    "        self.info(f\"\\n{phase_name} completed in {self.format_duration(total_time)}\")\n",
    "        self.end_phase(phase_name)\n",
    "\n",
    "# Initialize logger\n",
    "logger = ExperimentLogger(log_dir=\"logs\", experiment_name=\"multisession_training\")\n",
    "logger.info(f\"Device: {DEVICE}\")\n",
    "logger.info(f\"Window size: {WINDOW_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-wrapper",
   "metadata": {},
   "source": [
    "## Training Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-logging-wrapper",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:45:06 - Training helper function defined\n"
     ]
    }
   ],
   "source": [
    "import builtins\n",
    "\n",
    "original_train = multisession.train_from_cfg\n",
    "\n",
    "def train_with_logging(*args, **kwargs):\n",
    "    \"\"\"Wrapper for train_from_cfg that logs progress to logger and saves best model to disk.\n",
    "\n",
    "    This wrapper intercepts printed progress lines and keeps track of the best test R¬≤.\n",
    "    When a new best model is found it saves a checkpoint under `saved_models/` and\n",
    "    after training it also saves the final model state.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import time\n",
    "    import torch\n",
    "\n",
    "    original_print = builtins.print\n",
    "    \n",
    "    # Track best model\n",
    "    best_test_r2 = -1e99\n",
    "    best_model_state = None\n",
    "    best_embeddings_stim = None\n",
    "    test_r2_history = []\n",
    "    \n",
    "    # Extract model reference for checkpointing\n",
    "    cfg = args[0] if len(args) > 0 else kwargs.get('cfg')\n",
    "    model = args[1] if len(args) > 1 else kwargs.get('model')\n",
    "    save_best = kwargs.pop('save_best_model', True)\n",
    "    training_type = kwargs.pop('training_type', 'Unknown')  # NEW: training type for naming\n",
    "\n",
    "    def _ensure_saved_models_dir():\n",
    "        out_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        return out_dir\n",
    "\n",
    "    def logging_print(*print_args, **print_kwargs):\n",
    "        nonlocal best_test_r2, best_model_state, best_embeddings_stim\n",
    "        msg = ' '.join(map(str, print_args))\n",
    "        \n",
    "        if msg.startswith('----'):\n",
    "            parts = msg.split()\n",
    "            if len(parts) >= 5:\n",
    "                try:\n",
    "                    epoch = int(parts[1])\n",
    "                    train_loss = float(parts[2])\n",
    "                    test_loss = float(parts[3])\n",
    "                    train_r2 = float(parts[4])\n",
    "                    test_r2 = float(parts[5]) if len(parts) > 5 else None\n",
    "                    \n",
    "                    logger.log_progress(epoch, kwargs.get('epochs', 7001), train_loss, test_loss, train_r2, test_r2)\n",
    "                    \n",
    "                    # Track best model and save to disk when improved\n",
    "                    if save_best and test_r2 is not None:\n",
    "                        test_r2_history.append((epoch, test_r2))\n",
    "                        if test_r2 > best_test_r2:\n",
    "                            best_test_r2 = test_r2\n",
    "                            best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "                            logger.info(f\"  ‚Üí New best model! Test R¬≤: {best_test_r2:.6f}\")\n",
    "\n",
    "                            # Save checkpoint to disk with training type in name\n",
    "                            try:\n",
    "                                out_dir = _ensure_saved_models_dir()\n",
    "                                fname = os.path.join(out_dir, f\"{training_type}_{model.__class__.__name__}_best_{int(time.time())}.pt\")\n",
    "                                torch.save({\n",
    "                                    'model_state_dict': best_model_state,\n",
    "                                    'epoch': epoch,\n",
    "                                    'test_r2': best_test_r2,\n",
    "                                    'timestamp': time.time(),\n",
    "                                    'training_type': training_type,\n",
    "                                }, fname)\n",
    "                                logger.info(f\"Saved best checkpoint to {fname}\")\n",
    "                            except Exception as e:\n",
    "                                logger.warning(f\"Failed to save best checkpoint: {e}\")\n",
    "                    \n",
    "                    return\n",
    "                except (ValueError, IndexError):\n",
    "                    pass\n",
    "        \n",
    "        if msg.strip() and not msg.startswith('Building') and not msg.startswith('BOOM'):\n",
    "            logger.info(msg)\n",
    "        original_print(*print_args, **print_kwargs)\n",
    "    \n",
    "    builtins.print = logging_print\n",
    "    \n",
    "    try:\n",
    "        embeddings_stim, results = original_train(*args, **kwargs)\n",
    "        \n",
    "        # Restore best model\n",
    "        if save_best and best_model_state is not None:\n",
    "            logger.info(f\"Restoring best model (Test R¬≤: {best_test_r2:.6f})\")\n",
    "            device = model.device\n",
    "            model.load_state_dict({k: v.to(device) for k, v in best_model_state.items()})\n",
    "            # Update results with best model info\n",
    "            results['best_test_r2'] = best_test_r2\n",
    "            results['final_test_r2'] = best_test_r2  # Override with best\n",
    "\n",
    "        # Save final model to disk with training type in name\n",
    "        try:\n",
    "            out_dir = _ensure_saved_models_dir()\n",
    "            final_fname = os.path.join(out_dir, f\"{training_type}_{model.__class__.__name__}_final_{int(time.time())}.pt\")\n",
    "            model_cpu_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            torch.save({\n",
    "                'model_state_dict': model_cpu_state,\n",
    "                'results': results,\n",
    "                'timestamp': time.time(),\n",
    "                'training_type': training_type,\n",
    "            }, final_fname)\n",
    "            logger.info(f\"Saved final model to {final_fname}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to save final model: {e}\")\n",
    "\n",
    "        # Clean up intermediate checkpoint files of the same training type only\n",
    "        try:\n",
    "            cleanup_checkpoints(training_type=training_type, model_name_pattern=model.__class__.__name__, \n",
    "                              keep_final=True, keep_latest_best=False)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to cleanup checkpoints: {e}\")\n",
    "\n",
    "        return embeddings_stim, results\n",
    "    finally:\n",
    "        builtins.print = original_print\n",
    "\n",
    "logger.info(\"Training helper function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae468750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:45:06 - Checkpoint cleanup function defined\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "def cleanup_checkpoints(training_type=None, model_name_pattern=None, keep_final=True, keep_latest_best=False):\n",
    "    \"\"\"\n",
    "    Clean up checkpoint files after training completes.\n",
    "    \n",
    "    Args:\n",
    "        training_type: Training type to match (e.g., \"Baseline\", \"Spatial\", \"AE_Recon\", \"Sparsity\")\n",
    "                      If None, cleans all checkpoint files regardless of training type\n",
    "        model_name_pattern: Pattern to match model names (e.g., \"TBFMMultisession\")\n",
    "                           If None, cleans all checkpoint files\n",
    "        keep_final: If True, keeps final model files (*_final_*.pt)\n",
    "        keep_latest_best: If True, keeps the most recent best checkpoint\n",
    "    \"\"\"\n",
    "    saved_models_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "    if not os.path.exists(saved_models_dir):\n",
    "        return\n",
    "    \n",
    "    # Build pattern to match files\n",
    "    if training_type and model_name_pattern:\n",
    "        pattern = os.path.join(saved_models_dir, f\"{training_type}_{model_name_pattern}_*.pt\")\n",
    "    elif training_type:\n",
    "        pattern = os.path.join(saved_models_dir, f\"{training_type}_*.pt\")\n",
    "    elif model_name_pattern:\n",
    "        pattern = os.path.join(saved_models_dir, f\"*_{model_name_pattern}_*.pt\")\n",
    "    else:\n",
    "        pattern = os.path.join(saved_models_dir, \"*.pt\")\n",
    "    \n",
    "    checkpoint_files = glob.glob(pattern)\n",
    "    \n",
    "    files_to_delete = []\n",
    "    final_files = []\n",
    "    best_files = []\n",
    "    \n",
    "    # Categorize files\n",
    "    for filepath in checkpoint_files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        if \"_final_\" in filename:\n",
    "            final_files.append(filepath)\n",
    "        elif \"_best_\" in filename or \"_restored_best_\" in filename:\n",
    "            best_files.append(filepath)\n",
    "        else:\n",
    "            # Other checkpoint files\n",
    "            files_to_delete.append(filepath)\n",
    "    \n",
    "    # Sort best files by timestamp (filename contains Unix timestamp)\n",
    "    best_files.sort(key=lambda x: os.path.getmtime(x))\n",
    "    \n",
    "    # Determine what to delete\n",
    "    if not keep_final:\n",
    "        files_to_delete.extend(final_files)\n",
    "    \n",
    "    if not keep_latest_best:\n",
    "        files_to_delete.extend(best_files)\n",
    "    else:\n",
    "        # Keep only the most recent best file\n",
    "        files_to_delete.extend(best_files[:-1])\n",
    "    \n",
    "    # Delete files\n",
    "    deleted_count = 0\n",
    "    freed_mb = 0.0\n",
    "    \n",
    "    for filepath in files_to_delete:\n",
    "        try:\n",
    "            file_size = os.path.getsize(filepath) / (1024 * 1024)  # MB\n",
    "            os.remove(filepath)\n",
    "            filename = os.path.basename(filepath)\n",
    "            logger.info(f\"Deleted checkpoint: {filename}\")\n",
    "            deleted_count += 1\n",
    "            freed_mb += file_size\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to delete {filepath}: {e}\")\n",
    "    \n",
    "    if deleted_count > 0:\n",
    "        type_msg = f\"({training_type} only)\" if training_type else \"(all types)\"\n",
    "        logger.info(f\"‚úÖ Cleaned up {deleted_count} checkpoint files {type_msg} ({freed_mb:.1f} MB freed)\")\n",
    "    else:\n",
    "        logger.info(\"No checkpoint files to clean up\")\n",
    "\n",
    "logger.info(\"Checkpoint cleanup function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75648392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:45:06 - Deleted checkpoint: Baseline_TBFMMultisession_best_1761777698.pt\n",
      "2025-10-29 15:45:06 - Deleted checkpoint: Baseline_TBFMMultisession_best_1761777770.pt\n",
      "2025-10-29 15:45:06 - ‚úÖ Cleaned up 2 checkpoint files (all types) (0.0 MB freed)\n"
     ]
    }
   ],
   "source": [
    "# Test cleanup - clean up existing checkpoint files from TBFMMultisession training\n",
    "# This will keep only the final models and remove intermediate checkpoints\n",
    "cleanup_checkpoints(model_name_pattern=\"TBFMMultisession\", keep_final=True, keep_latest_best=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c05c6f",
   "metadata": {},
   "source": [
    "## Checkpoint Management Solution ‚úÖ\n",
    "\n",
    "**Problem**: Training functions were saving multiple checkpoint files (`_best_*.pt`) during training, but these intermediate files were not being cleaned up after training completed. This led to accumulated disk usage from old checkpoints.\n",
    "\n",
    "**Solution**: \n",
    "1. **Added `cleanup_checkpoints()` function** that automatically removes intermediate checkpoint files\n",
    "2. **Modified training functions** to call cleanup after training completes\n",
    "3. **Keeps important files**: Only deletes intermediate `_best_*` checkpoints, preserves `_final_*` models\n",
    "\n",
    "**What gets cleaned up:**\n",
    "- ‚ùå `ModelName_best_timestamp.pt` (intermediate checkpoints)\n",
    "- ‚ùå `ModelName_restored_best_timestamp.pt` (restored checkpoints) \n",
    "- ‚úÖ `ModelName_final_timestamp.pt` (final models - **KEPT**)\n",
    "\n",
    "**Modified functions:**\n",
    "- `train_with_logging()` - baseline training wrapper\n",
    "- `train_with_channel_sparsity()` - sparsity training function\n",
    "\n",
    "**Result**: Training now automatically cleans up old checkpoints when each model finishes training, keeping only the final trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b43a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model files in saved_models/:\n",
      "==================================================\n",
      "‚úÖ Baseline_TBFMMultisession_final_1761736616.pt      ( 1683.6 MB)\n",
      "‚úÖ Baseline_TBFMMultisession_final_1761766970.pt      ( 1683.6 MB)\n",
      "‚úÖ Baseline_TBFMMultisession_final_1761777099.pt      (  855.7 MB)\n",
      "‚úÖ TBFMMultisession_best_1761722291.pt                (    0.0 MB)\n",
      "‚úÖ TBFMMultisession_final_1761688839.pt               ( 1683.6 MB)\n",
      "‚úÖ TBFMMultisession_final_1761689517.pt               (    0.1 MB)\n",
      "‚úÖ TBFMMultisession_final_1761711001.pt               ( 1683.6 MB)\n",
      "‚úÖ TBFMMultisession_final_1761712710.pt               ( 1683.6 MB)\n",
      "‚úÖ baseline_model_best.pt                             ( 1683.6 MB)\n",
      "‚úÖ baseline_model_best_5s.pt                          ( 3956.1 MB)\n",
      "‚úÖ compressed_sparsity_TBFMMultisession_final_1761735966.pt ( 1683.6 MB)\n",
      "‚úÖ compressed_sparsity_TBFMMultisession_final_1761768325.pt ( 1683.6 MB)\n",
      "‚úÖ compressed_sparsity_TBFMMultisession_final_1761776251.pt ( 1683.6 MB)\n",
      "‚úÖ identity_sparsity_TBFMMultisession_final_1761732723.pt ( 1683.6 MB)\n",
      "‚úÖ identity_sparsity_TBFMMultisession_final_1761767650.pt ( 1683.6 MB)\n",
      "‚úÖ identity_sparsity_TBFMMultisession_final_1761772990.pt ( 1683.6 MB)\n",
      "‚úÖ identity_sparsity_TBFMMultisession_final_1761777432.pt (  855.7 MB)\n",
      "‚úÖ spatial_model_best.pt                              (    0.3 MB)\n",
      "‚úÖ spatial_model_best_5s.pt                           (    0.7 MB)\n",
      "==================================================\n",
      "Total: 19 files, 25872.1 MB\n",
      "\n",
      "üéØ Only final models are kept - intermediate checkpoints removed!\n"
     ]
    }
   ],
   "source": [
    "# Verify current checkpoint files - should only show final models now\n",
    "print(\"Current model files in saved_models/:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import os\n",
    "saved_models_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "if os.path.exists(saved_models_dir):\n",
    "    files = [f for f in os.listdir(saved_models_dir) if f.endswith('.pt')]\n",
    "    files.sort()\n",
    "    \n",
    "    total_size_mb = 0\n",
    "    for f in files:\n",
    "        filepath = os.path.join(saved_models_dir, f)\n",
    "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "        total_size_mb += size_mb\n",
    "        print(f\"‚úÖ {f:<50} ({size_mb:>7.1f} MB)\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total: {len(files)} files, {total_size_mb:.1f} MB\")\n",
    "    print(\"\\nüéØ Only final models are kept - intermediate checkpoints removed!\")\n",
    "else:\n",
    "    print(\"No saved_models directory found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cfa00a-55d2-44b7-ba16-d45b1bf3d780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:45:06 - \n",
      "================================================================================\n",
      "2025-10-29 15:45:06 - Starting: Data Loading\n",
      "2025-10-29 15:45:06 - ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:45:07 - Loaded 1 sessions\n",
      "2025-10-29 15:45:07 - Sessions: ['MonkeyG_20150914_Session1_S1']\n",
      "2025-10-29 15:45:07 - Training batch size: 31250\n",
      "2025-10-29 15:45:07 - Train batch shape: torch.Size([5000, 20, 93])\n",
      "2025-10-29 15:45:07 - Test batch shape: torch.Size([2500, 20, 93])\n",
      "2025-10-29 15:45:07 - \n",
      "Completed: Data Loading\n",
      "2025-10-29 15:45:07 - Duration: 00:00\n",
      "2025-10-29 15:45:07 - ================================================================================\n"
     ]
    }
   ],
   "source": [
    "logger.start_phase(\"Data Loading\")\n",
    "\n",
    "# held_in_session_ids = [\"MonkeyG_20150925_Session2_S1\", \"MonkeyG_20150918_Session1_M1\"]\n",
    "held_in_session_ids=[\n",
    "    \"MonkeyG_20150914_Session1_S1\",\n",
    "    # \"MonkeyG_20150915_Session3_S1\",\n",
    "    # \"MonkeyG_20150915_Session5_S1\",\n",
    "    # \"MonkeyG_20150916_Session4_S1\",\n",
    "    # \"MonkeyG_20150917_Session1_M1\",\n",
    "    # \"MonkeyG_20150917_Session1_S1\",\n",
    "    # \"MonkeyG_20150917_Session2_M1\",\n",
    "    # \"MonkeyG_20150917_Session2_S1\",\n",
    "    # \"MonkeyG_20150921_Session3_S1\",\n",
    "    # \"MonkeyG_20150921_Session5_S1\",\n",
    "    # \"MonkeyG_20150922_Session1_S1\",\n",
    "    # \"MonkeyG_20150922_Session2_S1\",\n",
    "    # \"MonkeyG_20150925_Session1_S1\",\n",
    "    # \"MonkeyG_20150925_Session2_S1\",\n",
    "    # \"MonkeyJ_20160426_Session2_S1\",\n",
    "    # \"MonkeyJ_20160426_Session3_S1\",\n",
    "    # \"MonkeyJ_20160428_Session3_S1\",\n",
    "    # \"MonkeyJ_20160429_Session1_S1\",\n",
    "    # \"MonkeyJ_20160502_Session1_S1\",\n",
    "    # \"MonkeyJ_20160624_Session3_S1\",\n",
    "    # \"MonkeyJ_20160625_Session4_S1\",\n",
    "    # \"MonkeyJ_20160625_Session5_S1\",\n",
    "    # \"MonkeyJ_20160627_Session1_S1\",\n",
    "    # \"MonkeyJ_20160630_Session3_S1\",\n",
    "    # \"MonkeyJ_20160702_Session2_S1\",\n",
    "]\n",
    "\n",
    "\n",
    "num_sessions = len(held_in_session_ids)\n",
    "MAX_BATCH_SIZE = 62500 // 2\n",
    "batch_size = (MAX_BATCH_SIZE // num_sessions) * num_sessions\n",
    "\n",
    "d, held_out_session_ids = multisession.load_stim_batched(\n",
    "    window_size=WINDOW_SIZE,\n",
    "    session_subdir=\"torchraw\",\n",
    "    data_dir=DATA_DIR,\n",
    "    unpack_stiminds=True,\n",
    "    held_in_session_ids=held_in_session_ids,\n",
    "    batch_size=batch_size,\n",
    "    num_held_out_sessions=NUM_HELD_OUT_SESSIONS,\n",
    ")\n",
    "data_train, data_test = d.train_test_split(5000, test_cut=2500)\n",
    "\n",
    "held_in_session_ids = data_train.session_ids\n",
    "embeddings_rest = multisession.load_rest_embeddings(held_in_session_ids, device=DEVICE)\n",
    "\n",
    "logger.info(f\"Loaded {len(held_in_session_ids)} sessions\")\n",
    "logger.info(f\"Sessions: {held_in_session_ids}\")\n",
    "logger.info(f\"Training batch size: {batch_size}\")\n",
    "\n",
    "b = next(iter(data_train))\n",
    "k0 = list(b.keys())[0]\n",
    "logger.info(f\"Train batch shape: {b[k0][0].shape}\")\n",
    "\n",
    "b = next(iter(data_test))\n",
    "logger.info(f\"Test batch shape: {b[k0][0].shape}\")\n",
    "\n",
    "logger.end_phase(\"Data Loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hk0go1hpp4l",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "\n",
    "Set which models to train and their hyperparameters here. Models with `TRAIN_*=False` will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dswmje2qymu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "Models to Train:\n",
      "  ‚úì Baseline (PCA AE)\n",
      "  ‚úó Spatial Regularization\n",
      "  ‚úó AE Reconstruction Penalty\n",
      "  ‚úì Sparsity-Based (Identity AE)\n",
      "\n",
      "Global Settings:\n",
      "  Latent dim: 50\n",
      "  Epochs: 5000\n",
      "  Test interval: 1000\n",
      "  Coadapt: True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRAINING CONFIGURATION - Edit this cell to control which models to train\n",
    "# ============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Model Selection - Set to False to skip training that model\n",
    "# -----------------------------------------------------------------------------\n",
    "TRAIN_BASELINE = True       # Standard TBFM with PCA-initialized AE\n",
    "TRAIN_SPATIAL = False       # Spatial regularization (was underperforming)\n",
    "TRAIN_AE_RECON = False       # AE reconstruction penalty only\n",
    "TRAIN_SPARSITY = True       # Identity AE + sparsity-driven approach\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Global Training Settings\n",
    "# -----------------------------------------------------------------------------\n",
    "GLOBAL_CONFIG = {\n",
    "    'latent_dim': 50,                # AE latent dimension\n",
    "    'epochs': 5000,                  # Training epochs (adjust for quick testing)\n",
    "    'test_interval': 1000,           # Evaluation frequency\n",
    "    'lambda_fro': 0.04,              # TBFM Frobenius regularization\n",
    "    'coadapt': True,                 # Whether AE trains with TBFM\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Baseline Model Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "BASELINE_CONFIG = {\n",
    "    'warm_start_is_identity': False,  # Use PCA initialization\n",
    "    'coadapt': GLOBAL_CONFIG['coadapt'],\n",
    "    'epochs': GLOBAL_CONFIG['epochs'],\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Spatial Regularization Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "SPATIAL_CONFIG = {\n",
    "    'use_spatial': True,\n",
    "    'lambda_spatial_smooth': 0.01,    # Spatial smoothness on reconstructions\n",
    "    'lambda_spatial_decoder': 0.002,  # Spatial smoothness on decoder weights\n",
    "    'spatial_penalty_freq': 10,       # Compute spatial penalties every N iters\n",
    "    'coadapt': GLOBAL_CONFIG['coadapt'],\n",
    "    'epochs': GLOBAL_CONFIG['epochs'],\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# AE Reconstruction Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "AE_RECON_CONFIG = {\n",
    "    'use_spatial': False,             # No spatial features\n",
    "    'lambda_ae_recon': 0.05,          # AE reconstruction penalty weight\n",
    "    'coadapt': GLOBAL_CONFIG['coadapt'],\n",
    "    'epochs': GLOBAL_CONFIG['epochs'],\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Sparsity-Based Configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "SPARSITY_CONFIG = {\n",
    "    'warm_start_is_identity': True,   # Start with identity AE (no compression)\n",
    "    'coadapt': False,                 # Freeze AE during Stage 1\n",
    "    'lambda_channel_sparsity': 0.005, # L1 penalty on channel activations\n",
    "    'lambda_sparsity_recon': 0.05,    # Sparsity-weighted reconstruction penalty\n",
    "    'epochs': GLOBAL_CONFIG['epochs'],\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Print Configuration Summary\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nModels to Train:\")\n",
    "print(f\"  {'‚úì' if TRAIN_BASELINE else '‚úó'} Baseline (PCA AE)\")\n",
    "print(f\"  {'‚úì' if TRAIN_SPATIAL else '‚úó'} Spatial Regularization\")\n",
    "print(f\"  {'‚úì' if TRAIN_AE_RECON else '‚úó'} AE Reconstruction Penalty\")\n",
    "print(f\"  {'‚úì' if TRAIN_SPARSITY else '‚úó'} Sparsity-Based (Identity AE)\")\n",
    "\n",
    "print(f\"\\nGlobal Settings:\")\n",
    "print(f\"  Latent dim: {GLOBAL_CONFIG['latent_dim']}\")\n",
    "print(f\"  Epochs: {GLOBAL_CONFIG['epochs']}\")\n",
    "print(f\"  Test interval: {GLOBAL_CONFIG['test_interval']}\")\n",
    "print(f\"  Coadapt: {GLOBAL_CONFIG['coadapt']}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## Configure and Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5850629-43ba-4d67-9fa5-037ab4861ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:45:07 - \n",
      "================================================================================\n",
      "2025-10-29 15:45:07 - Starting: Model Configuration - Baseline\n",
      "2025-10-29 15:45:07 - ================================================================================\n",
      "2025-10-29 15:45:07 - Configuration:\n",
      "2025-10-29 15:45:07 -   Epochs: 5000\n",
      "2025-10-29 15:45:07 -   Latent dim: 50\n",
      "2025-10-29 15:45:07 -   Co-adaptation: True\n",
      "2025-10-29 15:45:07 -   Lambda Fro: 0.04\n",
      "2025-10-29 15:45:07 - Building model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building and fitting normalizers...\n",
      "Building and warm starting AEs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:45:07 - \n",
      "Completed: Model Configuration - Baseline\n",
      "2025-10-29 15:45:07 - Duration: 00:00\n",
      "2025-10-29 15:45:07 - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building TBFM...\n",
      "BOOM! Dino DNA!\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_BASELINE:\n",
    "    logger.start_phase(\"Model Configuration - Baseline\")\n",
    "\n",
    "    def cfg_base(cfg, dim):\n",
    "        cfg.ae.training.coadapt = BASELINE_CONFIG['coadapt']\n",
    "        cfg.ae.warm_start_is_identity = BASELINE_CONFIG['warm_start_is_identity']\n",
    "        cfg.tbfm.module.use_film_bases = False\n",
    "        cfg.tbfm.module.num_bases = 12\n",
    "        cfg.tbfm.module.latent_dim = 64\n",
    "        cfg.latent_dim = dim\n",
    "        cfg.training.epochs = BASELINE_CONFIG['epochs']\n",
    "        cfg.normalizers.module._target_ = \"tbfm.normalizers.ScalerZscore\"\n",
    "        return cfg\n",
    "\n",
    "    cfg = cfg_base(cfg, dim=GLOBAL_CONFIG['latent_dim'])\n",
    "    cfg.tbfm.training.lambda_fro = GLOBAL_CONFIG['lambda_fro']\n",
    "\n",
    "    logger.info(f\"Configuration:\")\n",
    "    logger.info(f\"  Epochs: {cfg.training.epochs}\")\n",
    "    logger.info(f\"  Latent dim: {cfg.latent_dim}\")\n",
    "    logger.info(f\"  Co-adaptation: {cfg.ae.training.coadapt}\")\n",
    "    logger.info(f\"  Lambda Fro: {cfg.tbfm.training.lambda_fro}\")\n",
    "\n",
    "    logger.info(\"Building model...\")\n",
    "    ms = multisession.build_from_cfg(cfg, data_train, device=DEVICE)\n",
    "    model_optims = multisession.get_optims(cfg, ms)\n",
    "\n",
    "    logger.end_phase(\"Model Configuration - Baseline\")\n",
    "else:\n",
    "    logger.info(\"‚è≠Ô∏è  Skipping Baseline model (TRAIN_BASELINE=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ecfcd0-1204-4515-915a-c9fc43ebeec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:45:07 - \n",
      "================================================================================\n",
      "2025-10-29 15:45:07 - Starting: Baseline Model Training\n",
      "2025-10-29 15:45:07 - ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:45:07 - Epoch 0/5000 (0.0%) | Train Loss: 1.222797 | Test Loss: 0.228147 | Train R¬≤: 0.371025 | Test R¬≤: 0.370803 | Elapsed: 00:00 | ETA: 08:20\n",
      "2025-10-29 15:46:17 - Epoch 1000/5000 (20.0%) | Train Loss: 0.511797 | Test Loss: 0.171010 | Train R¬≤: 0.526792 | Test R¬≤: 0.527594 | Elapsed: 01:09 | ETA: 04:37\n",
      "2025-10-29 15:47:33 - Epoch 2000/5000 (40.0%) | Train Loss: 0.446897 | Test Loss: 0.168466 | Train R¬≤: 0.594049 | Test R¬≤: 0.534565 | Elapsed: 02:25 | ETA: 03:38\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAIN_BASELINE:\n\u001b[1;32m      2\u001b[0m     logger\u001b[38;5;241m.\u001b[39mstart_training(cfg\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;241m.\u001b[39mepochs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline Model Training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     embeddings_stim, results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_with_logging\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_optims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings_rest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGLOBAL_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_interval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBaseline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# NEW: Specify training type for model naming\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     logger\u001b[38;5;241m.\u001b[39mend_training(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline Model Training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Log final results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 85\u001b[0m, in \u001b[0;36mtrain_with_logging\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m builtins\u001b[38;5;241m.\u001b[39mprint \u001b[38;5;241m=\u001b[39m logging_print\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     embeddings_stim, results \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_train\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Restore best model\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_best \u001b[38;5;129;01mand\u001b[39;00m best_model_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/tbfm/multisession.py:234\u001b[0m, in \u001b[0;36mtrain_from_cfg\u001b[0;34m(cfg, model, data_train, model_optims, embeddings_rest, data_test, inner_steps, epochs, test_interval, support_size, embed_stim_lr, embed_stim_weight_decay, device, grad_clip, alternating_updates, bw_steps_per_bg_step, model_save_path)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eidx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    233\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 234\u001b[0m     iter_train, _data_train \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43miter_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# split into support/query\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     support, query \u001b[38;5;241m=\u001b[39m split_support_query_sessions(\n\u001b[1;32m    240\u001b[0m         _data_train,\n\u001b[1;32m    241\u001b[0m         support_size\u001b[38;5;241m=\u001b[39msupport_size,\n\u001b[1;32m    242\u001b[0m     )\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/tbfm/utils.py:292\u001b[0m, in \u001b[0;36miter_loader\u001b[0;34m(iterator, loader, device)\u001b[0m\n\u001b[1;32m    290\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(loader)\n\u001b[1;32m    291\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m--> 292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m iterator, \u001b[43mmove_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/tbfm/utils.py:278\u001b[0m, in \u001b[0;36mmove_batch\u001b[0;34m(batch, device)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmove_batch\u001b[39m(batch, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 278\u001b[0m         batch, streams \u001b[38;5;241m=\u001b[39m \u001b[43masync_copy_sessions_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m         wait_streams(streams)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/tbfm/utils.py:263\u001b[0m, in \u001b[0;36masync_copy_sessions_to_device\u001b[0;34m(sessions, device)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mstream(s):\n\u001b[0;32m--> 263\u001b[0m         d_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_to_dev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m         gpu_dict[sid] \u001b[38;5;241m=\u001b[39m d_gpu\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gpu_dict, streams\n",
      "File \u001b[0;32m~/GitHub/py-tbfm/tbfm/utils.py:263\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mstream(s):\n\u001b[0;32m--> 263\u001b[0m         d_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_to_dev(\u001b[43mdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m dd \u001b[38;5;129;01min\u001b[39;00m d)\n\u001b[1;32m    264\u001b[0m         gpu_dict[sid] \u001b[38;5;241m=\u001b[39m d_gpu\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gpu_dict, streams\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if TRAIN_BASELINE:\n",
    "    logger.start_training(cfg.training.epochs, \"Baseline Model Training\")\n",
    "\n",
    "    embeddings_stim, results = train_with_logging(\n",
    "        cfg,\n",
    "        ms,\n",
    "        data_train,\n",
    "        model_optims,\n",
    "        embeddings_rest,\n",
    "        data_test=data_test,\n",
    "        test_interval=GLOBAL_CONFIG['test_interval'],\n",
    "        epochs=cfg.training.epochs,\n",
    "        training_type=\"Baseline\",  # NEW: Specify training type for model naming\n",
    "        save_best_model=False\n",
    "    )\n",
    "\n",
    "    logger.end_training(\"Baseline Model Training\")\n",
    "\n",
    "    # Log final results\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"FINAL RESULTS - BASELINE\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"Overall Test R¬≤: {results['final_test_r2']:.6f}\")\n",
    "    logger.info(\"\\nPer-session Test R¬≤:\")\n",
    "    for session_id, r2 in results['final_test_r2s'].items():\n",
    "        logger.info(f\"  {session_id}: {r2:.6f}\")\n",
    "    logger.info(\"=\"*80)\n",
    "else:\n",
    "    logger.info(\"‚è≠Ô∏è  Skipping Baseline training (already skipped in config cell)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tsbfzunedz",
   "metadata": {},
   "source": [
    "## Spatial Regularization Comparison\n",
    "\n",
    "Now we'll train a model with spatial regularization and compare it to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6p50bspapr3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:23 - ‚è≠Ô∏è  Skipping Spatial model (TRAIN_SPATIAL=False)\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_SPATIAL:\n",
    "    logger.start_phase(\"Loading Spatial Structures\")\n",
    "\n",
    "    # Import spatial utilities\n",
    "    sys.path.append(\"/home/danmuir\")\n",
    "    from utils import get_preprocess_info\n",
    "\n",
    "    # Load spatial structures for each session\n",
    "    spatial_structures = {}\n",
    "    for session_id in held_in_session_ids:\n",
    "        logger.info(f\"Loading spatial structure for {session_id}\")\n",
    "        (\n",
    "            preprocess,\n",
    "            ch_from_orig,\n",
    "            ch_to_orig,\n",
    "            node_position_orig,  # Dict[int, tuple]: node_id -> (x, y)\n",
    "            node_id_orig,\n",
    "            ch_from_after,\n",
    "            ch_to_after,\n",
    "        ) = get_preprocess_info(session_id, subdir=DATA_DIR)\n",
    "\n",
    "        # Store for later use\n",
    "        spatial_structures[session_id] = {\n",
    "            'node_position': node_position_orig,\n",
    "            'node_position_after': preprocess.node_position,\n",
    "            'mask_indices': list(preprocess.node_position.keys()),\n",
    "            'num_channels': len(preprocess.node_position)\n",
    "        }\n",
    "\n",
    "        logger.info(f\"  {session_id}: {len(node_position_orig)} total electrodes, \"\n",
    "                    f\"{len(preprocess.node_position)} valid electrodes\")\n",
    "\n",
    "    logger.end_phase(\"Loading Spatial Structures\")\n",
    "else:\n",
    "    logger.info(\"‚è≠Ô∏è  Skipping Spatial model (TRAIN_SPATIAL=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t05ajqzs1jq",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:24 - ‚è≠Ô∏è  Skipping Spatial model build (already skipped)\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_SPATIAL:\n",
    "    logger.start_phase(\"Building Model with Spatial Regularization\")\n",
    "\n",
    "    # Build a new model with spatial support enabled\n",
    "    cfg_spatial = OmegaConf.create(OmegaConf.to_container(cfg, resolve=True))\n",
    "    cfg_spatial.ae.module.use_spatial = SPATIAL_CONFIG['use_spatial']\n",
    "    cfg_spatial.training.epochs = SPATIAL_CONFIG['epochs']\n",
    "    cfg_spatial.ae.training.coadapt = SPATIAL_CONFIG['coadapt']\n",
    "\n",
    "    logger.info(\"Building spatial model...\")\n",
    "    ms_spatial = multisession.build_from_cfg(cfg_spatial, data_train, device=DEVICE)\n",
    "\n",
    "    # Register spatial structures for each session's autoencoder\n",
    "    logger.info(\"Registering spatial structures...\")\n",
    "    for session_id in held_in_session_ids:\n",
    "        ae_instance = ms_spatial.ae.instances[session_id]\n",
    "        spatial_info = spatial_structures[session_id]\n",
    "        \n",
    "        ae_instance.register_spatial_structure(\n",
    "            node_position=spatial_info['node_position'],\n",
    "            mask_indices=spatial_info['mask_indices']\n",
    "        )\n",
    "        logger.info(f\"  Registered spatial structure for {session_id}\")\n",
    "\n",
    "    model_optims_spatial = multisession.get_optims(cfg_spatial, ms_spatial)\n",
    "\n",
    "    logger.end_phase(\"Building Model with Spatial Regularization\")\n",
    "else:\n",
    "    logger.info(\"‚è≠Ô∏è  Skipping Spatial model build (already skipped)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z0vmzmzasa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:24 - \n",
      "================================================================================\n",
      "2025-10-29 13:28:24 - Starting: Creating Spatial Training Function with AE Reconstruction Penalty\n",
      "2025-10-29 13:28:24 - ================================================================================\n",
      "2025-10-29 13:28:24 - \n",
      "Completed: Creating Spatial Training Function with AE Reconstruction Penalty\n",
      "2025-10-29 13:28:24 - Duration: 00:00\n",
      "2025-10-29 13:28:24 - ================================================================================\n"
     ]
    }
   ],
   "source": [
    "logger.start_phase(\"Creating Spatial Training Function with AE Reconstruction Penalty\")\n",
    "\n",
    "# Create a modified training function that adds spatial regularization + AE reconstruction penalty\n",
    "import torch.nn as nn\n",
    "from tbfm.multisession import split_support_query_sessions, r2_score\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def train_from_cfg_spatial_ae_recon(\n",
    "    cfg,\n",
    "    model,\n",
    "    data_train,\n",
    "    model_optims,\n",
    "    embeddings_rest,\n",
    "    data_test=None,\n",
    "    inner_steps=None,\n",
    "    epochs=10000,\n",
    "    test_interval=None,\n",
    "    support_size=300,\n",
    "    embed_stim_lr=None,\n",
    "    embed_stim_weight_decay=None,\n",
    "    device=\"cuda\",\n",
    "    grad_clip=None,\n",
    "    alternating_updates=True,\n",
    "    bw_steps_per_bg_step=None,\n",
    "    model_save_path=None,\n",
    "    lambda_spatial_smooth=0.05,  # weight for spatial smoothness penalty\n",
    "    lambda_spatial_decoder=0.01,  # weight for decoder spatial penalty\n",
    "    lambda_ae_recon=0.01,  # NEW: weight for autoencoder reconstruction penalty L_2(dec(enc(x)), x)\n",
    "    spatial_penalty_freq=10,  # compute spatial penalties every N iterations (saves ~50% time)\n",
    "    save_best_model=True,  # save best model during training\n",
    "    training_type=\"Custom\",  # NEW: training type for model naming\n",
    "):\n",
    "    \"\"\"\n",
    "    Modified training with spatial regularization + AE reconstruction penalty.\n",
    "    \n",
    "    The AE reconstruction penalty penalizes lossy conversions through the encoder-decoder bottleneck:\n",
    "        L_ae_recon = || dec(enc(x)) - x ||_2^2\n",
    "    \n",
    "    This encourages the autoencoder to preserve information through the latent bottleneck.\n",
    "    \n",
    "    Performance optimization: Set spatial_penalty_freq > 1 to compute spatial\n",
    "    penalties less frequently (e.g., every 10 iterations instead of every iteration).\n",
    "    This provides significant speedup (~50% faster) with minimal impact on final performance.\n",
    "    \"\"\"\n",
    "    # Same setup as original\n",
    "    test_interval = test_interval or cfg.training.test_interval\n",
    "    embed_stim_lr = embed_stim_lr or cfg.film.training.optim.lr\n",
    "    embed_stim_weight_decay = embed_stim_weight_decay or cfg.film.training.optim.weight_decay\n",
    "    inner_steps = inner_steps or cfg.film.training.inner_steps\n",
    "    use_film = cfg.tbfm.module.use_film_bases\n",
    "    bw_steps_per_bg_step = bw_steps_per_bg_step or cfg.training.bw_steps_per_bg_step\n",
    "    grad_clip = grad_clip or cfg.training.grad_clip or 10.0\n",
    "    epochs = epochs or cfg.training.epochs\n",
    "    support_size = support_size or cfg.film.training.support_size\n",
    "    device = model.device\n",
    "\n",
    "    def _ensure_saved_models_dir():\n",
    "        out_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        return out_dir\n",
    "\n",
    "    embeddings_stim = None\n",
    "    iter_train = iter(data_train)\n",
    "\n",
    "    train_losses = []\n",
    "    train_r2s = []\n",
    "    test_losses = []\n",
    "    test_r2s = []\n",
    "    spatial_smooth_losses = []\n",
    "    spatial_decoder_losses = []\n",
    "    ae_recon_losses = []  # NEW: track AE reconstruction losses\n",
    "    best_test_r2 = -1e99\n",
    "    best_model_state = None\n",
    "    best_embeddings_stim = None\n",
    "\n",
    "    for eidx in range(epochs):\n",
    "        model.train()\n",
    "        iter_train, _data_train = utils.iter_loader(iter_train, data_train, device=device)\n",
    "\n",
    "        support, query = split_support_query_sessions(_data_train, support_size=support_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_query = {sid: d[2] for sid, d in query.items()}\n",
    "            y_query = model.norms(y_query)\n",
    "\n",
    "        if use_film:\n",
    "            model.eval()\n",
    "            embeddings_stim = film.inner_update_stopgrad(\n",
    "                model, support, embeddings_rest, inner_steps=inner_steps,\n",
    "                lr=embed_stim_lr, weight_decay=embed_stim_weight_decay,\n",
    "            )\n",
    "            model.train()\n",
    "\n",
    "        model_optims.zero_grad(set_to_none=True)\n",
    "\n",
    "        yhat_query = model(query, embeddings_rest=embeddings_rest, embeddings_stim=embeddings_stim)\n",
    "\n",
    "        losses = {}\n",
    "        r2_trains = []\n",
    "        spatial_smooth_total = 0.0\n",
    "        spatial_decoder_total = 0.0\n",
    "\n",
    "        # NEW: Only compute spatial penalties every N iterations for speedup\n",
    "        compute_spatial = (eidx % spatial_penalty_freq) == 0\n",
    "\n",
    "        for sid, y in y_query.items():\n",
    "            _loss = nn.MSELoss()(yhat_query[sid], y)\n",
    "            losses[sid] = _loss\n",
    "\n",
    "            # NEW: Add spatial smoothness penalty on reconstructions (if enabled this iteration)\n",
    "            if compute_spatial:\n",
    "                ae_instance = model.ae.instances[sid]\n",
    "                if hasattr(ae_instance, 'use_spatial') and ae_instance.use_spatial:\n",
    "                    # Spatial smoothness on reconstructions\n",
    "                    yhat_flat = yhat_query[sid].flatten(0, 1)  # (B*T, C)\n",
    "                    smooth_penalty = ae_instance.spatial_smoothness_penalty(yhat_flat, reduction='mean')\n",
    "                    spatial_smooth_total += smooth_penalty\n",
    "\n",
    "                    # Spatial decoder penalty\n",
    "                    mask = list(range(yhat_query[sid].shape[-1]))\n",
    "                    decoder_penalty = ae_instance.spatial_decoder_penalty(mask)\n",
    "                    spatial_decoder_total += decoder_penalty\n",
    "\n",
    "            r2_train = r2_score(\n",
    "                yhat_query[sid].permute(0, 2, 1).flatten(end_dim=1),\n",
    "                y.permute(0, 2, 1).flatten(end_dim=1),\n",
    "            )\n",
    "            r2_trains.append(r2_train.item())\n",
    "\n",
    "        # Compute reconstruction loss (MSE only)\n",
    "        mse_only = sum(losses.values()) / len(y_query)\n",
    "\n",
    "        # Build total loss\n",
    "        loss = mse_only\n",
    "\n",
    "        # Add TBFM regularization\n",
    "        tbfm_regs = model.model.get_weighting_reg()\n",
    "        loss = loss + cfg.tbfm.training.lambda_fro * sum(tbfm_regs.values()) / len(y_query)\n",
    "\n",
    "        tbfm_regs_ortho = model.model.get_basis_rms_reg()\n",
    "        loss = loss + cfg.tbfm.training.lambda_ortho * sum(tbfm_regs_ortho.values()) / len(y_query)\n",
    "\n",
    "        # Add AE reconstruction penalty (if requested)\n",
    "        ae_loss_total = 0.0\n",
    "        if lambda_ae_recon > 0:\n",
    "            for sid, y in y_query.items():\n",
    "                ae_instance = model.ae.instances[sid]\n",
    "                y_flat = y.flatten(0, 1)\n",
    "                y_recon = ae_instance.reconstruct(y_flat, mask=list(range(y.shape[-1])))\n",
    "                ae_loss = nn.MSELoss()(y_recon, y_flat)\n",
    "                ae_loss_total += ae_loss\n",
    "            ae_loss_total = ae_loss_total / len(y_query)\n",
    "            loss = loss + lambda_ae_recon * ae_loss_total\n",
    "        \n",
    "        ae_recon_losses.append((eidx, ae_loss_total.item() if isinstance(ae_loss_total, torch.Tensor) else 0.0))\n",
    "\n",
    "        # Add spatial regularization (if computed this iteration)\n",
    "        if compute_spatial and spatial_smooth_total > 0:\n",
    "            loss = loss + lambda_spatial_smooth * (spatial_smooth_total / len(y_query))\n",
    "            loss = loss + lambda_spatial_decoder * (spatial_decoder_total / len(y_query))\n",
    "            spatial_smooth_losses.append((eidx, spatial_smooth_total.item() / len(y_query)))\n",
    "            spatial_decoder_losses.append((eidx, spatial_decoder_total.item() / len(y_query)))\n",
    "\n",
    "        # Log losses\n",
    "        train_losses.append((eidx, mse_only.item()))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if grad_clip is not None:\n",
    "            model_optims.clip_grad(value=grad_clip)\n",
    "\n",
    "        if alternating_updates:\n",
    "            update_basis_gen = (eidx % bw_steps_per_bg_step) == 0 or eidx < 200\n",
    "            if update_basis_gen:\n",
    "                model_optims.step()\n",
    "            else:\n",
    "                model_optims.step(skip=[\"bg\", \"film\"])\n",
    "        else:\n",
    "            model_optims.step()\n",
    "\n",
    "        # Testing\n",
    "        if data_test is not None and (eidx % test_interval) == 0:\n",
    "            train_r2s.append((eidx, sum(r2_trains) / len(y_query)))\n",
    "\n",
    "            model_optims.zero_grad(set_to_none=True)\n",
    "            model.eval()\n",
    "\n",
    "            test_r2s_session = {}\n",
    "            with torch.no_grad():\n",
    "                iter_test = iter(data_test)\n",
    "                iter_test, _data_test = utils.iter_loader(iter_test, data_test, device=device)\n",
    "\n",
    "                y_test = {sid: d[2] for sid, d in _data_test.items()}\n",
    "                y_test = model.norms(y_test)\n",
    "\n",
    "                yhat_test = model(_data_test, embeddings_rest=embeddings_rest, embeddings_stim=embeddings_stim)\n",
    "\n",
    "                test_losses_session = {}\n",
    "                for sid, y in y_test.items():\n",
    "                    _loss = nn.MSELoss()(yhat_test[sid], y)\n",
    "                    test_losses_session[sid] = _loss\n",
    "\n",
    "                    r2_test = r2_score(\n",
    "                        yhat_test[sid].permute(0, 2, 1).flatten(end_dim=1),\n",
    "                        y.permute(0, 2, 1).flatten(end_dim=1),\n",
    "                    )\n",
    "                    test_r2s_session[sid] = r2_test.item()\n",
    "\n",
    "                test_loss = sum(test_losses_session.values()) / len(y_test)\n",
    "                test_r2 = sum(test_r2s_session.values()) / len(y_test)\n",
    "\n",
    "                test_losses.append((eidx, test_loss.item()))\n",
    "                test_r2s.append((eidx, test_r2))\n",
    "\n",
    "            logger.log_progress(eidx, epochs, train_losses[-1][1], test_loss.item(), train_r2s[-1][1], test_r2)\n",
    "            \n",
    "            if save_best_model and test_r2 > best_test_r2:\n",
    "                best_test_r2 = test_r2\n",
    "                best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "                if embeddings_stim is not None:\n",
    "                    best_embeddings_stim = {k: v.cpu().clone() if torch.is_tensor(v) else v \n",
    "                                           for k, v in embeddings_stim.items()}\n",
    "                else:\n",
    "                    best_embeddings_stim = None\n",
    "                logger.info(f\"  ‚Üí New best model! Test R¬≤: {best_test_r2:.6f}\")\n",
    "\n",
    "                # Save checkpoint to disk with training type in name\n",
    "                try:\n",
    "                    out_dir = _ensure_saved_models_dir()\n",
    "                    fname = os.path.join(out_dir, f\"{training_type}_{model.__class__.__name__}_best_{int(time.time())}.pt\")\n",
    "                    torch.save({\n",
    "                        'model_state_dict': best_model_state,\n",
    "                        'epoch': eidx,\n",
    "                        'test_r2': best_test_r2,\n",
    "                        'timestamp': time.time(),\n",
    "                        'training_type': training_type,\n",
    "                    }, fname)\n",
    "                    logger.info(f\"Saved best checkpoint to {fname}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to save best checkpoint: {e}\")\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "    # Restore best model\n",
    "    if save_best_model and best_model_state is not None:\n",
    "        logger.info(f\"Restoring best model (Test R¬≤: {best_test_r2:.6f})\")\n",
    "        model.load_state_dict({k: v.to(device) for k, v in best_model_state.items()})\n",
    "        if best_embeddings_stim is not None:\n",
    "            embeddings_stim = {k: v.to(device) if torch.is_tensor(v) else v \n",
    "                              for k, v in best_embeddings_stim.items()}\n",
    "\n",
    "        # Save restored best model to disk with training type in name\n",
    "        try:\n",
    "            out_dir = _ensure_saved_models_dir()\n",
    "            best_fname = os.path.join(out_dir, f\"{training_type}_{model.__class__.__name__}_restored_best_{int(time.time())}.pt\")\n",
    "            model_cpu_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            torch.save({\n",
    "                'model_state_dict': model_cpu_state,\n",
    "                'best_test_r2': best_test_r2,\n",
    "                'timestamp': time.time(),\n",
    "                'training_type': training_type,\n",
    "            }, best_fname)\n",
    "            logger.info(f\"Saved restored best model to {best_fname}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to save restored best model: {e}\")\n",
    "\n",
    "        # Save final model with training type in name\n",
    "        try:\n",
    "            out_dir = _ensure_saved_models_dir()\n",
    "            final_fname = os.path.join(out_dir, f\"{training_type}_{model.__class__.__name__}_final_{int(time.time())}.pt\")\n",
    "            model_cpu_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            torch.save({\n",
    "                'model_state_dict': model_cpu_state,\n",
    "                'results': {\n",
    "                    'train_losses': train_losses,\n",
    "                    'test_losses': test_losses,\n",
    "                    'train_r2s': train_r2s,\n",
    "                    'test_r2s': test_r2s,\n",
    "                    'spatial_smooth_losses': spatial_smooth_losses,\n",
    "                    'spatial_decoder_losses': spatial_decoder_losses,\n",
    "                    'ae_recon_losses': ae_recon_losses,\n",
    "                    'final_test_r2': best_test_r2,\n",
    "                    'final_test_r2s': test_r2s_session,\n",
    "                    'best_test_r2': best_test_r2,\n",
    "                },\n",
    "                'timestamp': time.time(),\n",
    "                'training_type': training_type,\n",
    "            }, final_fname)\n",
    "            logger.info(f\"Saved final model to {final_fname}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to save final model: {e}\")\n",
    "\n",
    "        # Clean up intermediate checkpoint files of the same training type only\n",
    "        try:\n",
    "            cleanup_checkpoints(training_type=training_type, model_name_pattern=model.__class__.__name__, \n",
    "                              keep_final=True, keep_latest_best=False)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to cleanup checkpoints: {e}\")\n",
    "\n",
    "    return embeddings_stim, {\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'train_r2s': train_r2s,\n",
    "        'test_r2s': test_r2s,\n",
    "        'spatial_smooth_losses': spatial_smooth_losses,\n",
    "        'spatial_decoder_losses': spatial_decoder_losses,\n",
    "        'ae_recon_losses': ae_recon_losses,\n",
    "        'final_test_r2': best_test_r2,\n",
    "        'final_test_r2s': test_r2s_session,\n",
    "        'best_test_r2': best_test_r2,\n",
    "    }\n",
    "\n",
    "logger.end_phase(\"Creating Spatial Training Function with AE Reconstruction Penalty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w96w5lqtc7j",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:24 - ‚è≠Ô∏è  Skipping Spatial training (already skipped)\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_SPATIAL:\n",
    "    logger.start_training(cfg_spatial.training.epochs, \"Spatial Model Training\")\n",
    "\n",
    "    # Train with spatial regularization\n",
    "    embeddings_stim_spatial, results_spatial = train_from_cfg_spatial(\n",
    "        cfg_spatial,\n",
    "        ms_spatial,\n",
    "        data_train,\n",
    "        model_optims_spatial,\n",
    "        embeddings_rest,\n",
    "        data_test=data_test,\n",
    "        test_interval=GLOBAL_CONFIG['test_interval'],\n",
    "        epochs=cfg_spatial.training.epochs,\n",
    "        lambda_spatial_smooth=SPATIAL_CONFIG['lambda_spatial_smooth'],\n",
    "        lambda_spatial_decoder=SPATIAL_CONFIG['lambda_spatial_decoder'],\n",
    "        spatial_penalty_freq=10,  # Compute spatial penalties every 10 iterations\n",
    "    )\n",
    "\n",
    "    logger.end_training(\"Spatial Model Training\")\n",
    "\n",
    "    # Log spatial results\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"SPATIAL MODEL RESULTS\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"Overall Test R¬≤: {results_spatial['final_test_r2']:.6f}\")\n",
    "    logger.info(\"\\nPer-session Test R¬≤:\")\n",
    "    for session_id, r2 in results_spatial['final_test_r2s'].items():\n",
    "        logger.info(f\"  {session_id}: {r2:.6f}\")\n",
    "    logger.info(\"=\"*80)\n",
    "else:\n",
    "    logger.info(\"‚è≠Ô∏è  Skipping Spatial training (already skipped)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7u9p3qq8wcw",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:24 - ‚è≠Ô∏è  Skipping Spatial model save (already skipped)\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_SPATIAL:\n",
    "    # Save spatial model (best model is already loaded)\n",
    "    spatial_model_path = model_save_dir / \"spatial_model_best.pt\"\n",
    "    logger.info(f\"Saving best spatial model to {spatial_model_path}\")\n",
    "    logger.info(f\"Best Test R¬≤: {results_spatial['best_test_r2']:.6f}\")\n",
    "\n",
    "    # Save model state\n",
    "    torch.save({\n",
    "        'ms_state_dict': ms_spatial.state_dict(),\n",
    "        'embeddings_stim': embeddings_stim_spatial,\n",
    "        'results': results_spatial,\n",
    "        'config': OmegaConf.to_container(cfg_spatial, resolve=True),\n",
    "        'held_in_session_ids': held_in_session_ids,\n",
    "        'spatial_structures': spatial_structures,\n",
    "        'best_test_r2': results_spatial['best_test_r2'],\n",
    "    }, spatial_model_path)\n",
    "\n",
    "    logger.info(f\"Best spatial model saved successfully\")\n",
    "else:\n",
    "    logger.info(\"‚è≠Ô∏è  Skipping Spatial model save (already skipped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t2tjdq59xb",
   "metadata": {},
   "source": [
    "## Train with AE Reconstruction Penalty (No Spatial)\n",
    "\n",
    "Now let's train a model with the autoencoder reconstruction penalty added, without spatial regularization. This penalizes lossy conversions through the encoder-decoder bottleneck: L_ae_recon = || dec(enc(x)) - x ||_2^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9l8j1gorrii",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:24 - ‚è≠Ô∏è  Skipping AE Recon model (TRAIN_AE_RECON=False)\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_AE_RECON:\n",
    "    logger.start_phase(\"Building Model with AE Reconstruction (No Spatial)\")\n",
    "\n",
    "    # Build a new model WITHOUT spatial support (like baseline)\n",
    "    cfg_ae_recon = OmegaConf.create(OmegaConf.to_container(cfg, resolve=True))\n",
    "    # Do NOT enable spatial features (keep use_spatial=False like baseline)\n",
    "    cfg_ae_recon.training.epochs = AE_RECON_CONFIG['epochs']\n",
    "    cfg_ae_recon.ae.training.coadapt = AE_RECON_CONFIG['coadapt']\n",
    "\n",
    "    logger.info(\"Building AE reconstruction model (no spatial)...\")\n",
    "    ms_ae_recon = multisession.build_from_cfg(cfg_ae_recon, data_train, device=DEVICE)\n",
    "\n",
    "    model_optims_ae_recon = multisession.get_optims(cfg_ae_recon, ms_ae_recon)\n",
    "\n",
    "    logger.end_phase(\"Building Model with AE Reconstruction (No Spatial)\")\n",
    "else:\n",
    "    logger.info(\"‚è≠Ô∏è  Skipping AE Recon model (TRAIN_AE_RECON=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w055v28lqmb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:24 - ‚è≠Ô∏è  Skipping AE Recon training (already skipped)\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_AE_RECON:\n",
    "    logger.start_training(cfg_ae_recon.training.epochs, \"AE Reconstruction Model Training (No Spatial)\")\n",
    "\n",
    "    # Train with ONLY AE reconstruction penalty (no spatial regularization)\n",
    "    embeddings_stim_ae_recon, results_ae_recon = train_from_cfg_spatial_ae_recon(\n",
    "        cfg_ae_recon,\n",
    "        ms_ae_recon,\n",
    "        data_train,\n",
    "        model_optims_ae_recon,\n",
    "        embeddings_rest,\n",
    "        data_test=data_test,\n",
    "        test_interval=GLOBAL_CONFIG['test_interval'],\n",
    "        epochs=cfg_ae_recon.training.epochs,\n",
    "        lambda_spatial_smooth=0.0,  # NO spatial smoothness\n",
    "        lambda_spatial_decoder=0.0,  # NO spatial decoder penalty\n",
    "        lambda_ae_recon=AE_RECON_CONFIG['lambda_ae_recon'],\n",
    "        spatial_penalty_freq=10,\n",
    "    )\n",
    "\n",
    "    logger.end_training(\"AE Reconstruction Model Training (No Spatial)\")\n",
    "\n",
    "    # Log results\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"AE RECONSTRUCTION MODEL RESULTS (No Spatial)\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"Overall Test R¬≤: {results_ae_recon['final_test_r2']:.6f}\")\n",
    "    logger.info(\"\\nPer-session Test R¬≤:\")\n",
    "    for session_id, r2 in results_ae_recon['final_test_r2s'].items():\n",
    "        logger.info(f\"  {session_id}: {r2:.6f}\")\n",
    "    logger.info(\"=\"*80)\n",
    "else:\n",
    "    logger.info(\"‚è≠Ô∏è  Skipping AE Recon training (already skipped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xazisrxjla",
   "metadata": {},
   "source": [
    "## Sparsity-Based Compression Approach\n",
    "\n",
    "Since TBFM performs better with identity AE (no lossy compression), we'll use a two-stage approach:\n",
    "1. **Stage 1**: Train with identity AE + L1 sparsity penalty on channels ‚Üí learn which channels matter\n",
    "2. **Stage 2**: Build selective AE that only compresses unimportant channels ‚Üí task-informed compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y6ul4zewol",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:24 - \n",
      "================================================================================\n",
      "2025-10-29 13:28:24 - Starting: Creating Sparsity Training Function\n",
      "2025-10-29 13:28:24 - ================================================================================\n"
     ]
    }
   ],
   "source": [
    "logger.start_phase(\"Creating Sparsity Training Function\")\n",
    "\n",
    "# Create training function with L1 sparsity penalty on channel activations\n",
    "import torch.nn as nn\n",
    "from tbfm.multisession import split_support_query_sessions, r2_score\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "\n",
    "def train_with_channel_sparsity(\n",
    "    cfg,\n",
    "    model,\n",
    "    data_train,\n",
    "    model_optims,\n",
    "    embeddings_rest,\n",
    "    data_test=None,\n",
    "    inner_steps=None,\n",
    "    epochs=10000,\n",
    "    test_interval=None,\n",
    "    support_size=300,\n",
    "    embed_stim_lr=None,\n",
    "    embed_stim_weight_decay=None,\n",
    "    device=\"cuda\",\n",
    "    grad_clip=None,\n",
    "    alternating_updates=True,\n",
    "    bw_steps_per_bg_step=None,\n",
    "    lambda_channel_sparsity=0.001,  # L1 penalty on channel activations\n",
    "    lambda_sparsity_recon=0.0,  # NEW: Sparsity-weighted AE reconstruction penalty\n",
    "    save_best_model=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train TBFM with L1 sparsity penalty on channel activations + sparsity-driven reconstruction.\n",
    "    \n",
    "    This encourages the model to:\n",
    "    1. Use only a subset of channels (sparsity penalty)\n",
    "    2. Preserve information in important channels (sparsity-weighted reconstruction)\n",
    "    \n",
    "    Args:\n",
    "        lambda_channel_sparsity: Weight for L1 penalty on channel activations\n",
    "                                Encourages many channels to have near-zero activation\n",
    "        lambda_sparsity_recon: Weight for sparsity-weighted AE reconstruction penalty\n",
    "                              Focuses reconstruction on high-activation (important) channels\n",
    "    \"\"\"\n",
    "    # Same setup as original\n",
    "    test_interval = test_interval or cfg.training.test_interval\n",
    "    embed_stim_lr = embed_stim_lr or cfg.film.training.optim.lr\n",
    "    embed_stim_weight_decay = embed_stim_weight_decay or cfg.film.training.optim.weight_decay\n",
    "    inner_steps = inner_steps or cfg.film.training.inner_steps\n",
    "    use_film = cfg.tbfm.module.use_film_bases\n",
    "    bw_steps_per_bg_step = bw_steps_per_bg_step or cfg.training.bw_steps_per_bg_step\n",
    "    grad_clip = grad_clip or cfg.training.grad_clip or 10.0\n",
    "    epochs = epochs or cfg.training.epochs\n",
    "    support_size = support_size or cfg.film.training.support_size\n",
    "    device = model.device\n",
    "\n",
    "    def _ensure_saved_models_dir():\n",
    "        out_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        return out_dir\n",
    "\n",
    "    embeddings_stim = None\n",
    "    iter_train = iter(data_train)\n",
    "\n",
    "    train_losses = []\n",
    "    train_r2s = []\n",
    "    test_losses = []\n",
    "    test_r2s = []\n",
    "    channel_sparsity_losses = []\n",
    "    sparsity_recon_losses = []  # NEW: track sparsity-weighted reconstruction\n",
    "    channel_activations = {sid: [] for sid in data_train.session_ids}\n",
    "    best_test_r2 = -1e99\n",
    "    best_model_state = None\n",
    "    best_embeddings_stim = None\n",
    "\n",
    "    for eidx in range(epochs):\n",
    "        model.train()\n",
    "        iter_train, _data_train = utils.iter_loader(iter_train, data_train, device=device)\n",
    "\n",
    "        support, query = split_support_query_sessions(_data_train, support_size=support_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_query = {sid: d[2] for sid, d in query.items()}\n",
    "            y_query = model.norms(y_query)\n",
    "\n",
    "        if use_film:\n",
    "            model.eval()\n",
    "            embeddings_stim = film.inner_update_stopgrad(\n",
    "                model, support, embeddings_rest, inner_steps=inner_steps,\n",
    "                lr=embed_stim_lr, weight_decay=embed_stim_weight_decay,\n",
    "            )\n",
    "            model.train()\n",
    "\n",
    "        model_optims.zero_grad(set_to_none=True)\n",
    "\n",
    "        yhat_query = model(query, embeddings_rest=embeddings_rest, embeddings_stim=embeddings_stim)\n",
    "\n",
    "        losses = {}\n",
    "        r2_trains = []\n",
    "        sparsity_penalty_total = 0.0\n",
    "        sparsity_recon_total = 0.0  # NEW\n",
    "\n",
    "        for sid, y in y_query.items():\n",
    "            _loss = nn.MSELoss()(yhat_query[sid], y)\n",
    "            losses[sid] = _loss\n",
    "\n",
    "            # Compute channel activations (importance)\n",
    "            # yhat_query[sid] has shape (B, T, C) where C is channels\n",
    "            channel_activation = yhat_query[sid].abs().mean(dim=(0, 1))  # (C,) - mean activation per channel\n",
    "            \n",
    "            # L1 sparsity penalty on channel activations\n",
    "            sparsity_penalty = channel_activation.sum()\n",
    "            sparsity_penalty_total += sparsity_penalty\n",
    "            \n",
    "            # NEW: Sparsity-weighted reconstruction penalty\n",
    "            if lambda_sparsity_recon > 0:\n",
    "                ae_instance = model.ae.instances[sid]\n",
    "                mask = list(range(y.shape[-1]))  # All channels\n",
    "                \n",
    "                # Compute AE reconstruction: x_recon = dec(enc(x))\n",
    "                y_flat = y.flatten(0, 1)  # (B*T, C)\n",
    "                y_recon = ae_instance.reconstruct(y_flat, mask=mask)  # (B*T, C)\n",
    "                \n",
    "                # Compute per-channel reconstruction error\n",
    "                channel_recon_error = (y_recon - y_flat).pow(2).mean(dim=0)  # (C,) - MSE per channel\n",
    "                \n",
    "                # Weight reconstruction error by channel importance\n",
    "                # Important channels (high activation) ‚Üí high penalty if reconstruction is poor\n",
    "                # Unimportant channels (low activation) ‚Üí low penalty even if reconstruction is poor\n",
    "                # Normalize channel_activation to [0, 1] for stable weighting\n",
    "                channel_weights = channel_activation / (channel_activation.max() + 1e-8)\n",
    "                weighted_recon_error = (channel_weights * channel_recon_error).sum()\n",
    "                \n",
    "                sparsity_recon_total += weighted_recon_error\n",
    "            \n",
    "            # Track channel activations for analysis (every 100 epochs to save memory)\n",
    "            if eidx % 100 == 0:\n",
    "                channel_activations[sid].append((eidx, channel_activation.detach().cpu()))\n",
    "\n",
    "            r2_train = r2_score(\n",
    "                yhat_query[sid].permute(0, 2, 1).flatten(end_dim=1),\n",
    "                y.permute(0, 2, 1).flatten(end_dim=1),\n",
    "            )\n",
    "            r2_trains.append(r2_train.item())\n",
    "\n",
    "        # Compute reconstruction loss (MSE only)\n",
    "        mse_only = sum(losses.values()) / len(y_query)\n",
    "\n",
    "        # Build total loss\n",
    "        loss = mse_only\n",
    "\n",
    "        # Add TBFM regularization\n",
    "        tbfm_regs = model.model.get_weighting_reg()\n",
    "        loss = loss + cfg.tbfm.training.lambda_fro * sum(tbfm_regs.values()) / len(y_query)\n",
    "\n",
    "        tbfm_regs_ortho = model.model.get_basis_rms_reg()\n",
    "        loss = loss + cfg.tbfm.training.lambda_ortho * sum(tbfm_regs_ortho.values()) / len(y_query)\n",
    "\n",
    "        # Add channel sparsity penalty\n",
    "        if lambda_channel_sparsity > 0:\n",
    "            loss = loss + lambda_channel_sparsity * (sparsity_penalty_total / len(y_query))\n",
    "\n",
    "        # NEW: Add sparsity-weighted reconstruction penalty\n",
    "        if lambda_sparsity_recon > 0:\n",
    "            loss = loss + lambda_sparsity_recon * (sparsity_recon_total / len(y_query))\n",
    "\n",
    "        # Log losses\n",
    "        train_losses.append((eidx, mse_only.item()))\n",
    "        channel_sparsity_losses.append((eidx, sparsity_penalty_total.item() / len(y_query)))\n",
    "        sparsity_recon_losses.append((eidx, sparsity_recon_total.item() / len(y_query) if isinstance(sparsity_recon_total, torch.Tensor) else 0.0))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if grad_clip is not None:\n",
    "            model_optims.clip_grad(value=grad_clip)\n",
    "\n",
    "        if alternating_updates:\n",
    "            update_basis_gen = (eidx % bw_steps_per_bg_step) == 0 or eidx < 200\n",
    "            if update_basis_gen:\n",
    "                model_optims.step()\n",
    "            else:\n",
    "                model_optims.step(skip=[\"bg\", \"film\"])\n",
    "        else:\n",
    "            model_optims.step()\n",
    "\n",
    "        # Testing\n",
    "        if data_test is not None and (eidx % test_interval) == 0:\n",
    "            train_r2s.append((eidx, sum(r2_trains) / len(y_query)))\n",
    "\n",
    "            model_optims.zero_grad(set_to_none=True)\n",
    "            model.eval()\n",
    "\n",
    "            test_r2s_session = {}\n",
    "            with torch.no_grad():\n",
    "                iter_test = iter(data_test)\n",
    "                iter_test, _data_test = utils.iter_loader(iter_test, data_test, device=device)\n",
    "\n",
    "                y_test = {sid: d[2] for sid, d in _data_test.items()}\n",
    "                y_test = model.norms(y_test)\n",
    "\n",
    "                yhat_test = model(_data_test, embeddings_rest=embeddings_rest, embeddings_stim=embeddings_stim)\n",
    "\n",
    "                test_losses_session = {}\n",
    "                for sid, y in y_test.items():\n",
    "                    _loss = nn.MSELoss()(yhat_test[sid], y)\n",
    "                    test_losses_session[sid] = _loss\n",
    "\n",
    "                    r2_test = r2_score(\n",
    "                        yhat_test[sid].permute(0, 2, 1).flatten(end_dim=1),\n",
    "                        y.permute(0, 2, 1).flatten(end_dim=1),\n",
    "                    )\n",
    "                    test_r2s_session[sid] = r2_test.item()\n",
    "\n",
    "                test_loss = sum(test_losses_session.values()) / len(y_test)\n",
    "                test_r2 = sum(test_r2s_session.values()) / len(y_test)\n",
    "\n",
    "                test_losses.append((eidx, test_loss.item()))\n",
    "                test_r2s.append((eidx, test_r2))\n",
    "\n",
    "            logger.log_progress(eidx, epochs, train_losses[-1][1], test_loss.item(), train_r2s[-1][1], test_r2)\n",
    "            \n",
    "            if save_best_model and test_r2 > best_test_r2:\n",
    "                best_test_r2 = test_r2\n",
    "                best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "                if embeddings_stim is not None:\n",
    "                    best_embeddings_stim = {k: v.cpu().clone() if torch.is_tensor(v) else v \n",
    "                                           for k, v in embeddings_stim.items()}\n",
    "                else:\n",
    "                    best_embeddings_stim = None\n",
    "                logger.info(f\"  ‚Üí New best model! Test R¬≤: {best_test_r2:.6f}\")\n",
    "\n",
    "                # Save checkpoint to disk when improved\n",
    "                try:\n",
    "                    out_dir = _ensure_saved_models_dir()\n",
    "                    fname = os.path.join(out_dir, f\"{model.__class__.__name__}_best_{int(time.time())}.pt\")\n",
    "                    torch.save({\n",
    "                        'model_state_dict': best_model_state,\n",
    "                        'epoch': eidx,\n",
    "                        'test_r2': best_test_r2,\n",
    "                        'timestamp': time.time(),\n",
    "                    }, fname)\n",
    "                    logger.info(f\"Saved best checkpoint to {fname}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to save best checkpoint: {e}\")\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "    # Restore best model\n",
    "    if save_best_model and best_model_state is not None:\n",
    "        logger.info(f\"Restoring best model (Test R¬≤: {best_test_r2:.6f})\")\n",
    "        model.load_state_dict({k: v.to(device) for k, v in best_model_state.items()})\n",
    "        if best_embeddings_stim is not None:\n",
    "            embeddings_stim = {k: v.to(device) if torch.is_tensor(v) else v \n",
    "                              for k, v in best_embeddings_stim.items()}\n",
    "\n",
    "        # Save restored best model to disk\n",
    "        try:\n",
    "            out_dir = _ensure_saved_models_dir()\n",
    "            best_fname = os.path.join(out_dir, f\"{model.__class__.__name__}_restored_best_{int(time.time())}.pt\")\n",
    "            model_cpu_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            torch.save({\n",
    "                'model_state_dict': model_cpu_state,\n",
    "                'best_test_r2': best_test_r2,\n",
    "                'timestamp': time.time(),\n",
    "            }, best_fname)\n",
    "            logger.info(f\"Saved restored best model to {best_fname}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to save restored best model: {e}\")\n",
    "\n",
    "    # Also save final model file\n",
    "    try:\n",
    "        out_dir = _ensure_saved_models_dir()\n",
    "        final_fname = os.path.join(out_dir, f\"{model.__class__.__name__}_final_{int(time.time())}.pt\")\n",
    "        model_cpu_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "        torch.save({\n",
    "            'model_state_dict': model_cpu_state,\n",
    "            'results': {\n",
    "                'train_losses': train_losses,\n",
    "                'test_losses': test_losses,\n",
    "                'train_r2s': train_r2s,\n",
    "                'test_r2s': test_r2s,\n",
    "            },\n",
    "            'timestamp': time.time(),\n",
    "        }, final_fname)\n",
    "        logger.info(f\"Saved final model to {final_fname}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to save final model: {e}\")\n",
    "\n",
    "    # Clean up intermediate checkpoint files, keeping only the final model\n",
    "    try:\n",
    "        cleanup_checkpoints(model_name_pattern=model.__class__.__name__, \n",
    "                          keep_final=True, keep_latest_best=False)\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to cleanup checkpoints: {e}\")\n",
    "\n",
    "    return embeddings_stim, {\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'train_r2s': train_r2s,\n",
    "        'test_r2s': test_r2s,\n",
    "        'channel_sparsity_losses': channel_sparsity_losses,\n",
    "        'sparsity_recon_losses': sparsity_recon_losses,\n",
    "        'channel_activations': channel_activations,\n",
    "        'final_test_r2': best_test_r2 if save_best_model else test_r2s[-1][1] if test_r2s else 0,\n",
    "        'final_test_r2s': test_r2s_session if test_r2s else {},\n",
    "        'best_test_r2': best_test_r2,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rt5lnd260f",
   "metadata": {},
   "source": [
    "### Stage 1: Train with Identity AE + Channel Sparsity\n",
    "\n",
    "Use identity autoencoder (no compression) and apply L1 penalty to learn which channels are task-relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zmavohn1z",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:24 - \n",
      "================================================================================\n",
      "2025-10-29 13:28:24 - Starting: Building Model with Identity AE (Stage 1)\n",
      "2025-10-29 13:28:24 - ================================================================================\n",
      "2025-10-29 13:28:24 - Building Stage 1 model (identity AE)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building and fitting normalizers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:24 - Model configuration:\n",
      "2025-10-29 13:28:24 -   AE coadapt: False\n",
      "2025-10-29 13:28:24 -   AE identity init: True\n",
      "2025-10-29 13:28:24 -   Epochs: 5000\n",
      "2025-10-29 13:28:24 - \n",
      "Completed: Building Model with Identity AE (Stage 1)\n",
      "2025-10-29 13:28:24 - Duration: 00:00\n",
      "2025-10-29 13:28:24 - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building and warm starting AEs...\n",
      "Building TBFM...\n",
      "BOOM! Dino DNA!\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_SPARSITY:\n",
    "    logger.start_phase(\"Building Model with Identity AE (Stage 1)\")\n",
    "\n",
    "    # Build model with identity AE (no coadaptation, stays identity)\n",
    "    cfg_stage1 = OmegaConf.create(OmegaConf.to_container(cfg, resolve=True))\n",
    "    cfg_stage1.ae.training.coadapt = SPARSITY_CONFIG['coadapt']\n",
    "    cfg_stage1.ae.warm_start_is_identity = SPARSITY_CONFIG['warm_start_is_identity']\n",
    "    cfg_stage1.training.epochs = SPARSITY_CONFIG['epochs']\n",
    "\n",
    "    logger.info(\"Building Stage 1 model (identity AE)...\")\n",
    "    ms_stage1 = multisession.build_from_cfg(cfg_stage1, data_train, device=DEVICE)\n",
    "    model_optims_stage1 = multisession.get_optims(cfg_stage1, ms_stage1)\n",
    "\n",
    "    logger.info(\"Model configuration:\")\n",
    "    logger.info(f\"  AE coadapt: {cfg_stage1.ae.training.coadapt}\")\n",
    "    logger.info(f\"  AE identity init: {cfg_stage1.ae.warm_start_is_identity}\")\n",
    "    logger.info(f\"  Epochs: {cfg_stage1.training.epochs}\")\n",
    "\n",
    "    logger.end_phase(\"Building Model with Identity AE (Stage 1)\")\n",
    "else:\n",
    "    logger.info(\"‚è≠Ô∏è  Skipping Sparsity model (TRAIN_SPARSITY=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0yfyjd5pyqra",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:24 - ‚ö†Ô∏è  NOTE: This is the ORIGINAL (slower) sparsity approach\n",
      "2025-10-29 13:28:24 - ‚ö†Ô∏è  See 'Corrected Two-Stage Sparsity Approach' below for the faster method\n",
      "2025-10-29 13:28:24 - ‚ö†Ô∏è  Skipping original approach - run corrected version instead\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_SPARSITY:\n",
    "    logger.info(\"‚ö†Ô∏è  NOTE: This is the ORIGINAL (slower) sparsity approach\")\n",
    "    logger.info(\"‚ö†Ô∏è  See 'Corrected Two-Stage Sparsity Approach' below for the faster method\")\n",
    "    logger.info(\"‚ö†Ô∏è  Skipping original approach - run corrected version instead\")\n",
    "    \n",
    "    # Uncomment below to run original approach for comparison\n",
    "    # logger.start_training(cfg_stage1.training.epochs, \"Stage 1: Identity AE + Sparsity Training\")\n",
    "    # \n",
    "    # # Train Stage 1 with channel sparsity penalty + sparsity-weighted reconstruction\n",
    "    # embeddings_stim_s1, results_s1 = train_with_channel_sparsity(\n",
    "    #     cfg_stage1,\n",
    "    #     ms_stage1,\n",
    "    #     data_train,\n",
    "    #     model_optims_stage1,\n",
    "    #     embeddings_rest,\n",
    "    #     data_test=data_test,\n",
    "    #     test_interval=GLOBAL_CONFIG['test_interval'],\n",
    "    #     epochs=cfg_stage1.training.epochs,\n",
    "    #     lambda_channel_sparsity=SPARSITY_CONFIG['lambda_channel_sparsity'],\n",
    "    #     lambda_sparsity_recon=SPARSITY_CONFIG['lambda_sparsity_recon'],\n",
    "    # )\n",
    "    # \n",
    "    # logger.end_training(\"Stage 1: Identity AE + Sparsity Training\")\n",
    "    # \n",
    "    # # Log Stage 1 results\n",
    "    # logger.info(\"\\n\" + \"=\"*80)\n",
    "    # logger.info(\"STAGE 1 RESULTS (Identity AE + Sparsity)\")\n",
    "    # logger.info(\"=\"*80)\n",
    "    # logger.info(f\"Overall Test R¬≤: {results_s1['final_test_r2']:.6f}\")\n",
    "    # logger.info(\"\\nPer-session Test R¬≤:\")\n",
    "    # for session_id, r2 in results_s1['final_test_r2s'].items():\n",
    "    #     logger.info(f\"  {session_id}: {r2:.6f}\")\n",
    "    # logger.info(\"=\"*80)\n",
    "else:\n",
    "    logger.info(\"‚è≠Ô∏è  Skipping Sparsity training (already skipped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836aae93",
   "metadata": {},
   "source": [
    "## Corrected Two-Stage Sparsity Approach\n",
    "\n",
    "**Problem with Current Approach**: Training TBFM + AE simultaneously makes the AE reconstruction penalty expensive and the sparsity signals unclear.\n",
    "\n",
    "**Correct Approach**:\n",
    "1. **Stage 1**: Train TBFM bases with sparsity penalty (AE frozen as identity)\n",
    "2. **Stage 2**: Train AE to compress the pretrained sparse TBFM bases\n",
    "\n",
    "This separates concerns: first learn which channels/patterns matter, then learn efficient compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_tbfm_bases_only(\n",
    "#     cfg,\n",
    "#     model,\n",
    "#     data_train,\n",
    "#     model_optims,\n",
    "#     embeddings_rest,\n",
    "#     data_test=None,\n",
    "#     epochs=5000,\n",
    "#     test_interval=None,\n",
    "#     lambda_channel_sparsity=0.005,\n",
    "#     device=\"cuda\",\n",
    "#     save_best_model=True,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Stage 1: Train TBFM bases with sparsity penalty, keeping AE frozen as identity.\n",
    "    \n",
    "#     This focuses purely on learning which channels and temporal patterns matter\n",
    "#     without the computational overhead of AE reconstruction penalties.\n",
    "#     \"\"\"\n",
    "#     logger.info(\"Starting Stage 1: TBFM Basis Training (AE frozen)\")\n",
    "    \n",
    "#     # Freeze AE parameters - keep as identity\n",
    "#     for session_id in model.ae.instances:\n",
    "#         ae_instance = model.ae.instances[session_id]\n",
    "#         for param in ae_instance.parameters():\n",
    "#             param.requires_grad = False\n",
    "    \n",
    "#     # Use existing model_optims but only update TBFM parameters\n",
    "#     # (the frozen parameters just won't contribute gradients)\n",
    "    \n",
    "#     test_interval = test_interval or cfg.training.test_interval\n",
    "#     use_film = cfg.tbfm.module.use_film_bases\n",
    "#     support_size = cfg.film.training.support_size\n",
    "    \n",
    "#     train_losses = []\n",
    "#     test_losses = []\n",
    "#     train_r2s = []\n",
    "#     test_r2s = []\n",
    "#     sparsity_losses = []\n",
    "#     best_test_r2 = -1e99\n",
    "#     best_model_state = None\n",
    "    \n",
    "#     iter_train = iter(data_train)\n",
    "    \n",
    "#     for eidx in range(epochs):\n",
    "#         model.train()\n",
    "#         iter_train, _data_train = utils.iter_loader(iter_train, data_train, device=device)\n",
    "        \n",
    "#         support, query = split_support_query_sessions(_data_train, support_size=support_size)\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             y_query = {sid: d[2] for sid, d in query.items()}\n",
    "#             y_query = model.norms(y_query)\n",
    "        \n",
    "#         # FiLM embeddings if needed\n",
    "#         embeddings_stim = None\n",
    "#         if use_film:\n",
    "#             model.eval()\n",
    "#             embeddings_stim = film.inner_update_stopgrad(\n",
    "#                 model, support, embeddings_rest, \n",
    "#                 inner_steps=cfg.film.training.inner_steps,\n",
    "#                 lr=cfg.film.training.optim.lr, \n",
    "#                 weight_decay=cfg.film.training.optim.weight_decay,\n",
    "#             )\n",
    "#             model.train()\n",
    "        \n",
    "#         model_optims.zero_grad(set_to_none=True)\n",
    "        \n",
    "#         # Forward pass through TBFM (AE is identity, so no compression)\n",
    "#         yhat_query = model(query, embeddings_rest=embeddings_rest, embeddings_stim=embeddings_stim)\n",
    "        \n",
    "#         # Standard reconstruction loss\n",
    "#         total_loss = 0\n",
    "#         r2_trains = []\n",
    "#         total_sparsity = 0\n",
    "        \n",
    "#         for sid, y in y_query.items():\n",
    "#             mse_loss = nn.MSELoss()(yhat_query[sid], y)\n",
    "#             total_loss += mse_loss\n",
    "            \n",
    "#             # Channel sparsity penalty - encourage sparse channel usage\n",
    "#             channel_activation = yhat_query[sid].abs().mean()  # Overall activation sparsity\n",
    "#             total_sparsity += channel_activation\n",
    "            \n",
    "#             # R2 for tracking\n",
    "#             r2_train = r2_score(\n",
    "#                 yhat_query[sid].permute(0, 2, 1).flatten(end_dim=1),\n",
    "#                 y.permute(0, 2, 1).flatten(end_dim=1),\n",
    "#             )\n",
    "#             r2_trains.append(r2_train.item())\n",
    "        \n",
    "#         # Average losses\n",
    "#         avg_loss = total_loss / len(y_query)\n",
    "#         avg_sparsity = total_sparsity / len(y_query)\n",
    "        \n",
    "#         # Add TBFM regularization\n",
    "#         tbfm_regs = model.model.get_weighting_reg()\n",
    "#         reg_loss = cfg.tbfm.training.lambda_fro * sum(tbfm_regs.values()) / len(y_query)\n",
    "        \n",
    "#         tbfm_regs_ortho = model.model.get_basis_rms_reg()\n",
    "#         ortho_loss = cfg.tbfm.training.lambda_ortho * sum(tbfm_regs_ortho.values()) / len(y_query)\n",
    "        \n",
    "#         # Total loss with sparsity\n",
    "#         final_loss = avg_loss + reg_loss + ortho_loss + lambda_channel_sparsity * avg_sparsity\n",
    "        \n",
    "#         final_loss.backward()\n",
    "        \n",
    "#         # Use existing model_optims (frozen AE params won't get gradients)\n",
    "#         model_optims.step()\n",
    "        \n",
    "#         # Logging\n",
    "#         train_losses.append((eidx, avg_loss.item()))\n",
    "#         sparsity_losses.append((eidx, avg_sparsity.item()))\n",
    "        \n",
    "#         # Testing\n",
    "#         if data_test is not None and (eidx % test_interval) == 0:\n",
    "#             train_r2s.append((eidx, sum(r2_trains) / len(r2_trains)))\n",
    "            \n",
    "#             model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 iter_test = iter(data_test)\n",
    "#                 iter_test, _data_test = utils.iter_loader(iter_test, data_test, device=device)\n",
    "                \n",
    "#                 y_test = {sid: d[2] for sid, d in _data_test.items()}\n",
    "#                 y_test = model.norms(y_test)\n",
    "                \n",
    "#                 yhat_test = model(_data_test, embeddings_rest=embeddings_rest, embeddings_stim=embeddings_stim)\n",
    "                \n",
    "#                 test_loss = 0\n",
    "#                 test_r2s_session = {}\n",
    "#                 for sid, y in y_test.items():\n",
    "#                     loss = nn.MSELoss()(yhat_test[sid], y)\n",
    "#                     test_loss += loss\n",
    "                    \n",
    "#                     r2_test = r2_score(\n",
    "#                         yhat_test[sid].permute(0, 2, 1).flatten(end_dim=1),\n",
    "#                         y.permute(0, 2, 1).flatten(end_dim=1),\n",
    "#                     )\n",
    "#                     test_r2s_session[sid] = r2_test.item()\n",
    "                \n",
    "#                 avg_test_loss = test_loss / len(y_test)\n",
    "#                 avg_test_r2 = sum(test_r2s_session.values()) / len(test_r2s_session)\n",
    "                \n",
    "#                 test_losses.append((eidx, avg_test_loss.item()))\n",
    "#                 test_r2s.append((eidx, avg_test_r2))\n",
    "                \n",
    "#                 logger.log_progress(eidx, epochs, avg_loss.item(), avg_test_loss.item(), \n",
    "#                                   train_r2s[-1][1], avg_test_r2)\n",
    "                \n",
    "#                 # Save best model\n",
    "#                 if save_best_model and avg_test_r2 > best_test_r2:\n",
    "#                     best_test_r2 = avg_test_r2\n",
    "#                     best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "#                     logger.info(f\"  ‚Üí New best TBFM! Test R¬≤: {best_test_r2:.6f}\")\n",
    "            \n",
    "#             model.train()\n",
    "    \n",
    "#     # Restore best model\n",
    "#     if save_best_model and best_model_state is not None:\n",
    "#         logger.info(f\"Restoring best TBFM model (Test R¬≤: {best_test_r2:.6f})\")\n",
    "#         model.load_state_dict({k: v.to(device) for k, v in best_model_state.items()})\n",
    "    \n",
    "#     # Unfreeze AE for next stage\n",
    "#     for session_id in model.ae.instances:\n",
    "#         ae_instance = model.ae.instances[session_id]\n",
    "#         for param in ae_instance.parameters():\n",
    "#             param.requires_grad = True\n",
    "    \n",
    "#     logger.info(\"Stage 1 Complete: TBFM bases trained with sparsity\")\n",
    "    \n",
    "#     return {\n",
    "#         'train_losses': train_losses,\n",
    "#         'test_losses': test_losses, \n",
    "#         'train_r2s': train_r2s,\n",
    "#         'test_r2s': test_r2s,\n",
    "#         'sparsity_losses': sparsity_losses,\n",
    "#         'final_test_r2': best_test_r2 if save_best_model else test_r2s[-1][1] if test_r2s else 0,\n",
    "#         'final_test_r2s': test_r2s_session if 'test_r2s_session' in locals() else {},\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34015a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_ae_for_pretrained_tbfm(\n",
    "#     cfg,\n",
    "#     model,\n",
    "#     data_train,\n",
    "#     model_optims,\n",
    "#     embeddings_rest,\n",
    "#     data_test=None,\n",
    "#     epochs=3000,\n",
    "#     test_interval=None,\n",
    "#     lambda_ae_recon=0.01,\n",
    "#     device=\"cuda\",\n",
    "#     save_best_model=True,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Stage 2: Train AE to compress pretrained TBFM bases.\n",
    "    \n",
    "#     Now that we know which channels/patterns are important from Stage 1,\n",
    "#     train the AE to efficiently compress the neural activity while preserving\n",
    "#     the TBFM's learned representations.\n",
    "#     \"\"\"\n",
    "#     logger.info(\"Starting Stage 2: AE Training (TBFM frozen)\")\n",
    "    \n",
    "#     # Freeze TBFM parameters - keep learned bases fixed\n",
    "#     for name, param in model.named_parameters():\n",
    "#         if 'ae.' not in name:  # Freeze everything except AE\n",
    "#             param.requires_grad = False\n",
    "    \n",
    "#     # Use existing model_optims but only AE parameters will get gradients\n",
    "    \n",
    "#     test_interval = test_interval or cfg.training.test_interval\n",
    "#     use_film = cfg.tbfm.module.use_film_bases\n",
    "#     support_size = cfg.film.training.support_size\n",
    "    \n",
    "#     train_losses = []\n",
    "#     test_losses = []\n",
    "#     train_r2s = []\n",
    "#     test_r2s = []\n",
    "#     ae_recon_losses = []\n",
    "#     best_test_r2 = -1e99\n",
    "#     best_model_state = None\n",
    "    \n",
    "#     iter_train = iter(data_train)\n",
    "    \n",
    "#     # Use the embeddings_stim from Stage 1 (don't update during Stage 2)\n",
    "#     embeddings_stim = None\n",
    "#     if use_film:\n",
    "#         logger.info(\"Using frozen embeddings_stim from Stage 1 (no FiLM updates in Stage 2)\")\n",
    "#         # We'll compute embeddings_stim once and reuse it\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             iter_temp = iter(data_train)\n",
    "#             iter_temp, _data_temp = utils.iter_loader(iter_temp, data_train, device=device)\n",
    "#             support_temp, _ = split_support_query_sessions(_data_temp, support_size=support_size)\n",
    "#             embeddings_stim = film.inner_update_stopgrad(\n",
    "#                 model, support_temp, embeddings_rest, \n",
    "#                 inner_steps=cfg.film.training.inner_steps,\n",
    "#                 lr=cfg.film.training.optim.lr, \n",
    "#                 weight_decay=cfg.film.training.optim.weight_decay,\n",
    "#             )\n",
    "#         model.train()\n",
    "    \n",
    "#     for eidx in range(epochs):\n",
    "#         model.train()\n",
    "#         iter_train, _data_train = utils.iter_loader(iter_train, data_train, device=device)\n",
    "        \n",
    "#         support, query = split_support_query_sessions(_data_train, support_size=support_size)\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             y_query = {sid: d[2] for sid, d in query.items()}\n",
    "#             y_query = model.norms(y_query)\n",
    "        \n",
    "#         # Skip FiLM updates - use the frozen embeddings_stim computed above\n",
    "        \n",
    "#         model_optims.zero_grad(set_to_none=True)\n",
    "        \n",
    "#         # Forward pass - TBFM is frozen, only AE trains\n",
    "#         yhat_query = model(query, embeddings_rest=embeddings_rest, embeddings_stim=embeddings_stim)\n",
    "        \n",
    "#         # Standard reconstruction loss\n",
    "#         total_loss = 0\n",
    "#         r2_trains = []\n",
    "#         total_ae_recon = 0\n",
    "        \n",
    "#         for sid, y in y_query.items():\n",
    "#             mse_loss = nn.MSELoss()(yhat_query[sid], y)\n",
    "#             total_loss += mse_loss\n",
    "            \n",
    "#             # AE reconstruction penalty - ensure AE preserves information\n",
    "#             if lambda_ae_recon > 0:\n",
    "#                 ae_instance = model.ae.instances[sid]\n",
    "#                 mask = list(range(y.shape[-1]))\n",
    "                \n",
    "#                 # Compute AE reconstruction error\n",
    "#                 y_flat = y.flatten(0, 1)  # (B*T, C)\n",
    "#                 y_recon = ae_instance.reconstruct(y_flat, mask=mask)\n",
    "#                 ae_recon_loss = nn.MSELoss()(y_recon, y_flat)\n",
    "#                 total_ae_recon += ae_recon_loss\n",
    "            \n",
    "#             # R2 for tracking\n",
    "#             r2_train = r2_score(\n",
    "#                 yhat_query[sid].permute(0, 2, 1).flatten(end_dim=1),\n",
    "#                 y.permute(0, 2, 1).flatten(end_dim=1),\n",
    "#             )\n",
    "#             r2_trains.append(r2_train.item())\n",
    "        \n",
    "#         # Average losses\n",
    "#         avg_loss = total_loss / len(y_query)\n",
    "#         avg_ae_recon = total_ae_recon / len(y_query) if lambda_ae_recon > 0 else 0\n",
    "        \n",
    "#         # Total loss \n",
    "#         final_loss = avg_loss + lambda_ae_recon * avg_ae_recon\n",
    "        \n",
    "#         final_loss.backward()\n",
    "        \n",
    "#         # Use existing model_optims (frozen TBFM params won't get gradients)\n",
    "#         model_optims.step()\n",
    "        \n",
    "#         # Logging\n",
    "#         train_losses.append((eidx, avg_loss.item()))\n",
    "#         ae_recon_losses.append((eidx, avg_ae_recon.item() if isinstance(avg_ae_recon, torch.Tensor) else avg_ae_recon))\n",
    "        \n",
    "#         # Testing\n",
    "#         if data_test is not None and (eidx % test_interval) == 0:\n",
    "#             train_r2s.append((eidx, sum(r2_trains) / len(r2_trains)))\n",
    "            \n",
    "#             model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 iter_test = iter(data_test)\n",
    "#                 iter_test, _data_test = utils.iter_loader(iter_test, data_test, device=device)\n",
    "                \n",
    "#                 y_test = {sid: d[2] for sid, d in _data_test.items()}\n",
    "#                 y_test = model.norms(y_test)\n",
    "                \n",
    "#                 yhat_test = model(_data_test, embeddings_rest=embeddings_rest, embeddings_stim=embeddings_stim)\n",
    "                \n",
    "#                 test_loss = 0\n",
    "#                 test_r2s_session = {}\n",
    "#                 for sid, y in y_test.items():\n",
    "#                     loss = nn.MSELoss()(yhat_test[sid], y)\n",
    "#                     test_loss += loss\n",
    "                    \n",
    "#                     r2_test = r2_score(\n",
    "#                         yhat_test[sid].permute(0, 2, 1).flatten(end_dim=1),\n",
    "#                         y.permute(0, 2, 1).flatten(end_dim=1),\n",
    "#                     )\n",
    "#                     test_r2s_session[sid] = r2_test.item()\n",
    "                \n",
    "#                 avg_test_loss = test_loss / len(y_test)\n",
    "#                 avg_test_r2 = sum(test_r2s_session.values()) / len(test_r2s_session)\n",
    "                \n",
    "#                 test_losses.append((eidx, avg_test_loss.item()))\n",
    "#                 test_r2s.append((eidx, avg_test_r2))\n",
    "                \n",
    "#                 logger.log_progress(eidx, epochs, avg_loss.item(), avg_test_loss.item(), \n",
    "#                                   train_r2s[-1][1], avg_test_r2)\n",
    "                \n",
    "#                 # Save best model\n",
    "#                 if save_best_model and avg_test_r2 > best_test_r2:\n",
    "#                     best_test_r2 = avg_test_r2\n",
    "#                     best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "#                     logger.info(f\"  ‚Üí New best AE! Test R¬≤: {best_test_r2:.6f}\")\n",
    "            \n",
    "#             model.train()\n",
    "    \n",
    "#     # Restore best model\n",
    "#     if save_best_model and best_model_state is not None:\n",
    "#         logger.info(f\"Restoring best AE model (Test R¬≤: {best_test_r2:.6f})\")\n",
    "#         model.load_state_dict({k: v.to(device) for k, v in best_model_state.items()})\n",
    "    \n",
    "#     # Unfreeze all parameters for future use\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = True\n",
    "    \n",
    "#     logger.info(\"Stage 2 Complete: AE trained for pretrained TBFM\")\n",
    "    \n",
    "#     return {\n",
    "#         'train_losses': train_losses,\n",
    "#         'test_losses': test_losses, \n",
    "#         'train_r2s': train_r2s,\n",
    "#         'test_r2s': test_r2s,\n",
    "#         'ae_recon_losses': ae_recon_losses,\n",
    "#         'final_test_r2': best_test_r2 if save_best_model else test_r2s[-1][1] if test_r2s else 0,\n",
    "#         'final_test_r2s': test_r2s_session if 'test_r2s_session' in locals() else {},\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa246ad",
   "metadata": {},
   "source": [
    "### Execute Corrected Two-Stage Training\n",
    "\n",
    "Now let's run the proper sequence:\n",
    "1. **Stage 1**: Learn sparse TBFM bases (much faster!)\n",
    "2. **Stage 2**: Train AE to compress the learned bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c003d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:24 - \n",
      "================================================================================\n",
      "2025-10-29 13:28:24 - Starting: Two-Stage Sparsity Training: Identity AE ‚Üí Compressed AE\n",
      "2025-10-29 13:28:24 - ================================================================================\n",
      "2025-10-29 13:28:24 - üöÄ STAGE 1: Training with Identity Autoencoder (no compression)\n",
      "2025-10-29 13:28:24 - This is functionally equivalent to vanilla TBFM but uses existing infrastructure\n",
      "2025-10-29 13:28:24 -   AE latent_dim: 93 (same as input - identity transform)\n",
      "2025-10-29 13:28:24 -   AE coadapt: False\n",
      "2025-10-29 13:28:24 -   AE identity init: True\n",
      "2025-10-29 13:28:24 -   Sparsity lambda: 0.02\n",
      "2025-10-29 13:28:24 -   Prediction sparsity lambda: 0.002\n",
      "2025-10-29 13:28:24 -   Epochs: 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building and fitting normalizers...\n",
      "Building and warm starting AEs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:25 - Training identity AE model with sparsity regularization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building TBFM...\n",
      "BOOM! Dino DNA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 13:28:26 - Epoch 0/5000 (0.0%) | Train Loss: 339.262268 | Test Loss: 12.612190 | Train R¬≤: 0.037596 | Test R¬≤: 0.061099 | Elapsed: 00:01 | ETA: 02:43:50\n",
      "2025-10-29 13:28:26 -   ‚Üí New best model! Test R¬≤: 0.061099\n",
      "2025-10-29 13:28:26 - Saved best checkpoint to /home/danmuir/GitHub/py-tbfm/saved_models/identity_sparsity_TBFMMultisession_best_1761769706.pt\n",
      "2025-10-29 13:39:18 - Epoch 1000/5000 (20.0%) | Train Loss: 338.349976 | Test Loss: 12.383114 | Train R¬≤: 0.039331 | Test R¬≤: 0.088338 | Elapsed: 10:53 | ETA: 43:30\n",
      "2025-10-29 13:39:18 -   ‚Üí New best model! Test R¬≤: 0.088338\n",
      "2025-10-29 13:39:18 - Saved best checkpoint to /home/danmuir/GitHub/py-tbfm/saved_models/identity_sparsity_TBFMMultisession_best_1761770358.pt\n",
      "2025-10-29 13:50:11 - Epoch 2000/5000 (40.0%) | Train Loss: 338.311554 | Test Loss: 12.290613 | Train R¬≤: 0.039793 | Test R¬≤: 0.100564 | Elapsed: 21:46 | ETA: 32:38\n",
      "2025-10-29 13:50:11 -   ‚Üí New best model! Test R¬≤: 0.100564\n",
      "2025-10-29 13:50:11 - Saved best checkpoint to /home/danmuir/GitHub/py-tbfm/saved_models/identity_sparsity_TBFMMultisession_best_1761771011.pt\n",
      "2025-10-29 14:01:15 - Epoch 3000/5000 (60.0%) | Train Loss: 338.186920 | Test Loss: 12.205113 | Train R¬≤: 0.040542 | Test R¬≤: 0.111624 | Elapsed: 32:50 | ETA: 21:52\n",
      "2025-10-29 14:01:15 -   ‚Üí New best model! Test R¬≤: 0.111624\n",
      "2025-10-29 14:01:15 - Saved best checkpoint to /home/danmuir/GitHub/py-tbfm/saved_models/identity_sparsity_TBFMMultisession_best_1761771675.pt\n",
      "2025-10-29 14:12:08 - Epoch 4000/5000 (80.0%) | Train Loss: 337.787872 | Test Loss: 12.066449 | Train R¬≤: 0.042008 | Test R¬≤: 0.129404 | Elapsed: 43:43 | ETA: 10:55\n",
      "2025-10-29 14:12:08 -   ‚Üí New best model! Test R¬≤: 0.129404\n",
      "2025-10-29 14:12:08 - Saved best checkpoint to /home/danmuir/GitHub/py-tbfm/saved_models/identity_sparsity_TBFMMultisession_best_1761772328.pt\n",
      "2025-10-29 14:23:10 - Final: 12.03499698638916 0.13379287719726562\n",
      "2025-10-29 14:23:10 - Restoring best model (Test R¬≤: 0.129404)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final: 12.03499698638916 0.13379287719726562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 14:23:12 - Saved final model to /home/danmuir/GitHub/py-tbfm/saved_models/identity_sparsity_TBFMMultisession_final_1761772990.pt\n",
      "2025-10-29 14:23:12 - Deleted checkpoint: identity_sparsity_TBFMMultisession_best_1761769706.pt\n",
      "2025-10-29 14:23:12 - Deleted checkpoint: identity_sparsity_TBFMMultisession_best_1761770358.pt\n",
      "2025-10-29 14:23:12 - Deleted checkpoint: identity_sparsity_TBFMMultisession_best_1761771011.pt\n",
      "2025-10-29 14:23:12 - Deleted checkpoint: identity_sparsity_TBFMMultisession_best_1761771675.pt\n",
      "2025-10-29 14:23:12 - Deleted checkpoint: identity_sparsity_TBFMMultisession_best_1761772328.pt\n",
      "2025-10-29 14:23:12 - ‚úÖ Cleaned up 5 checkpoint files (identity_sparsity only) (0.0 MB freed)\n",
      "2025-10-29 14:23:12 - ‚úÖ Stage 1 Complete - Identity AE (vanilla TBFM equiv) Test R¬≤: 0.129404\n",
      "2025-10-29 14:23:12 - üöÄ STAGE 2: Training compressed model with learned sparse TBFM knowledge\n",
      "2025-10-29 14:23:12 -   Compressed AE latent_dim: 50\n",
      "2025-10-29 14:23:12 -   Reduced sparsity lambda: 0.010000000000000002\n",
      "2025-10-29 14:23:12 -   Epochs: 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building and fitting normalizers...\n",
      "Building and warm starting AEs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 14:23:13 - Transferring learned sparse TBFM knowledge to compressed model...\n",
      "2025-10-29 14:23:13 -   MonkeyG_20150914_Session1_S1: Transferred sparse TBFM basis generator\n",
      "2025-10-29 14:23:13 -   MonkeyG_20150915_Session3_S1: Transferred sparse TBFM basis generator\n",
      "2025-10-29 14:23:13 - Training compressed model with transferred sparse TBFM knowledge...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building TBFM...\n",
      "BOOM! Dino DNA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 14:23:14 - Epoch 0/5000 (0.0%) | Train Loss: 114.637749 | Test Loss: 24.307793 | Train R¬≤: 0.355693 | Test R¬≤: -1.298563 | Elapsed: 54:49 | ETA: 4567:23:48\n",
      "2025-10-29 14:23:14 -   ‚Üí New best model! Test R¬≤: -1.298563\n",
      "2025-10-29 14:23:14 - Saved best checkpoint to /home/danmuir/GitHub/py-tbfm/saved_models/compressed_sparsity_TBFMMultisession_best_1761772994.pt\n",
      "2025-10-29 14:33:57 - Epoch 1000/5000 (20.0%) | Train Loss: 88.840675 | Test Loss: 5.496982 | Train R¬≤: 0.593587 | Test R¬≤: 0.483361 | Elapsed: 01:05:32 | ETA: 04:21:49\n",
      "2025-10-29 14:33:57 -   ‚Üí New best model! Test R¬≤: 0.483361\n",
      "2025-10-29 14:33:57 - Saved best checkpoint to /home/danmuir/GitHub/py-tbfm/saved_models/compressed_sparsity_TBFMMultisession_best_1761773637.pt\n",
      "2025-10-29 14:44:31 - Epoch 2000/5000 (40.0%) | Train Loss: 87.502777 | Test Loss: 5.444959 | Train R¬≤: 0.609203 | Test R¬≤: 0.488699 | Elapsed: 01:16:06 | ETA: 01:54:03\n",
      "2025-10-29 14:44:31 -   ‚Üí New best model! Test R¬≤: 0.488699\n",
      "2025-10-29 14:44:31 - Saved best checkpoint to /home/danmuir/GitHub/py-tbfm/saved_models/compressed_sparsity_TBFMMultisession_best_1761774271.pt\n",
      "2025-10-29 14:55:22 - Epoch 3000/5000 (60.0%) | Train Loss: 86.739326 | Test Loss: 5.395452 | Train R¬≤: 0.617931 | Test R¬≤: 0.494847 | Elapsed: 01:26:57 | ETA: 57:55\n",
      "2025-10-29 14:55:22 -   ‚Üí New best model! Test R¬≤: 0.494847\n",
      "2025-10-29 14:55:22 - Saved best checkpoint to /home/danmuir/GitHub/py-tbfm/saved_models/compressed_sparsity_TBFMMultisession_best_1761774922.pt\n",
      "2025-10-29 15:06:28 - Epoch 4000/5000 (80.0%) | Train Loss: 85.914871 | Test Loss: 5.372486 | Train R¬≤: 0.625098 | Test R¬≤: 0.498682 | Elapsed: 01:38:03 | ETA: 24:28\n",
      "2025-10-29 15:06:28 -   ‚Üí New best model! Test R¬≤: 0.498682\n",
      "2025-10-29 15:06:28 - Saved best checkpoint to /home/danmuir/GitHub/py-tbfm/saved_models/compressed_sparsity_TBFMMultisession_best_1761775588.pt\n",
      "2025-10-29 15:17:31 - Final: 5.457650184631348 0.4941916763782501\n",
      "2025-10-29 15:17:31 - Restoring best model (Test R¬≤: 0.498682)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final: 5.457650184631348 0.4941916763782501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:17:33 - Saved final model to /home/danmuir/GitHub/py-tbfm/saved_models/compressed_sparsity_TBFMMultisession_final_1761776251.pt\n",
      "2025-10-29 15:17:33 - Deleted checkpoint: compressed_sparsity_TBFMMultisession_best_1761772994.pt\n",
      "2025-10-29 15:17:33 - Deleted checkpoint: compressed_sparsity_TBFMMultisession_best_1761773637.pt\n",
      "2025-10-29 15:17:33 - Deleted checkpoint: compressed_sparsity_TBFMMultisession_best_1761774271.pt\n",
      "2025-10-29 15:17:33 - Deleted checkpoint: compressed_sparsity_TBFMMultisession_best_1761774922.pt\n",
      "2025-10-29 15:17:33 - Deleted checkpoint: compressed_sparsity_TBFMMultisession_best_1761775588.pt\n",
      "2025-10-29 15:17:33 - ‚úÖ Cleaned up 5 checkpoint files (compressed_sparsity only) (0.0 MB freed)\n",
      "2025-10-29 15:17:33 - ‚úÖ Stage 2 Complete - Compressed Model Test R¬≤: 0.498682\n",
      "2025-10-29 15:17:33 - \n",
      "Two-Stage Sparsity Training completed in 01:49:08\n",
      "2025-10-29 15:17:33 - \n",
      "Completed: Two-Stage Sparsity Training\n",
      "2025-10-29 15:17:33 - Duration: 01:49:08\n",
      "2025-10-29 15:17:33 - ================================================================================\n",
      "2025-10-29 15:17:33 - \n",
      "================================================================================\n",
      "2025-10-29 15:17:33 - TWO-STAGE SPARSITY RESULTS\n",
      "2025-10-29 15:17:33 - ================================================================================\n",
      "2025-10-29 15:17:33 - Stage 1 (Identity AE - Sparse TBFM): 0.129404\n",
      "2025-10-29 15:17:33 - Stage 2 (Compressed AE): 0.498682\n",
      "2025-10-29 15:17:33 - Compression Improvement: +0.369278\n",
      "2025-10-29 15:17:33 - \n",
      "Per-session Final R¬≤ (Compressed):\n",
      "2025-10-29 15:17:33 -   MonkeyG_20150914_Session1_S1: 0.708354 (+0.705835)\n",
      "2025-10-29 15:17:33 -   MonkeyG_20150915_Session3_S1: 0.280030 (+0.014962)\n",
      "2025-10-29 15:17:33 - ================================================================================\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_SPARSITY:\n",
    "    # Import necessary modules for this stage\n",
    "    from omegaconf import OmegaConf\n",
    "    import torch\n",
    "    from tbfm import multisession\n",
    "    from tbfm.tbfm import TBFM\n",
    "    from tbfm import utils\n",
    "    from torch import nn\n",
    "    import numpy as np\n",
    "    \n",
    "    logger.start_training(SPARSITY_CONFIG['epochs'], \"Two-Stage Sparsity Training: Identity AE ‚Üí Compressed AE\")\n",
    "    \n",
    "    # STAGE 1: Train with Identity Autoencoder (equivalent to vanilla TBFM)\n",
    "    logger.info(\"üöÄ STAGE 1: Training with Identity Autoencoder (no compression)\")\n",
    "    logger.info(\"This is functionally equivalent to vanilla TBFM but uses existing infrastructure\")\n",
    "    \n",
    "    # Create configuration for identity autoencoder\n",
    "    cfg_identity = OmegaConf.create(OmegaConf.to_container(cfg, resolve=True))\n",
    "    \n",
    "    # Configure for identity transformation (no compression)  \n",
    "    cfg_identity.ae.training.coadapt = SPARSITY_CONFIG['coadapt']\n",
    "    cfg_identity.ae.warm_start_is_identity = True  # Start as identity\n",
    "    \n",
    "    # Get number of channels from existing batch sample\n",
    "    # k0 is the first batch key, b[k0][0] gives us the data tensor\n",
    "    num_channels = b[k0][0].shape[-1]  # Last dimension is channels (93)\n",
    "    cfg_identity.ae.module.latent_dim = num_channels  # TRUE input dimension (93 channels)\n",
    "    cfg_identity.training.epochs = SPARSITY_CONFIG['epochs']\n",
    "    \n",
    "    # Add strong sparsity penalties for Stage 1\n",
    "    cfg_identity.training.lambda_sparse = SPARSITY_CONFIG.get('lambda_sparse', 0.02)\n",
    "    cfg_identity.training.lambda_pred_sparse = SPARSITY_CONFIG.get('lambda_pred_sparse', 0.002)\n",
    "    \n",
    "    logger.info(f\"  AE latent_dim: {cfg_identity.ae.module.latent_dim} (same as input - identity transform)\")\n",
    "    logger.info(f\"  AE coadapt: {cfg_identity.ae.training.coadapt}\")\n",
    "    logger.info(f\"  AE identity init: {cfg_identity.ae.warm_start_is_identity}\")\n",
    "    logger.info(f\"  Sparsity lambda: {cfg_identity.training.lambda_sparse}\")\n",
    "    logger.info(f\"  Prediction sparsity lambda: {cfg_identity.training.lambda_pred_sparse}\")\n",
    "    logger.info(f\"  Epochs: {cfg_identity.training.epochs}\")\n",
    "    \n",
    "    # Build identity model\n",
    "    ms_identity = multisession.build_from_cfg(cfg_identity, data_train, device=DEVICE)\n",
    "    model_optims_identity = multisession.get_optims(cfg_identity, ms_identity)\n",
    "    \n",
    "    # Train Stage 1: Identity AE with sparsity (equivalent to vanilla TBFM)\n",
    "    logger.info(\"Training identity AE model with sparsity regularization...\")\n",
    "    embeddings_stim_identity, identity_results = train_with_logging(\n",
    "        cfg_identity,\n",
    "        ms_identity,\n",
    "        data_train,\n",
    "        model_optims_identity,\n",
    "        embeddings_rest,\n",
    "        data_test=data_test,\n",
    "        epochs=cfg_identity.training.epochs,\n",
    "        test_interval=GLOBAL_CONFIG['test_interval'],\n",
    "        training_type=\"identity_sparsity\",\n",
    "        save_best_model=False\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"‚úÖ Stage 1 Complete - Identity AE (vanilla TBFM equiv) Test R¬≤: {identity_results['final_test_r2']:.6f}\")\n",
    "    \n",
    "    # STAGE 2: Train compressed model using the sparse TBFM learned in Stage 1\n",
    "    logger.info(\"üöÄ STAGE 2: Training compressed model with learned sparse TBFM knowledge\")\n",
    "    \n",
    "    # Create configuration for compressed autoencoder\n",
    "    cfg_compressed = OmegaConf.create(OmegaConf.to_container(cfg, resolve=True))\n",
    "    cfg_compressed.ae.training.coadapt = True\n",
    "    cfg_compressed.ae.warm_start_is_identity = False  # Now use actual compression\n",
    "    cfg_compressed.ae.module.latent_dim = cfg.latent_dim  # Compressed dimension (e.g., 20)\n",
    "    cfg_compressed.training.epochs = SPARSITY_CONFIG['epochs']  # Remaining epochs for Stage 2\n",
    "    \n",
    "    # Reduce sparsity penalties for Stage 2 (focus on compression)\n",
    "    cfg_compressed.training.lambda_sparse = SPARSITY_CONFIG.get('lambda_sparse', 0.1) * 0.1\n",
    "    cfg_compressed.training.lambda_pred_sparse = SPARSITY_CONFIG.get('lambda_pred_sparse', 0.01) * 0.1\n",
    "    \n",
    "    logger.info(f\"  Compressed AE latent_dim: {cfg_compressed.ae.module.latent_dim}\")\n",
    "    logger.info(f\"  Reduced sparsity lambda: {cfg_compressed.training.lambda_sparse}\")\n",
    "    logger.info(f\"  Epochs: {cfg_compressed.training.epochs}\")\n",
    "    \n",
    "    # Build compressed model\n",
    "    ms_compressed = multisession.build_from_cfg(cfg_compressed, data_train, device=DEVICE)\n",
    "    model_optims_compressed = multisession.get_optims(cfg_compressed, ms_compressed)\n",
    "    \n",
    "    # Transfer learned TBFM knowledge from identity model to compressed model\n",
    "    logger.info(\"Transferring learned sparse TBFM knowledge to compressed model...\")\n",
    "    with torch.no_grad():\n",
    "        for session_id in data_train.session_ids:\n",
    "            identity_tbfm = ms_identity.model.instances[session_id]\n",
    "            compressed_tbfm = ms_compressed.model.instances[session_id]\n",
    "            \n",
    "            # Copy TBFM basis generators (temporal patterns learned in Stage 1)\n",
    "            if hasattr(identity_tbfm, 'bases') and hasattr(compressed_tbfm, 'bases'):\n",
    "                compressed_tbfm.bases.load_state_dict(identity_tbfm.bases.state_dict())\n",
    "                logger.info(f\"  {session_id}: Transferred sparse TBFM basis generator\")\n",
    "            \n",
    "            # Copy other TBFM components that are compatible\n",
    "            if hasattr(identity_tbfm, 'norms') and hasattr(compressed_tbfm, 'norms'):\n",
    "                compressed_tbfm.norms.load_state_dict(identity_tbfm.norms.state_dict())\n",
    "    \n",
    "    # Train Stage 2: Compressed model\n",
    "    logger.info(\"Training compressed model with transferred sparse TBFM knowledge...\")\n",
    "    embeddings_stim_compressed, compressed_results = train_with_logging(\n",
    "        cfg_compressed,\n",
    "        ms_compressed,\n",
    "        data_train,\n",
    "        model_optims_compressed,\n",
    "        embeddings_rest,\n",
    "        data_test=data_test,\n",
    "        epochs=cfg_compressed.training.epochs,\n",
    "        test_interval=GLOBAL_CONFIG['test_interval'],\n",
    "        training_type=\"compressed_sparsity\",\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"‚úÖ Stage 2 Complete - Compressed Model Test R¬≤: {compressed_results['final_test_r2']:.6f}\")\n",
    "    \n",
    "    # Combine results for analysis\n",
    "    results_corrected_sparsity = {\n",
    "        'stage1_identity': identity_results,\n",
    "        'stage2_compressed': compressed_results,\n",
    "        'final_test_r2': compressed_results['final_test_r2'],\n",
    "        'final_test_r2s': compressed_results.get('final_test_r2s', {}),\n",
    "        'identity_model': ms_identity,\n",
    "        'compressed_model': ms_compressed,\n",
    "        'embeddings_stim_compressed': embeddings_stim_compressed,\n",
    "    }\n",
    "    \n",
    "    logger.end_training(\"Two-Stage Sparsity Training\")\n",
    "    \n",
    "    # Log final results\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"TWO-STAGE SPARSITY RESULTS\")\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(f\"Stage 1 (Identity AE - Sparse TBFM): {identity_results['final_test_r2']:.6f}\")\n",
    "    logger.info(f\"Stage 2 (Compressed AE): {compressed_results['final_test_r2']:.6f}\")\n",
    "    improvement = compressed_results['final_test_r2'] - identity_results['final_test_r2']\n",
    "    logger.info(f\"Compression Improvement: {improvement:+.6f}\")\n",
    "    \n",
    "    if 'final_test_r2s' in compressed_results:\n",
    "        logger.info(\"\\nPer-session Final R¬≤ (Compressed):\")\n",
    "        for session_id, r2 in compressed_results['final_test_r2s'].items():\n",
    "            identity_r2 = identity_results.get('final_test_r2s', {}).get(session_id, 0.0)\n",
    "            improvement_session = r2 - identity_r2\n",
    "            logger.info(f\"  {session_id}: {r2:.6f} ({improvement_session:+.6f})\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    logger.info(\"‚è≠Ô∏è  Skipping Sparsity training (TRAIN_SPARSITY=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ddfc66",
   "metadata": {},
   "source": [
    "### Why This Corrected Approach is Much Faster\n",
    "\n",
    "**Original (Slow) Approach:**\n",
    "```python\n",
    "# EVERY epoch, EVERY session:\n",
    "yhat = model(data)  # TBFM forward pass\n",
    "y_recon = ae.reconstruct(y)  # ADDITIONAL AE forward pass  \n",
    "channel_weights = yhat.abs().mean()  # Channel analysis\n",
    "weighted_loss = channel_weights * reconstruction_error  # Complex weighting\n",
    "```\n",
    "\n",
    "**Corrected (Fast) Approach:**\n",
    "```python\n",
    "# Stage 1: Only TBFM training (no AE overhead)\n",
    "yhat = model(data)  # TBFM forward pass only\n",
    "sparsity_penalty = yhat.abs().mean()  # Simple sparsity\n",
    "\n",
    "# Stage 2: Only AE training (TBFM frozen)\n",
    "yhat = model(data)  # Single forward pass, TBFM cached\n",
    "ae_loss = ae.reconstruct(y)  # AE only trains here\n",
    "```\n",
    "\n",
    "**Performance Benefits:**\n",
    "- ‚ö° **~50% faster**: No double forward passes during Stage 1\n",
    "- üéØ **Clearer objectives**: Each stage has one focused goal  \n",
    "- üß† **Better learning**: TBFM learns patterns first, then AE compresses\n",
    "- üíæ **Less memory**: No need to track channel activations during TBFM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w0kvadqdo1h",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save baseline model (best model is already loaded)\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "\n",
    "# model_save_dir = Path(\"saved_models\")\n",
    "# model_save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# baseline_model_path = model_save_dir / \"baseline_model_best.pt\"\n",
    "# logger.info(f\"Saving best baseline model to {baseline_model_path}\")\n",
    "# if 'best_test_r2' in results:\n",
    "#     logger.info(f\"Best Test R¬≤: {results['best_test_r2']:.6f}\")\n",
    "\n",
    "# # Save model state\n",
    "# torch.save({\n",
    "#     'ms_state_dict': ms.state_dict(),\n",
    "#     'embeddings_stim': embeddings_stim,\n",
    "#     'results': results,\n",
    "#     'config': OmegaConf.to_container(cfg, resolve=True),\n",
    "#     'held_in_session_ids': held_in_session_ids,\n",
    "#     'best_test_r2': results.get('best_test_r2', results.get('final_test_r2')),\n",
    "# }, baseline_model_path)\n",
    "\n",
    "# logger.info(f\"Best baseline model saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9eeb88-89dc-476c-a755-5214a1d4dfb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Baseline training curves (original)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m txt \u001b[38;5;241m=\u001b[39m [t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      3\u001b[0m tlt \u001b[38;5;241m=\u001b[39m [t[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Baseline training curves (original)\n",
    "txt = [t[0] for t in results['train_losses']]\n",
    "tlt = [t[1] for t in results['train_losses']]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(txt[-500:], tlt[-500:], label=\"train (last 500)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Baseline: Recent Training Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Full baseline curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "tx = [t[0] for t in results['test_losses']]\n",
    "tl = [t[1] for t in results['test_losses']]\n",
    "\n",
    "axes[0].plot(txt, tlt, label=\"Baseline Train\", alpha=0.7)\n",
    "axes[0].plot(tx, tl, label=\"Baseline Test\", alpha=0.7)\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Baseline: Loss Curves\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "tx_r2 = [t[0] for t in results['train_r2s']]\n",
    "tr = [t[1] for t in results['train_r2s']]\n",
    "te = [t[1] for t in results['test_r2s']]\n",
    "\n",
    "axes[1].plot(tx_r2, tr, label=\"Baseline Train\", alpha=0.7)\n",
    "axes[1].plot(tx_r2, te, label=\"Baseline Test\", alpha=0.7)\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"R¬≤\")\n",
    "axes[1].set_title(\"Baseline: R¬≤ Curves\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sr5mfqewxtn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize AE reconstruction penalty alongside other metrics\n",
    "# Handle missing data gracefully\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Check which models are available\n",
    "models_available = {\n",
    "    'baseline': 'results' in globals(),\n",
    "    'spatial': 'results_spatial' in globals(),\n",
    "    'ae_recon': 'results_ae_recon' in globals(),\n",
    "}\n",
    "\n",
    "print(\"Available models:\")\n",
    "for name, available in models_available.items():\n",
    "    print(f\"  {name}: {'‚úì' if available else '‚úó'}\")\n",
    "print()\n",
    "\n",
    "# Extract baseline data if available\n",
    "if models_available['baseline']:\n",
    "    txt = [t[0] for t in results['train_losses']]\n",
    "    tlt = [t[1] for t in results['train_losses']]\n",
    "    tx = [t[0] for t in results['test_losses']]\n",
    "    tl = [t[1] for t in results['test_losses']]\n",
    "    tx_r2 = [t[0] for t in results['train_r2s']]\n",
    "    tr = [t[1] for t in results['train_r2s']]\n",
    "    te = [t[1] for t in results['test_r2s']]\n",
    "\n",
    "# Extract spatial data if available\n",
    "if models_available['spatial']:\n",
    "    txt_s = [t[0] for t in results_spatial['train_losses']]\n",
    "    tlt_s = [t[1] for t in results_spatial['train_losses']]\n",
    "    tx_s = [t[0] for t in results_spatial['test_losses']]\n",
    "    tl_s = [t[1] for t in results_spatial['test_losses']]\n",
    "    tx_r2_s = [t[0] for t in results_spatial['train_r2s']]\n",
    "    tr_s = [t[1] for t in results_spatial['train_r2s']]\n",
    "    te_s = [t[1] for t in results_spatial['test_r2s']]\n",
    "\n",
    "# Extract AE recon data if available\n",
    "if models_available['ae_recon']:\n",
    "    txt_ae = [t[0] for t in results_ae_recon['train_losses']]\n",
    "    tlt_ae = [t[1] for t in results_ae_recon['train_losses']]\n",
    "    tx_ae = [t[0] for t in results_ae_recon['test_losses']]\n",
    "    tl_ae = [t[1] for t in results_ae_recon['test_losses']]\n",
    "    tx_r2_ae = [t[0] for t in results_ae_recon['train_r2s']]\n",
    "    tr_ae = [t[1] for t in results_ae_recon['train_r2s']]\n",
    "    te_ae = [t[1] for t in results_ae_recon['test_r2s']]\n",
    "\n",
    "# Test Loss Comparison\n",
    "if models_available['baseline']:\n",
    "    axes[0, 0].plot(tx, tl, label=\"Baseline\", alpha=0.8, linewidth=2, color='C0')\n",
    "if models_available['spatial']:\n",
    "    axes[0, 0].plot(tx_s, tl_s, label=\"Spatial\", alpha=0.8, linewidth=2, color='C2')\n",
    "if models_available['ae_recon']:\n",
    "    axes[0, 0].plot(tx_ae, tl_ae, label=\"AE Recon\", alpha=0.8, linewidth=2, color='C3')\n",
    "axes[0, 0].set_xlabel(\"Epoch\")\n",
    "axes[0, 0].set_ylabel(\"Test Loss\")\n",
    "axes[0, 0].set_title(\"Test Loss: All Available Models\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test R¬≤ Comparison\n",
    "if models_available['baseline']:\n",
    "    axes[0, 1].plot(tx_r2, te, label=\"Baseline\", alpha=0.8, linewidth=2, color='C0')\n",
    "if models_available['spatial']:\n",
    "    axes[0, 1].plot(tx_r2_s, te_s, label=\"Spatial\", alpha=0.8, linewidth=2, color='C2')\n",
    "if models_available['ae_recon']:\n",
    "    axes[0, 1].plot(tx_r2_ae, te_ae, label=\"AE Recon\", alpha=0.8, linewidth=2, color='C3')\n",
    "axes[0, 1].set_xlabel(\"Epoch\")\n",
    "axes[0, 1].set_ylabel(\"Test R¬≤\")\n",
    "axes[0, 1].set_title(\"Test R¬≤: All Available Models\")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# AE Reconstruction penalty over training (if available)\n",
    "if models_available['ae_recon']:\n",
    "    ae_recon_x = [t[0] for t in results_ae_recon['ae_recon_losses']]\n",
    "    ae_recon_y = [t[1] for t in results_ae_recon['ae_recon_losses']]\n",
    "    axes[1, 0].plot(ae_recon_x, ae_recon_y, alpha=0.8, linewidth=2, color='C1')\n",
    "    axes[1, 0].set_xlabel(\"Epoch\")\n",
    "    axes[1, 0].set_ylabel(\"AE Reconstruction Loss\")\n",
    "    axes[1, 0].set_title(\"AE Reconstruction Penalty Over Training\")\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, \"AE Recon model not trained\", \n",
    "                    ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "    axes[1, 0].set_title(\"AE Reconstruction Penalty (N/A)\")\n",
    "\n",
    "# Per-session R¬≤ comparison bar chart\n",
    "if any(models_available.values()):\n",
    "    # Get session list from first available model\n",
    "    if models_available['baseline']:\n",
    "        sessions = list(results['final_test_r2s'].keys())\n",
    "    elif models_available['spatial']:\n",
    "        sessions = list(results_spatial['final_test_r2s'].keys())\n",
    "    else:\n",
    "        sessions = list(results_ae_recon['final_test_r2s'].keys())\n",
    "    \n",
    "    x = range(len(sessions))\n",
    "    width = 0.25\n",
    "    offset = 0\n",
    "    \n",
    "    if models_available['baseline']:\n",
    "        baseline_vals = [results['final_test_r2s'][s] for s in sessions]\n",
    "        axes[1, 1].bar([i + offset*width for i in x], baseline_vals, width, \n",
    "                      label='Baseline', color='C0', alpha=0.7)\n",
    "        offset += 1\n",
    "    \n",
    "    if models_available['spatial']:\n",
    "        spatial_vals = [results_spatial['final_test_r2s'][s] for s in sessions]\n",
    "        axes[1, 1].bar([i + offset*width for i in x], spatial_vals, width, \n",
    "                      label='Spatial', color='C2', alpha=0.7)\n",
    "        offset += 1\n",
    "    \n",
    "    if models_available['ae_recon']:\n",
    "        ae_recon_vals = [results_ae_recon['final_test_r2s'][s] for s in sessions]\n",
    "        axes[1, 1].bar([i + offset*width for i in x], ae_recon_vals, width, \n",
    "                      label='AE Recon', color='C3', alpha=0.7)\n",
    "        offset += 1\n",
    "    \n",
    "    axes[1, 1].set_ylabel(\"Test R¬≤\")\n",
    "    axes[1, 1].set_title(\"Per-Session Test R¬≤ Comparison\")\n",
    "    axes[1, 1].set_xticks([i + (offset-1)*width/2 for i in x])\n",
    "    axes[1, 1].set_xticklabels([s.split('_')[1] + '_' + s.split('_')[-1] for s in sessions], \n",
    "                               rotation=45, ha='right')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, \"No models trained yet\", \n",
    "                    ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "    axes[1, 1].set_title(\"Per-Session Comparison (N/A)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comparison table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL COMPARISON: Available Models\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = []\n",
    "if models_available['baseline']:\n",
    "    comparison_data.append((\"Baseline\", results['final_test_r2']))\n",
    "if models_available['spatial']:\n",
    "    comparison_data.append((\"Spatial\", results_spatial['final_test_r2']))\n",
    "if models_available['ae_recon']:\n",
    "    comparison_data.append((\"AE Recon\", results_ae_recon['final_test_r2']))\n",
    "\n",
    "if comparison_data:\n",
    "    for name, r2 in comparison_data:\n",
    "        print(f\"{name:20s} Test R¬≤ = {r2:.6f}\")\n",
    "    \n",
    "    if len(comparison_data) > 1:\n",
    "        print(\"=\"*80)\n",
    "        print(\"\\nImprovement over Baseline:\")\n",
    "        baseline_r2 = comparison_data[0][1] if comparison_data[0][0] == \"Baseline\" else None\n",
    "        if baseline_r2:\n",
    "            for name, r2 in comparison_data[1:]:\n",
    "                improvement = r2 - baseline_r2\n",
    "                pct = improvement / baseline_r2 * 100\n",
    "                print(f\"  {name:18s} {improvement:+.6f} ({pct:+.2f}%)\")\n",
    "else:\n",
    "    print(\"No models trained yet. Run training cells above.\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5tpxioria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training curves with both penalties\n",
    "# Handle missing Stage 1 data\n",
    "\n",
    "if 'results_s1' not in globals():\n",
    "    print(\"=\"*80)\n",
    "    print(\"Stage 1 not trained yet - run Stage 1 training cell first\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    # Test R¬≤ over training\n",
    "    tx_r2_s1 = [t[0] for t in results_s1['train_r2s']]\n",
    "    te_s1 = [t[1] for t in results_s1['test_r2s']]\n",
    "\n",
    "    axes[0, 0].plot(tx_r2_s1, te_s1, label=\"Stage 1 (Sparsity)\", linewidth=2, color='C3')\n",
    "    axes[0, 0].set_xlabel(\"Epoch\")\n",
    "    axes[0, 0].set_ylabel(\"Test R¬≤\")\n",
    "    axes[0, 0].set_title(\"Test R¬≤: Sparsity-Based Training\")\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Test Loss over training\n",
    "    tx_s1 = [t[0] for t in results_s1['test_losses']]\n",
    "    tl_s1 = [t[1] for t in results_s1['test_losses']]\n",
    "\n",
    "    axes[0, 1].plot(tx_s1, tl_s1, label=\"Stage 1 (Sparsity)\", linewidth=2, color='C3')\n",
    "    axes[0, 1].set_xlabel(\"Epoch\")\n",
    "    axes[0, 1].set_ylabel(\"Test Loss\")\n",
    "    axes[0, 1].set_title(\"Test Loss: Sparsity-Based Training\")\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Channel sparsity penalty over training\n",
    "    sparsity_x = [t[0] for t in results_s1['channel_sparsity_losses']]\n",
    "    sparsity_y = [t[1] for t in results_s1['channel_sparsity_losses']]\n",
    "\n",
    "    axes[1, 0].plot(sparsity_x, sparsity_y, linewidth=2, color='C4')\n",
    "    axes[1, 0].set_xlabel(\"Epoch\")\n",
    "    axes[1, 0].set_ylabel(\"Channel Sparsity Penalty (L1)\")\n",
    "    axes[1, 0].set_title(\"L1 Sparsity Penalty Over Training\")\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Sparsity-weighted reconstruction penalty over training\n",
    "    recon_x = [t[0] for t in results_s1['sparsity_recon_losses']]\n",
    "    recon_y = [t[1] for t in results_s1['sparsity_recon_losses']]\n",
    "\n",
    "    axes[1, 1].plot(recon_x, recon_y, linewidth=2, color='C5')\n",
    "    axes[1, 1].set_xlabel(\"Epoch\")\n",
    "    axes[1, 1].set_ylabel(\"Sparsity-Weighted Reconstruction Loss\")\n",
    "    axes[1, 1].set_title(\"Reconstruction Penalty Over Training\")\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nStage 1 Complete:\")\n",
    "    print(f\"  Test R¬≤: {results_s1['final_test_r2']:.6f}\")\n",
    "    print(f\"  Final sparsity penalty: {sparsity_y[-1]:.6f}\")\n",
    "    print(f\"  Final reconstruction penalty: {recon_y[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8my3u51tlz7",
   "metadata": {},
   "source": [
    "### Analyze Learned Sparsity Patterns\n",
    "\n",
    "Examine which channels have low activation and can be safely compressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87zng9flu4k",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze channel activations from Stage 1 to identify important channels\n",
    "import numpy as np\n",
    "\n",
    "# Check if Stage 1 results are available\n",
    "if 'results_s1' not in globals():\n",
    "    print(\"=\"*80)\n",
    "    print(\"Stage 1 not trained yet - run Stage 1 training cell first\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(\"SPARSITY ANALYSIS\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    important_channels = {}\n",
    "    channel_importance_scores = {}\n",
    "\n",
    "    for session_id in held_in_session_ids:\n",
    "        # Get final channel activations (from last tracking point)\n",
    "        if len(results_s1['channel_activations'][session_id]) > 0:\n",
    "            final_epoch, final_activations = results_s1['channel_activations'][session_id][-1]\n",
    "            channel_importance = final_activations.numpy()\n",
    "            \n",
    "            # Store importance scores\n",
    "            channel_importance_scores[session_id] = channel_importance\n",
    "            \n",
    "            # Identify important channels (above median activation)\n",
    "            median_activation = np.median(channel_importance)\n",
    "            important_mask = channel_importance > median_activation\n",
    "            important_idx = np.where(important_mask)[0]\n",
    "            \n",
    "            important_channels[session_id] = important_idx.tolist()\n",
    "            \n",
    "            logger.info(f\"\\n{session_id}:\")\n",
    "            logger.info(f\"  Total channels: {len(channel_importance)}\")\n",
    "            logger.info(f\"  Important channels (>median): {len(important_idx)}\")\n",
    "            logger.info(f\"  Compression ratio: {len(important_idx)/len(channel_importance):.2%}\")\n",
    "            logger.info(f\"  Median activation: {median_activation:.6f}\")\n",
    "            logger.info(f\"  Max activation: {channel_importance.max():.6f}\")\n",
    "            logger.info(f\"  Min activation: {channel_importance.min():.6f}\")\n",
    "\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    # Visualize channel importance across sessions\n",
    "    fig, axes = plt.subplots(len(held_in_session_ids), 1, figsize=(12, 3*len(held_in_session_ids)))\n",
    "    if len(held_in_session_ids) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for idx, session_id in enumerate(held_in_session_ids):\n",
    "        if session_id in channel_importance_scores:\n",
    "            importance = channel_importance_scores[session_id]\n",
    "            important_idx = important_channels[session_id]\n",
    "            \n",
    "            axes[idx].bar(range(len(importance)), importance, alpha=0.6, color='gray', label='All channels')\n",
    "            axes[idx].bar(important_idx, importance[important_idx], alpha=0.8, color='C3', label='Important channels')\n",
    "            axes[idx].axhline(np.median(importance), color='red', linestyle='--', label='Median', linewidth=2)\n",
    "            axes[idx].set_xlabel(\"Channel Index\")\n",
    "            axes[idx].set_ylabel(\"Mean Activation\")\n",
    "            axes[idx].set_title(f\"{session_id.split('_')[1]}_{session_id.split('_')[-1]}\")\n",
    "            axes[idx].legend()\n",
    "            axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nChannel importance scores computed. Ready for Stage 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h0cdfkhk04",
   "metadata": {},
   "source": [
    "## Overall Summary\n",
    "\n",
    "Compare all trained models (automatically detects which ones are available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sswcetxw7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model comparison - automatically detects available models\n",
    "import pandas as pd\n",
    "\n",
    "# Check which models are available\n",
    "models_info = {\n",
    "    'Baseline (PCA AE)': ('results', 'Standard TBFM with PCA-initialized AE'),\n",
    "    'Spatial Reg': ('results_spatial', 'Spatial smoothness regularization'),\n",
    "    'AE Recon': ('results_ae_recon', 'AE reconstruction penalty only'),\n",
    "    'Sparsity Stage 1': ('results_s1', 'Identity AE + sparsity penalties'),\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAvailable Models:\")\n",
    "\n",
    "available_models = []\n",
    "for name, (var_name, description) in models_info.items():\n",
    "    is_available = var_name in globals()\n",
    "    status = \"‚úì\" if is_available else \"‚úó\"\n",
    "    print(f\"  {status} {name:20s} - {description}\")\n",
    "    if is_available:\n",
    "        available_models.append((name, var_name, globals()[var_name]))\n",
    "\n",
    "if not available_models:\n",
    "    print(\"\\nNo models trained yet. Run training cells above.\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PERFORMANCE COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_rows = []\n",
    "    for name, var_name, results in available_models:\n",
    "        comparison_rows.append({\n",
    "            'Model': name,\n",
    "            'Test R¬≤': f\"{results['final_test_r2']:.6f}\",\n",
    "            'Best R¬≤': f\"{results.get('best_test_r2', results['final_test_r2']):.6f}\",\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(comparison_rows)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Calculate improvements if baseline exists\n",
    "    baseline_results = next((r for n, v, r in available_models if n == 'Baseline (PCA AE)'), None)\n",
    "    if baseline_results and len(available_models) > 1:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"IMPROVEMENT OVER BASELINE\")\n",
    "        print(\"=\"*80)\n",
    "        baseline_r2 = baseline_results['final_test_r2']\n",
    "        \n",
    "        for name, var_name, results in available_models:\n",
    "            if name != 'Baseline (PCA AE)':\n",
    "                r2 = results['final_test_r2']\n",
    "                improvement = r2 - baseline_r2\n",
    "                pct = (improvement / baseline_r2) * 100\n",
    "                symbol = \"+\" if improvement > 0 else \"\"\n",
    "                print(f\"  {name:20s}: {symbol}{improvement:.6f} ({symbol}{pct:.2f}%)\")\n",
    "    \n",
    "    # Per-session breakdown if multiple models\n",
    "    if len(available_models) > 1:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"PER-SESSION COMPARISON\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Get session list from first available model\n",
    "        sessions = list(available_models[0][2]['final_test_r2s'].keys())\n",
    "        \n",
    "        for session_id in sessions:\n",
    "            print(f\"\\n{session_id}:\")\n",
    "            for name, var_name, results in available_models:\n",
    "                if session_id in results['final_test_r2s']:\n",
    "                    r2 = results['final_test_r2s'][session_id]\n",
    "                    print(f\"  {name:20s}: {r2:.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    # Visualize all available models\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Overall comparison bar chart\n",
    "    model_names = [name for name, _, _ in available_models]\n",
    "    test_r2s = [results['final_test_r2'] for _, _, results in available_models]\n",
    "    \n",
    "    axes[0].bar(range(len(model_names)), test_r2s, alpha=0.7)\n",
    "    axes[0].set_xticks(range(len(model_names)))\n",
    "    axes[0].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    axes[0].set_ylabel(\"Test R¬≤\")\n",
    "    axes[0].set_title(\"Overall Test R¬≤ Comparison\")\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add values on bars\n",
    "    for i, v in enumerate(test_r2s):\n",
    "        axes[0].text(i, v + 0.005, f\"{v:.4f}\", ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Per-session heatmap\n",
    "    if len(available_models) > 1:\n",
    "        sessions = list(available_models[0][2]['final_test_r2s'].keys())\n",
    "        session_data = []\n",
    "        for name, var_name, results in available_models:\n",
    "            session_r2s = [results['final_test_r2s'].get(s, 0) for s in sessions]\n",
    "            session_data.append(session_r2s)\n",
    "        \n",
    "        session_data = np.array(session_data).T  # Sessions x Models\n",
    "        \n",
    "        im = axes[1].imshow(session_data, aspect='auto', cmap='viridis')\n",
    "        axes[1].set_xticks(range(len(model_names)))\n",
    "        axes[1].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "        axes[1].set_yticks(range(len(sessions)))\n",
    "        axes[1].set_yticklabels([s.split('_')[1] + '_' + s.split('_')[-1] for s in sessions])\n",
    "        axes[1].set_title(\"Per-Session Test R¬≤\")\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=axes[1])\n",
    "        cbar.set_label(\"Test R¬≤\")\n",
    "        \n",
    "        # Add text annotations\n",
    "        for i in range(len(sessions)):\n",
    "            for j in range(len(model_names)):\n",
    "                text = axes[1].text(j, i, f\"{session_data[i, j]:.3f}\",\n",
    "                                   ha=\"center\", va=\"center\", color=\"w\", fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2p4wvdexnny",
   "metadata": {},
   "source": [
    "## Comparison: Baseline vs Spatial Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dmle5eeq8t",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"\\n\" + \"=\"*80)\n",
    "logger.info(\"COMPARISON: BASELINE vs SPATIAL\")\n",
    "logger.info(\"=\"*80)\n",
    "\n",
    "# Compare overall performance\n",
    "baseline_r2 = results['final_test_r2']\n",
    "spatial_r2 = results_spatial['final_test_r2']\n",
    "\n",
    "logger.info(f\"\\nOverall Test R¬≤:\")\n",
    "logger.info(f\"  Baseline: {baseline_r2:.6f}\")\n",
    "logger.info(f\"  Spatial:  {spatial_r2:.6f}\")\n",
    "logger.info(f\"  Improvement: {(spatial_r2 - baseline_r2):.6f} ({(spatial_r2 - baseline_r2)/baseline_r2*100:.2f}%)\")\n",
    "\n",
    "# Per-session comparison\n",
    "logger.info(f\"\\nPer-session Test R¬≤:\")\n",
    "for session_id in held_in_session_ids:\n",
    "    base_r2 = results['final_test_r2s'][session_id]\n",
    "    spat_r2 = results_spatial['final_test_r2s'][session_id]\n",
    "    improvement = spat_r2 - base_r2\n",
    "    logger.info(f\"  {session_id}:\")\n",
    "    logger.info(f\"    Baseline: {base_r2:.6f}\")\n",
    "    logger.info(f\"    Spatial:  {spat_r2:.6f}\")\n",
    "    logger.info(f\"    Improvement: {improvement:.6f} ({improvement/base_r2*100:.2f}%)\")\n",
    "\n",
    "logger.info(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drqixieh9e",
   "metadata": {},
   "source": [
    "## Comparison Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ju30yr0bgq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct comparison: Baseline vs Spatial\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Extract data\n",
    "txt = [t[0] for t in results['train_losses']]\n",
    "tlt = [t[1] for t in results['train_losses']]\n",
    "tx = [t[0] for t in results['test_losses']]\n",
    "tl = [t[1] for t in results['test_losses']]\n",
    "tx_r2 = [t[0] for t in results['train_r2s']]\n",
    "tr = [t[1] for t in results['train_r2s']]\n",
    "te = [t[1] for t in results['test_r2s']]\n",
    "\n",
    "txt_s = [t[0] for t in results_spatial['train_losses']]\n",
    "tlt_s = [t[1] for t in results_spatial['train_losses']]\n",
    "tx_s = [t[0] for t in results_spatial['test_losses']]\n",
    "tl_s = [t[1] for t in results_spatial['test_losses']]\n",
    "tx_r2_s = [t[0] for t in results_spatial['train_r2s']]\n",
    "tr_s = [t[1] for t in results_spatial['train_r2s']]\n",
    "te_s = [t[1] for t in results_spatial['test_r2s']]\n",
    "\n",
    "# Test Loss Comparison\n",
    "axes[0, 0].plot(tx, tl, label=\"Baseline\", alpha=0.8, linewidth=2, color='C0')\n",
    "axes[0, 0].plot(tx_s, tl_s, label=\"Spatial\", alpha=0.8, linewidth=2, color='C2')\n",
    "axes[0, 0].set_xlabel(\"Epoch\")\n",
    "axes[0, 0].set_ylabel(\"Test Loss\")\n",
    "axes[0, 0].set_title(\"Test Loss: Baseline vs Spatial\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test R¬≤ Comparison\n",
    "axes[0, 1].plot(tx_r2, te, label=\"Baseline\", alpha=0.8, linewidth=2, color='C0')\n",
    "axes[0, 1].plot(tx_r2_s, te_s, label=\"Spatial\", alpha=0.8, linewidth=2, color='C2')\n",
    "axes[0, 1].set_xlabel(\"Epoch\")\n",
    "axes[0, 1].set_ylabel(\"Test R¬≤\")\n",
    "axes[0, 1].set_title(\"Test R¬≤: Baseline vs Spatial\")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Spatial penalty curves\n",
    "smoothx = [t[0] for t in results_spatial['spatial_smooth_losses']]\n",
    "smoothy = [t[1] for t in results_spatial['spatial_smooth_losses']]\n",
    "decx = [t[0] for t in results_spatial['spatial_decoder_losses']]\n",
    "decy = [t[1] for t in results_spatial['spatial_decoder_losses']]\n",
    "\n",
    "axes[1, 0].plot(smoothx, smoothy, alpha=0.8, linewidth=2, color='C4')\n",
    "axes[1, 0].set_xlabel(\"Epoch\")\n",
    "axes[1, 0].set_ylabel(\"Spatial Smoothness Penalty\")\n",
    "axes[1, 0].set_title(\"Spatial Smoothness Penalty Over Training\")\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(decx, decy, alpha=0.8, linewidth=2, color='C5')\n",
    "axes[1, 1].set_xlabel(\"Epoch\")\n",
    "axes[1, 1].set_ylabel(\"Spatial Decoder Penalty\")\n",
    "axes[1, 1].set_title(\"Spatial Decoder Penalty Over Training\")\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final comparison bar chart\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Overall comparison\n",
    "overall_data = [baseline_r2, spatial_r2]\n",
    "axes[0].bar(['Baseline', 'Spatial'], overall_data, color=['C0', 'C2'], alpha=0.7)\n",
    "axes[0].set_ylabel(\"Test R¬≤\")\n",
    "axes[0].set_title(\"Overall Test R¬≤ Comparison\")\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "for i, v in enumerate(overall_data):\n",
    "    axes[0].text(i, v + 0.001, f\"{v:.5f}\", ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Per-session comparison\n",
    "sessions = list(results['final_test_r2s'].keys())\n",
    "baseline_vals = [results['final_test_r2s'][s] for s in sessions]\n",
    "spatial_vals = [results_spatial['final_test_r2s'][s] for s in sessions]\n",
    "\n",
    "x = range(len(sessions))\n",
    "width = 0.35\n",
    "\n",
    "axes[1].bar([i - width/2 for i in x], baseline_vals, width, label='Baseline', color='C0', alpha=0.7)\n",
    "axes[1].bar([i + width/2 for i in x], spatial_vals, width, label='Spatial', color='C2', alpha=0.7)\n",
    "axes[1].set_ylabel(\"Test R¬≤\")\n",
    "axes[1].set_title(\"Per-Session Test R¬≤ Comparison\")\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels([s.split('_')[1] + '_' + s.split('_')[-1] for s in sessions], rotation=45, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Summary Statistics\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Baseline - Final Test R¬≤: {baseline_r2:.6f}\")\n",
    "print(f\"Spatial  - Final Test R¬≤: {spatial_r2:.6f}\")\n",
    "print(f\"Improvement: {(spatial_r2 - baseline_r2):.6f} ({(spatial_r2 - baseline_r2)/baseline_r2*100:.2f}%)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x3iglauxi5m",
   "metadata": {},
   "source": [
    "## Load Saved Models\n",
    "\n",
    "To load the saved models later, use:\n",
    "\n",
    "```python\n",
    "# Load baseline model\n",
    "checkpoint = torch.load(model_save_dir / \"baseline_model.pt\")\n",
    "ms_loaded = multisession.build_from_cfg(cfg, data_train, device=DEVICE)\n",
    "ms_loaded.load_state_dict(checkpoint['ms_state_dict'])\n",
    "embeddings_stim_loaded = checkpoint['embeddings_stim']\n",
    "results_loaded = checkpoint['results']\n",
    "\n",
    "# Load spatial model\n",
    "checkpoint_spatial = torch.load(model_save_dir / \"spatial_model.pt\")\n",
    "cfg_spatial_loaded = OmegaConf.create(checkpoint_spatial['config'])\n",
    "ms_spatial_loaded = multisession.build_from_cfg(cfg_spatial_loaded, data_train, device=DEVICE)\n",
    "ms_spatial_loaded.load_state_dict(checkpoint_spatial['ms_state_dict'])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
